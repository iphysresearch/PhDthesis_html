% Encoding: UTF-8
%---------------------------------------------------------------------------%
%-                                                                         -%
%-                             Bibliography                                -%
%-                                                                         -%
%---------------------------------------------------------------------------%

@Article{2016Abbott-ObservationGravitationalWaves,
  author        = {Abbott, B. P. and others},
  title         = {Observation of Gravitational Waves from a Binary Black Hole Merger},
  journal       = {Phys. Rev. Lett.},
  year          = {2016},
  volume        = {116},
  number        = {6},
  pages         = {061102},
  archiveprefix = {arXiv},
  collaboration = {Virgo, LIGO Scientific},
  doi           = {10.1103/PhysRevLett.116.061102},
  eprint        = {1602.03837},
  file          = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:2016Abbott-ObservationGravitationalWaves.pdf/\:PDF/\:/\:2016Abbott-ObservationGravitationalWaves.pdf/\:PDF/\:PDF/\:/\:2016Abbott-ObservationGravitationalWaves.pdf/\:PDF/\:/\:2016Abbott-ObservationGravitationalWaves.pdf/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  primaryclass  = {gr-qc},
  reportnumber  = {LIGO-P150914},
}

@Article{2016Abbott-GW151226ObservationGravitational,
  author        = {Abbott, B. P. and others},
  title         = {GW151226: Observation of Gravitational Waves from a 22-Solar-Mass Binary Black Hole Coalescence},
  journal       = {Phys. Rev. Lett.},
  year          = {2016},
  volume        = {116},
  number        = {24},
  pages         = {241103},
  archiveprefix = {arXiv},
  collaboration = {Virgo, LIGO Scientific},
  doi           = {10.1103/PhysRevLett.116.241103},
  eprint        = {1606.04855},
  primaryclass  = {gr-qc},
  reportnumber  = {LIGO-P151226},
}

@Article{2017Abbott-GW170104Observation50,
  author        = {Abbott, Benjamin P. and others},
  title         = {GW170104: Observation of a 50-Solar-Mass Binary Black Hole Coalescence at Redshift 0.2},
  journal       = {Phys. Rev. Lett.},
  year          = {2017},
  volume        = {118},
  number        = {22},
  pages         = {221101},
  archiveprefix = {arXiv},
  collaboration = {VIRGO, LIGO Scientific},
  doi           = {10.1103/PhysRevLett.118.221101},
  eprint        = {1706.01812},
  primaryclass  = {gr-qc},
  reportnumber  = {LIGO-P170104},
}

@Article{2017Abbott-GW170608Observation19,
  author        = {Abbott, B.. P.. and others},
  title         = {GW170608: Observation of a 19-solar-mass Binary Black Hole Coalescence},
  journal       = {Astrophys. J.},
  year          = {2017},
  volume        = {851},
  number        = {2},
  pages         = {L35},
  archiveprefix = {arXiv},
  collaboration = {Virgo, LIGO Scientific},
  doi           = {10.3847/2041-8213/aa9f0c},
  eprint        = {1711.05578},
  primaryclass  = {astro-ph.HE},
  reportnumber  = {LIGO-DOCUMENT-P170608-V8},
}

@Article{2016Abbott-PropertiesBinaryBlack,
  author        = {Abbott, B. P. and others},
  title         = {Properties of the Binary Black Hole Merger GW150914},
  journal       = {Phys. Rev. Lett.},
  year          = {2016},
  volume        = {116},
  number        = {24},
  pages         = {241102},
  archiveprefix = {arXiv},
  collaboration = {LIGO Scientific, Virgo},
  doi           = {10.1103/PhysRevLett.116.241102},
  eprint        = {1602.03840},
  primaryclass  = {gr-qc},
  reportnumber  = {LIGO-P1500218},
}

@Article{2010Belczynski-effectmetallicitydetection,
  author        = {Belczynski, Krzysztof and Dominik, Michal and Bulik, Tomasz and O'Shaughnessy, Richard and Fryer, Chris and Holz, Daniel E.},
  title         = {The effect of metallicity on the detection prospects for gravitational waves},
  journal       = {Astrophys. J.},
  year          = {2010},
  volume        = {715},
  pages         = {L138},
  archiveprefix = {arXiv},
  doi           = {10.1088/2041-8205/715/2/L138},
  eprint        = {1004.0386},
  primaryclass  = {astro-ph.HE},
  reportnumber  = {LA-UR-10-01970},
}

@Article{2016Antonini-Blackholemergers,
  author        = {Antonini, Fabio and Chatterjee, Sourav and Rodriguez, Carl L. and Morscher, Meagan and Pattabiraman, Bharath and Kalogera, Vicky and Rasio, Frederic A.},
  title         = {Black hole mergers and blue stragglers from hierarchical triples formed in globular clusters},
  journal       = {Astrophys. J.},
  year          = {2016},
  volume        = {816},
  number        = {2},
  pages         = {65},
  archiveprefix = {arXiv},
  doi           = {10.3847/0004-637X/816/2/65},
  eprint        = {1509.05080},
  primaryclass  = {astro-ph.GA},
}

@Article{2018Abbott-ProspectsObservingLocalizing,
  author        = {Abbott, B. P. and others},
  journal       = {Living Rev. Rel.},
  title         = {Prospects for Observing and Localizing Gravitational-Wave Transients with Advanced LIGO, Advanced Virgo and KAGRA},
  year          = {2018},
  number        = {1},
  pages         = {3},
  volume        = {21},
  archiveprefix = {arXiv},
  collaboration = {KAGRA, LIGO Scientific, VIRGO},
  doi           = {10.1007/s41114-018-0012-9,10.1007/lrr-2016-1},
  eprint        = {1304.0670},
  primaryclass  = {gr-qc},
  reportnumber  = {LIGO-P1200087, VIR-0288A-12},
}

@Article{2016Rodriguez-BinaryBlackHole,
  author        = {Rodriguez, Carl L. and Chatterjee, Sourav and Rasio, Frederic A.},
  title         = {Binary Black Hole Mergers from Globular Clusters: Masses, Merger Rates, and the Impact of Stellar Evolution},
  journal       = {Phys. Rev.},
  year          = {2016},
  volume        = {D93},
  number        = {8},
  pages         = {084029},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.93.084029},
  eprint        = {1602.02444},
  primaryclass  = {astro-ph.HE},
}

@Article{2016Belczynski-firstgravitationalwave,
  author        = {Belczynski, Krzysztof and Holz, Daniel E. and Bulik, Tomasz and O'Shaughnessy, Richard},
  title         = {The first gravitational-wave source from the isolated evolution of two 40-100 Msun stars},
  journal       = {Nature},
  year          = {2016},
  volume        = {534},
  pages         = {512},
  archiveprefix = {arXiv},
  doi           = {10.1038/nature18322},
  eprint        = {1602.04531},
  primaryclass  = {astro-ph.HE},
}

@Article{2016Marchant-newroutetowards,
  author        = {Marchant, Pablo and Langer, Norbert and Podsiadlowski, Philipp and Tauris, Thomas M. and Moriya, Takashi J.},
  title         = {A new route towards merging massive black holes},
  journal       = {Astron. Astrophys.},
  year          = {2016},
  volume        = {588},
  pages         = {A50},
  archiveprefix = {arXiv},
  doi           = {10.1051/0004-6361/201628133},
  eprint        = {1601.03718},
  primaryclass  = {astro-ph.SR},
}

@Article{2016Mink-chemicallyhomogeneousevolutionary,
  author        = {de Mink, S. E. and Mandel, I.},
  title         = {The chemically homogeneous evolutionary channel for binary black hole mergers: rates and properties of gravitational-wave events detectable by advanced LIGO},
  journal       = {Mon. Not. Roy. Astron. Soc.},
  year          = {2016},
  volume        = {460},
  number        = {4},
  pages         = {3545--3553},
  archiveprefix = {arXiv},
  doi           = {10.1093/mnras/stw1219},
  eprint        = {1603.02291},
  primaryclass  = {astro-ph.HE},
}

@Article{2015Acernese-AdvancedVirgosecond,
  author        = {Acernese, F. and others},
  title         = {Advanced Virgo: a second-generation interferometric gravitational wave detector},
  journal       = {Class. Quant. Grav.},
  year          = {2015},
  volume        = {32},
  number        = {2},
  pages         = {024001},
  archiveprefix = {arXiv},
  collaboration = {VIRGO},
  doi           = {10.1088/0264-9381/32/2/024001},
  eprint        = {1408.3978},
  primaryclass  = {gr-qc},
}

@Article{2017Abbott-GW170814ThreeDetector,
  author        = {Abbott, B. P. and others},
  title         = {GW170814: A Three-Detector Observation of Gravitational Waves from a Binary Black Hole Coalescence},
  journal       = {Phys. Rev. Lett.},
  year          = {2017},
  volume        = {119},
  number        = {14},
  pages         = {141101},
  archiveprefix = {arXiv},
  collaboration = {Virgo, LIGO Scientific},
  doi           = {10.1103/PhysRevLett.119.141101},
  eprint        = {1709.09660},
  primaryclass  = {gr-qc},
}

@Article{2017Abbott-GW170817ObservationGravitational,
  author        = {Abbott, B. P. and others},
  title         = {GW170817: Observation of Gravitational Waves from a Binary Neutron Star Inspiral},
  journal       = {Phys. Rev. Lett.},
  year          = {2017},
  volume        = {119},
  number        = {16},
  pages         = {161101},
  archiveprefix = {arXiv},
  collaboration = {Virgo, LIGO Scientific},
  doi           = {10.1103/PhysRevLett.119.161101},
  eprint        = {1710.05832},
  primaryclass  = {gr-qc},
  reportnumber  = {LIGO-P170817},
}

@Article{1989Eichler-NucleosynthesisNeutrinoBursts,
  author       = {Eichler, David and Livio, Mario and Piran, Tsvi and Schramm, David N.},
  title        = {Nucleosynthesis, Neutrino Bursts and Gamma-Rays from Coalescing Neutron Stars},
  journal      = {Nature},
  year         = {1989},
  volume       = {340},
  pages        = {126--128},
  note         = {[,682(1989)]},
  doi          = {10.1038/340126a0},
  reportnumber = {FERMILAB-PUB-89-102-A},
}

@Article{1986Paczynski-Gammaraybursters,
  author  = {Paczynski, Bohdan},
  title   = {Gamma-ray bursters at cosmological distances},
  journal = {Astrophys. J.},
  year    = {1986},
  volume  = {308},
  pages   = {L43-L46},
  doi     = {10.1086/184740},
}

@Article{1992Narayan-Gammaraybursts,
  author        = {Narayan, Ramesh and Paczynski, Bohdan and Piran, Tsvi},
  title         = {Gamma-ray bursts as the death throes of massive binary stars},
  journal       = {Astrophys. J.},
  year          = {1992},
  volume        = {395},
  pages         = {L83-L86},
  archiveprefix = {arXiv},
  doi           = {10.1086/186493},
  eprint        = {astro-ph/9204001},
  primaryclass  = {astro-ph},
  reportnumber  = {CFA-3396},
}

@Article{1993Kochanek-Gravitationalwavesgamma,
  author        = {Kochanek, Christopher S. and Piran, Tsvi},
  title         = {Gravitational waves and gamma-ray bursts},
  journal       = {Astrophys. J.},
  year          = {1993},
  volume        = {417},
  pages         = {L17-L20},
  archiveprefix = {arXiv},
  doi           = {10.1086/187083},
  eprint        = {astro-ph/9305015},
  primaryclass  = {astro-ph},
  reportnumber  = {CFA-3637},
}

@Article{2017Abbott-MultimessengerObservations,
  author        = {Abbott, B. P. and others},
  title         = {Multi-messenger Observations of a Binary Neutron Star Merger},
  journal       = {Astrophys. J.},
  year          = {2017},
  volume        = {848},
  number        = {2},
  pages         = {L12},
  archiveprefix = {arXiv},
  collaboration = {LIGO Scientific, Virgo, Fermi GBM, INTEGRAL, IceCube, AstroSat Cadmium Zinc Telluride Imager Team, IPN, Insight-Hxmt, ANTARES, Swift, AGILE Team, 1M2H Team, Dark Energy Camera GW-EM, DES, DLT40, GRAWITA, Fermi-LAT, ATCA, ASKAP, Las Cumbres Observatory Group, OzGrav, DWF (Deeper Wider Faster Program), AST3, CAASTRO, VINROUGE, MASTER, J-GEM, GROWTH, JAGWAR, CaltechNRAO, TTU-NRAO, NuSTAR, Pan-STARRS, MAXI Team, TZAC Consortium, KU, Nordic Optical Telescope, ePESSTO, GROND, Texas Tech University, SALT Group, TOROS, BOOTES, MWA, CALET, IKI-GW Follow-up, H.E.S.S., LOFAR, LWA, HAWC, Pierre Auger, ALMA, Euro VLBI Team, Pi of Sky, Chandra Team at McGill University, DFN, ATLAS Telescopes, High Time Resolution Universe Survey, RIMAS, RATIR, SKA South Africa/MeerKAT},
  doi           = {10.3847/2041-8213/aa91c9},
  eprint        = {1710.05833},
  primaryclass  = {astro-ph.HE},
  reportnumber  = {LIGO-P1700294, VIR-0802A-17, FERMILAB-PUB-17-478-A-AE-CD},
}

@Article{2013Piran-ElectromagneticSignalsCompact,
  author        = {Piran, Tsvi and Nakar, Ehud and Rosswog, Stephan},
  title         = {The Electromagnetic Signals of Compact Binary Mergers},
  journal       = {Mon. Not. Roy. Astron. Soc.},
  year          = {2013},
  volume        = {430},
  number        = {3},
  pages         = {2121--2136},
  archiveprefix = {arXiv},
  doi           = {10.1093/mnras/stt037},
  eprint        = {1204.6242},
  primaryclass  = {astro-ph.HE},
}

@Article{2010Lee-Shortgammaray,
  author        = {Lee, William H. and Ramirez-Ruiz, Enrico and van de Ven, Glenn},
  title         = {Short gamma-ray bursts from dynamically-assembled compact binaries in globular clusters: pathways, rates, hydrodynamics and cosmological setting},
  journal       = {Astrophys. J.},
  year          = {2010},
  volume        = {720},
  pages         = {953--975},
  archiveprefix = {arXiv},
  doi           = {10.1088/0004-637X/720/1/953},
  eprint        = {0909.2884},
  primaryclass  = {astro-ph.HE},
}

@Article{2007Lee-ProgenitorsShortGamma,
  author        = {Lee, William H. and Ramirez-Ruiz, Enrico},
  title         = {The Progenitors of Short Gamma-Ray Bursts},
  journal       = {New J. Phys.},
  year          = {2007},
  volume        = {9},
  pages         = {17},
  archiveprefix = {arXiv},
  doi           = {10.1088/1367-2630/9/1/017},
  eprint        = {astro-ph/0701874},
  primaryclass  = {ASTRO-PH},
}

@Article{2009Ott-GravitationalWaveSignature,
  author        = {Ott, ChristianD.},
  title         = {The Gravitational Wave Signature of Core-Collapse Supernovae},
  journal       = {Class. Quant. Grav.},
  year          = {2009},
  volume        = {26},
  pages         = {063001},
  archiveprefix = {arXiv},
  doi           = {10.1088/0264-9381/26/6/063001},
  eprint        = {0809.0695},
  primaryclass  = {astro-ph},
}

@Article{2009Phinney-FindingUsingElectromagnetic,
  author        = {Phinney, E. S.},
  title         = {Finding and Using Electromagnetic Counterparts of Gravitational Wave Sources},
  year          = {2009},
  archiveprefix = {arXiv},
  eprint        = {0903.0098},
  primaryclass  = {astro-ph.CO},
}

@Article{2015Aasi-AdvancedLIGO,
  author        = {Aasi, J. and others},
  title         = {Advanced LIGO},
  journal       = {Class. Quant. Grav.},
  year          = {2015},
  volume        = {32},
  pages         = {074001},
  archiveprefix = {arXiv},
  collaboration = {LIGO Scientific},
  doi           = {10.1088/0264-9381/32/7/074001},
  eprint        = {1411.4547},
  primaryclass  = {gr-qc},
}

@Article{2014Hirose-Updatedevelopmentcryogenic,
  author        = {Hirose, Eiichi and Sekiguchi, Takanori and Kumar, Rahul and Takahashi, Ryutaro},
  title         = {Update on the development of cryogenic sapphire mirrors and their seismic attenuation system for KAGRA},
  journal       = {Class. Quant. Grav.},
  year          = {2014},
  volume        = {31},
  number        = {22},
  pages         = {224004},
  collaboration = {KAGRA},
  doi           = {10.1088/0264-9381/31/22/224004},
}

@Article{2013Unnikrishnan-IndIGOLIGOIndia,
  author        = {Unnikrishnan, C. S.},
  title         = {IndIGO and LIGO-India: Scope and plans for gravitational wave research and precision metrology in India},
  journal       = {Int. J. Mod. Phys.},
  year          = {2013},
  volume        = {D22},
  pages         = {1341010},
  archiveprefix = {arXiv},
  doi           = {10.1142/S0218271813410101},
  eprint        = {1510.06059},
  primaryclass  = {physics.ins-det},
}

@Article{2017Abbott-Effectswaveformmodel,
  author        = {Abbott, Benjamin P. and others},
  title         = {Effects of waveform model systematics on the interpretation of GW150914},
  journal       = {Class. Quant. Grav.},
  year          = {2017},
  volume        = {34},
  number        = {10},
  pages         = {104002},
  archiveprefix = {arXiv},
  collaboration = {LIGO Scientific, Virgo},
  doi           = {10.1088/1361-6382/aa6854},
  eprint        = {1611.07531},
  primaryclass  = {gr-qc},
  reportnumber  = {P1500259},
}

@Article{2009Sathyaprakash-PhysicsAstrophysicsCosmology,
  author        = {Sathyaprakash, B. S. and Schutz, B. F.},
  title         = {Physics, Astrophysics and Cosmology with Gravitational Waves},
  journal       = {Living Rev. Rel.},
  year          = {2009},
  volume        = {12},
  pages         = {2},
  archiveprefix = {arXiv},
  doi           = {10.12942/lrr-2009-2},
  eprint        = {0903.0338},
  primaryclass  = {gr-qc},
}

@Article{2005Abbott-darkenergysurvey,
  author        = {Abbott, T. and others},
  title         = {The dark energy survey},
  year          = {2005},
  archiveprefix = {arXiv},
  collaboration = {DES},
  eprint        = {astro-ph/0510346},
  primaryclass  = {astro-ph},
  reportnumber  = {FERMILAB-PUB-05-656-A},
}

@Article{2009Abell-LSSTScienceBook,
  author        = {Abell, Paul A. and others},
  title         = {LSST Science Book, Version 2.0},
  year          = {2009},
  archiveprefix = {arXiv},
  collaboration = {LSST Science, LSST Project},
  eprint        = {0912.0201},
  primaryclass  = {astro-ph.IM},
  reportnumber  = {FERMILAB-TM-2495-A, SLAC-R-1031},
}

@Article{2018Amendola-Cosmologyfundamentalphysics,
  author        = {Amendola, Luca and others},
  title         = {Cosmology and fundamental physics with the Euclid satellite},
  journal       = {Living Rev. Rel.},
  year          = {2018},
  volume        = {21},
  number        = {1},
  pages         = {2},
  archiveprefix = {arXiv},
  doi           = {10.1007/s41114-017-0010-3},
  eprint        = {1606.00180},
  primaryclass  = {astro-ph.CO},
}

@Article{2013Amendola-Cosmologyfundamentalphysics,
  author        = {Amendola, Luca and others},
  title         = {Cosmology and fundamental physics with the Euclid satellite},
  journal       = {Living Rev. Rel.},
  year          = {2013},
  volume        = {16},
  pages         = {6},
  archiveprefix = {arXiv},
  collaboration = {Euclid Theory Working Group},
  doi           = {10.12942/lrr-2013-6},
  eprint        = {1206.1225},
  primaryclass  = {astro-ph.CO},
}

@Article{2013Spergel-WFIRST2.4What,
  author        = {Spergel, D. and others},
  title         = {WFIRST-2.4: What Every Astronomer Should Know},
  year          = {2013},
  archiveprefix = {arXiv},
  eprint        = {1305.5425},
  primaryclass  = {astro-ph.IM},
}

@Article{2013Spergel-WideFieldInfraRed,
  author        = {Spergel, D. and others},
  title         = {Wide-Field InfraRed Survey Telescope-Astrophysics Focused Telescope Assets WFIRST-AFTA Final Report},
  year          = {2013},
  archiveprefix = {arXiv},
  eprint        = {1305.5422},
  primaryclass  = {astro-ph.IM},
}

@InProceedings{2011Christensen-MultimessengerAstronomy,
  author        = {Christensen, N. L.},
  title         = {Multimessenger Astronomy},
  booktitle     = {Proceedings, 46\textsuperscript{th} Rencontres de Moriond on Gravitational Waves and Experimental Gravity: La Thuile, Italy, March 20-27, 2011},
  year          = {2011},
  pages         = {35--42},
  archiveprefix = {arXiv},
  collaboration = {LIGO Scientific, VIRGO},
  eprint        = {1105.5843},
  primaryclass  = {gr-qc},
  reportnumber  = {LIGO-DOCUMENT-NUMBER-P-1100053, LIGO Document Number P-1100053},
}

@Article{2013Smith-AstrophysicalMultimessengerObservatory,
  author        = {Smith, M. W. E. and others},
  title         = {The Astrophysical Multimessenger Observatory Network (AMON)},
  journal       = {Astropart. Phys.},
  year          = {2013},
  volume        = {45},
  pages         = {56--70},
  archiveprefix = {arXiv},
  doi           = {10.1016/j.astropartphys.2013.03.003},
  eprint        = {1211.5602},
  primaryclass  = {astro-ph.HE},
}

@Article{2009Rover-Bayesianreconstructiongravitational,
  author        = {Rover, Christian and Bizouard, Marie-Anne and Christensen, Nelson and Dimmelmeier, Harald and Heng, Ik Siong and Meyer, Renate},
  title         = {Bayesian reconstruction of gravitational wave burst signals from simulations of rotating stellar core collapse and bounce},
  journal       = {Phys. Rev.},
  year          = {2009},
  volume        = {D80},
  pages         = {102004},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.80.102004},
  eprint        = {0909.1093},
  primaryclass  = {gr-qc},
  reportnumber  = {LIGO-P0900089, AEI-2009-089},
}

@Article{2016Littenberg-Systematicerrorslow,
  author        = {Littenberg, Tyson B. and Farr, Ben and Coughlin, Scott and Kalogera, Vicky},
  title         = {Systematic errors in low latency gravitational wave parameter estimation impact electromagnetic follow-up observations},
  journal       = {Astrophys. J.},
  year          = {2016},
  volume        = {820},
  number        = {1},
  pages         = {7},
  archiveprefix = {arXiv},
  doi           = {10.3847/0004-637X/820/1/7},
  eprint        = {1601.02661},
  primaryclass  = {astro-ph.HE},
}

@Article{2016Usman-PyCBCsearchgravitational,
  author        = {Usman, Samantha A. and others},
  title         = {The PyCBC search for gravitational waves from compact binary coalescence},
  journal       = {Class. Quant. Grav.},
  year          = {2016},
  volume        = {33},
  number        = {21},
  pages         = {215004},
  archiveprefix = {arXiv},
  doi           = {10.1088/0264-9381/33/21/215004},
  eprint        = {1508.02357},
  file          = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:2016Usman-PyCBCsearchgravitational.pdf/\:PDF/\:/\:2016Usman-PyCBCsearchgravitational.pdf/\:PDF/\:PDF/\:/\:2016Usman-PyCBCsearchgravitational.pdf/\:PDF/\:/\:2016Usman-PyCBCsearchgravitational.pdf/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  primaryclass  = {gr-qc},
  reportnumber  = {LIGO-P1500086},
}

@Article{2017Huerta-Completewaveformmodel,
  author        = {Huerta, E. A. and others},
  title         = {Complete waveform model for compact binaries on eccentric orbits},
  journal       = {Phys. Rev.},
  year          = {2017},
  volume        = {D95},
  number        = {2},
  pages         = {024038},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.95.024038},
  eprint        = {1609.05933},
  primaryclass  = {gr-qc},
}

@Article{2016Tiwari-Proposedsearchdetection,
  author        = {Tiwari, V. and others},
  title         = {Proposed search for the detection of gravitational waves from eccentric binary black holes},
  journal       = {Phys. Rev.},
  year          = {2016},
  volume        = {D93},
  number        = {4},
  pages         = {043007},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.93.043007},
  eprint        = {1511.09240},
  primaryclass  = {gr-qc},
}

%%% contains utf-8, see: https://inspirehep.net/info/faq/general#utf8
%%% add \usepackage[utf8]{inputenc} to your latex preamble

@Article{2014Huerta-Accurateefficientwaveforms,
  author        = {Huerta, E. A. and Kumar, Prayush and McWilliams, Sean T. and O'Shaughnessy, Richard and Yunes, Nicol{\'{a}}s},
  title         = {Accurate and efficient waveforms for compact binaries on eccentric orbits},
  journal       = {Phys. Rev.},
  year          = {2014},
  volume        = {D90},
  number        = {8},
  pages         = {084016},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.90.084016},
  eprint        = {1408.3406},
  primaryclass  = {gr-qc},
}

@Article{2018Huerta-Eccentricnonspinninginspiral,
  author        = {Huerta, E. A. and others},
  title         = {Eccentric, nonspinning, inspiral, Gaussian-process merger approximant for the detection and characterization of eccentric binary black hole mergers},
  journal       = {Phys. Rev.},
  year          = {2018},
  volume        = {D97},
  number        = {2},
  pages         = {024031},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.97.024031},
  eprint        = {1711.06276},
  primaryclass  = {gr-qc},
}

@Article{2015Veitch-Parameterestimationcompact,
  author        = {Veitch, J. and others},
  title         = {Parameter estimation for compact binaries with ground-based gravitational-wave observations using the LALInference software library},
  journal       = {Phys. Rev.},
  year          = {2015},
  volume        = {D91},
  number        = {4},
  pages         = {042003},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.91.042003},
  eprint        = {1409.7215},
  primaryclass  = {gr-qc},
  reportnumber  = {LIGO-P1400152},
}

@DataSet{2016Wardell-SimulationGW150914binary,
  author    = {Wardell, Barry and Hinder, Ian and Bentivegna, Eloisa},
  doi       = {10.5281/zenodo.155394},
  month     = sep,
  publisher = {Zenodo},
  title     = {Simulation of GW150914 binary black hole merger using the Einstein Toolkit},
  year      = {2016},
}

@Article{2016Zevin-GravitySpyIntegrating,
  author        = {Zevin, Michael and Coughlin, Scott and Bahaadini, Sara and Besler, Emre and Rohani, Neda and Allen, Sarah and Cabero, Miriam and Crowston, Kevin and Katsaggelos, Aggelos K. and Larson, Shane L. and Lee, Tae Kyoung and Lintott, Chris and Littenberg, Tyson B. and Lundgren, Andrew and Oesterlund, Carsten and Smith, Joshua R. and Trouille, Laura and Kalogera, Vicky},
  title         = {Gravity Spy: Integrating Advanced LIGO Detector Characterization, Machine Learning, and Citizen Science},
  journal       = {Class. Quantum Grav. 34 (2017) 064003 (22pp)},
  year          = {2016},
  month         = nov,
  abstract      = {(abridged for arXiv) With the first direct detection of gravitational waves, the Advanced Laser Interferometer Gravitational-wave Observatory (LIGO) has initiated a new field of astronomy by providing an alternate means of sensing the universe. The extreme sensitivity required to make such detections is achieved through exquisite isolation of all sensitive components of LIGO from non-gravitational-wave disturbances. Nonetheless, LIGO is still susceptible to a variety of instrumental and environmental sources of noise that contaminate the data. Of particular concern are noise features known as glitches, which are transient and non-Gaussian in their nature, and occur at a high enough rate so that accidental coincidence between the two LIGO detectors is non-negligible. In this paper we describe an innovative project that combines crowdsourcing with machine learning to aid in the challenging task of categorizing all of the glitches recorded by the LIGO detectors. Through the Zooniverse platform, we engage and recruit volunteers from the public to categorize images of glitches into pre-identified morphological classes and to discover new classes that appear as the detectors evolve. In addition, machine learning algorithms are used to categorize images after being trained on human-classified examples of the morphological classes. Leveraging the strengths of both classification methods, we create a combined method with the aim of improving the efficiency and accuracy of each individual classifier. The resulting classification and characterization should help LIGO scientists to identify causes of glitches and subsequently eliminate them from the data or the detector entirely, thereby improving the rate and accuracy of gravitational-wave observations. We demonstrate these methods using a small subset of data from LIGO's first observing run.},
  archiveprefix = {arXiv},
  doi           = {10.1088/1361-6382/aa5cea},
  eprint        = {1611.04596v2},
  file          = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:1611.04596v2/\:PDF/\:PDF/\:1611.04596v2/\:PDF/\:/\:2016Zevin-GravitySpy_Integrating.pdf/\:PDF/\;online/\:http/\:/arxiv.org/pdf/1611.04596v2/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  keywords      = {gr-qc, astro-ph.HE, astro-ph.IM, physics.ins-det, skimmed},
  primaryclass  = {gr-qc},
}

@Book{2016Goodfellow-DeepLearning,
  title     = {Deep Learning},
  publisher = {The MIT Press},
  year      = {2016},
  author    = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  series    = {Adaptive Computation and Machine Learning series},
  isbn      = {9780262337373},
  url       = {https://www.amazon.com/Deep-Learning-Adaptive-Computation-Machine-ebook/dp/B01MRVFGX4?SubscriptionId=AKIAIOBINVZYXZQZ2U3A&tag=chimbori05-20&linkCode=xm2&camp=2025&creative=165953&creativeASIN=B01MRVFGX4},
}

@Article{2015LeCun-Deeplearning,
  author    = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  title     = {Deep learning},
  journal   = {nature},
  year      = {2015},
  volume    = {521},
  number    = {7553},
  pages     = {436--444},
  publisher = {Nature Publishing Group},
}

@InProceedings{2015Sharma-Comparativeanalysiszoning,
  author    = {Sharma, A. K. and Adhyaru, D. M. and Zaveri, T. H. and Thakkar, P. B.},
  booktitle = {Proc. 5\textsuperscript{th} Nirma University Int. Conf. Engineering (NUiCONE)},
  title     = {Comparative analysis of zoning based methods for Gujarati handwritten numeral recognition},
  year      = {2015},
  month     = nov,
  pages     = {1--5},
  abstract  = {Gujarati is one of the ancient Indian languages spoken widely by the people of Gujarat state. This paper is concerned with the recognition of handwritten Gujarati numerals. For recognition of Gujarati numerals zoning based Feature extraction method is used. Numeral image is divided in 16×16, 8×8, 4×4 and 2×2 Zones. After feature extraction through the zoning method, Naive Bayes classifier and multilayer feed forward neural network classifier are implemented for the classification of numerals. For the database generation, 14,000 samples of each numeral are used. The overall recognition rates of this method used for recognition of Gujarati numeral using 16×16, 8×8, 4×4 and 2×2 zoning with neural network are 93.03%, 95.92%, 91.89% and 61.78% and with Naive Bayes classifier are 75%, 85.60%, 81% and 53.75% respectively.},
  doi       = {10.1109/NUICONE.2015.7449632},
  issn      = {null},
  keywords  = {Bayes methods, feature extraction, feedforward neural nets, handwritten character recognition, image classification, comparative analysis, zoning based methods, Gujarati handwritten numeral recognition, feature extraction, numeral image, Naive Bayes classifier, multilayer feed forward neural network classifier, numerals classification, Feature extraction, Handwriting recognition, Neural networks, Databases, Character recognition, Classification algorithms, Optical character recognition software, Gujarati script, Neural networks, Naive Bayes classifier, Zone based feature extraction},
}

@Article{2015Najafabadi-Deeplearningapplications,
  author    = {Najafabadi, Maryam M. and Villanustre, Flavio and Khoshgoftaar, Taghi M. and Seliya, Naeem and Wald, Randall and Muharemagic, Edin},
  title     = {Deep learning applications and challenges in big data analytics},
  journal   = {Journal of Big Data},
  year      = {2015},
  volume    = {2},
  number    = {1},
  pages     = {1},
  publisher = {Springer},
}

%%% contains utf-8, see: https://inspirehep.net/info/faq/general#utf8
%%% add \usepackage[utf8]{inputenc} to your latex preamble

@InCollection{2017Tiec-TheoryGravitationalWaves,
  author        = {Tiec, Alexandre Le and Novak, J'erome},
  title         = {Theory of Gravitational Waves},
  booktitle     = {An Overview of Gravitational Waves: Theory, Sources and Detection},
  year          = {2017},
  editor        = {Auger, Gerard and Plagnol, Eric},
  pages         = {1--41},
  archiveprefix = {arXiv},
  eprint        = {1607.04202},
  primaryclass  = {gr-qc},
}

@Article{2017Cao-Waveformmodeleccentric,
  author        = {Cao, Zhoujian and Han, Wen-Biao},
  title         = {Waveform model for an eccentric binary black hole based on the effective-one-body-numerical-relativity formalism},
  journal       = {Phys. Rev.},
  year          = {2017},
  volume        = {D96},
  number        = {4},
  pages         = {044028},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.96.044028},
  eprint        = {1708.00166},
  primaryclass  = {gr-qc},
}

@Article{2019Chua-Reducedordermodeling,
  author        = {Chua, Alvin J. K. and Galley, Chad R. and Vallisneri, Michele},
  title         = {Reduced-order modeling with artificial neurons for gravitational-wave inference},
  journal       = {Phys. Rev. Lett.},
  year          = {2019},
  volume        = {122},
  number        = {21},
  pages         = {211101},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevLett.122.211101},
  eprint        = {1811.05491},
  primaryclass  = {astro-ph.IM},
}

@Article{2018Rebei-Fusingnumericalrelativity,
  author        = {Rebei, Adam and Huerta, E. A. and Wang, Sibo and Habib, Sarah and Haas, Roland and Johnson, Daniel and George, Daniel},
  journal       = {Phys. Rev. D 100, 044025 (2019)},
  title         = {Fusing numerical relativity and deep learning to detect higher-order multipole waveforms from eccentric binary black hole mergers},
  year          = {2018},
  month         = jul,
  abstract      = {We determine the mass-ratio, eccentricity and binary inclination angles that maximize the contribution of the higher-order waveform multipoles (ℓ, |m|)= (2, 2), (2, 1), (3, 3), (3, 2), (3, 1), (4, 4), (4, 3), (4, 2), (4, 1) for the gravitational wave detection of eccentric binary black hole mergers. We carry out this study using numerical relativity waveforms that describe non-spinning black hole binaries with mass-ratios 1≤ q ≤ 10, and orbital eccentricities as high as e_0=0.18 fifteen cycles before merger. For stellar-mass, asymmetric mass-ratio, binary black hole mergers, and assuming LIGO's Zero Detuned High Power configuration, we find that in regions of parameter space where black hole mergers modeled with ℓ=|m|=2 waveforms have vanishing signal-to-noise ratios, the inclusion of (ℓ, |m|) modes enables the observation of these sources with signal-to-noise ratios that range between 30% to 45% the signal-to-noise ratio of optimally oriented binary black hole mergers modeled with ℓ=|m|=2 numerical relativity waveforms. Having determined the parameter space where (ℓ, |m|) modes are important for gravitational wave detection, we construct waveform signals that describe these astrophysically motivate scenarios, and demonstrate that these topologically complex signals can be detected and characterized in real LIGO noise with deep learning algorithms.},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.100.044025},
  eprint        = {http://arxiv.org/abs/1807.09787v2},
  file          = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:1807.09787v2/\:PDF/\:PDF/\:1807.09787v2/\:PDF/\:/\:2018Rebei-Fusingnumericalrelativity.pdf/\:PDF/\;/\:http/\:/arxiv.org/pdf/1807.09787v2/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  keywords      = {gr-qc, astro-ph.HE, physics.comp-ph, J.2},
  primaryclass  = {gr-qc},
}

@Article{2019Chua-LearningBayestheorem,
  author        = {Chua, Alvin J. K. and Vallisneri, Michele},
  title         = {Learning Bayes' theorem with a neural network for gravitational-wave inference},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1909.05966},
  primaryclass  = {gr-qc},
}

%%% contains utf-8, see: https://inspirehep.net/info/faq/general#utf8
%%% add \usepackage[utf8]{inputenc} to your latex preamble

@Article{2019Setyawati-Regressionmethodswaveform,
  author        = {Setyawati, Yoshinta and P{\"{u}}rrer, Michael and Ohme, Frank},
  title         = {Regression methods in waveform modeling: a comparative study},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1909.10986},
  primaryclass  = {astro-ph.IM},
}

@Article{2020Akutsu-statusKAGRAunderground,
  author        = {Akutsu, T. and others},
  title         = {The status of KAGRA underground cryogenic gravitational wave telescope},
  journal       = {J. Phys. Conf. Ser.},
  year          = {2020},
  volume        = {1342},
  number        = {1},
  pages         = {012014},
  archiveprefix = {arXiv},
  booktitle     = {Proceedings, 15\textsuperscript{th} International Conference on Topics in Astroparticle and Underground Physics (TAUP 2017): Sudbury, Ontario, Canada, July 24-28, 2017},
  collaboration = {KAGRA},
  doi           = {10.1088/1742-6596/1342/1/012014},
  eprint        = {1710.04823},
  primaryclass  = {gr-qc},
  reportnumber  = {JGW-P1707191},
}

%%% contains utf-8, see: https://inspirehep.net/info/faq/general#utf8
%%% add \usepackage[utf8]{inputenc} to your latex preamble

@Article{2013ChassandeMottin-Dataanalysischallenges,
  author        = {Chassande-Mottin, {{\'{E}}}ric},
  journal       = {AIP Conf. Proc.},
  title         = {Data analysis challenges in transient gravitational-wave astronomy},
  year          = {2013},
  number        = {1},
  pages         = {252},
  volume        = {1535},
  archiveprefix = {arXiv},
  booktitle     = {Proceedings, 5\textsuperscript{th} International Workshop on Acoustic and Radio EeV Neutrino Detection Activities (ARENA 2012): Erlangen, Germany, June 29-July 2, 2012},
  collaboration = {LIGO Scientific, VIRGO},
  doi           = {10.1063/1.4807558},
  eprint        = {1210.7173},
  primaryclass  = {gr-qc},
  reportnumber  = {LIGO-P1200135, VIR-0379C-12, LIGO-P1200135; VIR-0379C-12},
}

@Article{2016Gibney-Successfultestdrive,
  author  = {Gibney, Elizabeth},
  title   = {Successful test drive for space-based gravitational-wave detector},
  journal = {Nature News},
  year    = {2016},
  volume  = {531},
  number  = {7592},
  pages   = {30},
}

@Article{2011Gong-scientificcasestudy,
  author    = {Gong, Xuefei and Xu, Shengnian and Bai, Shan and Cao, Zhoujian and Chen, Gerui and Chen, Yanbei and He, Xiaokai and Heinzel, Gerhard and Lau, Yun-Kau and Liu, Chenzhou and others},
  title     = {A scientific case study of an advanced LISA mission},
  journal   = {Classical and Quantum Gravity},
  year      = {2011},
  volume    = {28},
  number    = {9},
  pages     = {094012},
  publisher = {IOP Publishing},
}

@Article{2017Hu-TaijiProgramSpace,
  author  = {Hu, Wen-Rui and Wu, Yue-Liang},
  journal = {Natl. Sci. Rev.},
  title   = {The Taiji Program in Space for Gravitational Wave Physics and the Nature of Gravity},
  year    = {2017},
  number  = {5},
  pages   = {685--686},
  volume  = {4},
  doi     = {10.1093/nsr/nwx116},
}

@Article{2016Luo-TianQinspaceborne,
  author        = {Luo, Jun and others},
  title         = {TianQin: a space-borne gravitational wave detector},
  journal       = {Class. Quant. Grav.},
  year          = {2016},
  volume        = {33},
  number        = {3},
  pages         = {035010},
  archiveprefix = {arXiv},
  collaboration = {TianQin},
  doi           = {10.1088/0264-9381/33/3/035010},
  eprint        = {1512.02076},
  primaryclass  = {astro-ph.IM},
}

@Article{2015Moore-Gravitationalwavesensitivity,
  author        = {Moore, C. J. and Cole, R. H. and Berry, C. P. L.},
  title         = {Gravitational-wave sensitivity curves},
  journal       = {Class. Quant. Grav.},
  year          = {2015},
  volume        = {32},
  number        = {1},
  pages         = {015014},
  archiveprefix = {arXiv},
  doi           = {10.1088/0264-9381/32/1/015014},
  eprint        = {1408.0740},
  primaryclass  = {gr-qc},
  reportnumber  = {LIGO-P1400129},
}

@Article{2012Hild-SecondGenerationLaser,
  author        = {Hild, S.},
  title         = {Beyond the Second Generation of Laser-Interferometric Gravitational Wave Observatories},
  journal       = {Class. Quant. Grav.},
  year          = {2012},
  volume        = {29},
  pages         = {124006},
  archiveprefix = {arXiv},
  booktitle     = {Gravitational waves. Numerical relativity - data analysis. Proceedings, 9\textsuperscript{th} Edoardo Amaldi Conference, Amaldi 9, and meeting, NRDA 2011, Cardiff, UK, July 10-15, 2011},
  doi           = {10.1088/0264-9381/29/12/124006},
  eprint        = {1111.6277},
  primaryclass  = {gr-qc},
}

@Article{2019Colgan-EfficientGravitationalwave,
  author        = {Colgan, Robert E. and Corley, K. Rainer and Lau, Yenson and Bartos, Imre and Wright, John N. and Marka, Zsuzsa and Marka, Szabolcs},
  title         = {Efficient Gravitational-wave Glitch Identification from Environmental Data Through Machine Learning},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1911.11831},
  primaryclass  = {astro-ph.IM},
}

@Article{2015Vallisneri-LIGOOpenScience,
  author        = {Vallisneri, Michele and Kanner, Jonah and Williams, Roy and Weinstein, Alan and Stephens, Branson},
  title         = {The LIGO Open Science Center},
  journal       = {J. Phys. Conf. Ser.},
  year          = {2015},
  volume        = {610},
  number        = {1},
  pages         = {012021},
  archiveprefix = {arXiv},
  booktitle     = {Proceedings, 10\textsuperscript{th} International LISA Symposium: Gainesville, Florida, USA, May 18-23, 2014},
  doi           = {10.1088/1742-6596/610/1/012021},
  eprint        = {1410.4839},
  primaryclass  = {gr-qc},
}

@Article{2019Collaboration-GuideLIGOVirgo,
  author         = {Collaboration, The L. I. G. O. Scientific and Collaboration, The Virgo},
  title          = {A Guide to LIGO-Virgo Detector Noise and Extraction of Transient Gravitational-wave Signals},
  year           = {2019},
  month          = aug,
  abstract       = {The LIGO Scientific Collaboration and the Virgo Collaboration have cataloged eleven confidently detected gravitational-wave events during the first two observing runs of the advanced detector era. All eleven events were consistent with being from well-modeled mergers between compact stellar-mass objects: black holes or neutron stars. The data around the time of each of these events have been made publicly available through the Gravitational-Wave Open Science Center. The entirety of the gravitational-wave strain data from the first and second observing runs have also now been made publicly available. There is considerable interest among the broad scientific community in understanding the data and methods used in the analyses. In this paper, we provide an overview of the detector noise properties and the data analysis techniques used to detect gravitational-wave signals and infer the source properties. We describe some of the checks that are performed to validate the analyses and results from the observations of gravitational-wave events. We also address concerns that have been raised about various properties of LIGO-Virgo detector noise and the correctness of our analyses as applied to the resulting data.},
  archiveprefix  = {arXiv},
  eprint         = {http://arxiv.org/abs/1908.11170v1},
  file           = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:1908.11170v1/\:PDF/\:PDF/\:1908.11170v1/\:PDF/\:/\:2019Collaboration-GuideLIGOVirgo.pdf/\:PDF/\;/\:http/\:/arxiv.org/pdf/1908.11170v1/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  keywords       = {gr-qc, astro-ph.IM, relevant, qualityAssured},
  primaryclass   = {gr-qc},
}

@Article{2008Klimenko-Coherentmethoddetection,
  author        = {Klimenko, S. and Yakushin, I. and Mercer, A. and Mitselmakher, Guenakh},
  title         = {Coherent method for detection of gravitational wave bursts},
  journal       = {Class. Quant. Grav.},
  year          = {2008},
  volume        = {25},
  pages         = {114029},
  archiveprefix = {arXiv},
  booktitle     = {Proceedings, 18\textsuperscript{th} International Conference on General Relativity and Gravitation (GRG18) and 7\textsuperscript{th} Edoardo Amaldi Conference on Gravitational Waves (Amaldi7), Sydney, Australia, July 2007},
  doi           = {10.1088/0264-9381/25/11/114029},
  eprint        = {0802.3232},
  file          = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:2008Klimenko-Coherentmethoddetection.pdf/\:PDF/\:/\:2008Klimenko-Coherentmethoddetection.pdf/\:PDF/\:PDF/\:/\:2008Klimenko-Coherentmethoddetection.pdf/\:PDF/\:/\:2008Klimenko-Coherentmethoddetection.pdf/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  primaryclass  = {gr-qc},
  reportnumber  = {LIGO-P070093-00-Z},
}

@Misc{2020Nitz-gwastro/pycbcPyCBCRelease,
  author    = {Nitz, Alex and Harry, Ian and Brown, Duncan and Biwer, Christopher M. and Willis, Josh and Canton, Tito Dal and Capano, Collin and Pekowsky, Larne and Dent, Thomas and Williamson, Andrew R. and De, Soumi and Davies, Gareth and Cabero, Miriam and Macleod, Duncan and Machenschalk, Bernd and Reyes, Steven and Kumar, Prayush and Massinger, Thomas and Pannarale, Francesco and Dfinstad and T{\'{a}}pai, M{\'{a}}rton and Fairhurst, Stephen and Khan, Sebastian and Singer, Leo and Kumar, Sumit and Nielsen, Alex and Shasvath and Idorrington92 and Lenon, Amber and Gabbard, Hunter},
  title     = {gwastro/pycbc: PyCBC Release v1.15.4},
  year      = {2020},
  doi       = {10.5281/ZENODO.596388},
  publisher = {Zenodo},
}

@Article{2017Messick-AnalysisFrameworkPrompt,
  author        = {Messick, Cody and others},
  title         = {Analysis Framework for the Prompt Discovery of Compact Binary Mergers in Gravitational-wave Data},
  journal       = {Phys. Rev.},
  year          = {2017},
  volume        = {D95},
  number        = {4},
  pages         = {042001},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.95.042001},
  eprint        = {1604.04324},
  file          = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:2017Messick-AnalysisFrameworkPrompt.pdf/\:PDF/\:/\:2017Messick-AnalysisFrameworkPrompt.pdf/\:PDF/\:PDF/\:/\:2017Messick-AnalysisFrameworkPrompt.pdf/\:PDF/\:/\:2017Messick-AnalysisFrameworkPrompt.pdf/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  primaryclass  = {astro-ph.IM},
}

@Article{2017Romano-Detectionmethodsstochastic,
  author        = {Romano, Joseph D. and Cornish, Neil J.},
  title         = {Detection methods for stochastic gravitational-wave backgrounds: a unified treatment},
  journal       = {Living Rev. Rel.},
  year          = {2017},
  volume        = {20},
  number        = {1},
  pages         = {2},
  archiveprefix = {arXiv},
  doi           = {10.1007/s41114-017-0004-1},
  eprint        = {1608.06889},
  file          = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:2017Romano-Detectionmethodsstochastic.pdf/\:PDF/\;/\:1608.06889.pdf/\:PDF/\:/\:2017Romano-Detectionmethodsstochastic.pdf/\:PDF/\;/\:1608.06889.pdf/\:PDF/\:PDF/\:/\:2017Romano-Detectionmethodsstochastic.pdf/\:PDF/\;/\:1608.06889.pdf/\:PDF/\:/\:2017Romano-Detectionmethodsstochastic.pdf/\:PDF/\;/\:1608.06889.pdf/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  primaryclass  = {gr-qc},
}

@Article{2001Cuoco-linepowerspectra,
  author        = {Cuoco, Elena and Fabbroni, Leonardo and Mazzoni, Massimo and Stanga, Ruggero and Calamai, Giovanni and Losurdo, Giovanni and Vetrano, Flavio},
  title         = {On line power spectra identification and whitening for the noise in interferometric gravitational wave detectors},
  journal       = {Class. Quant. Grav.},
  year          = {2001},
  volume        = {18},
  pages         = {1727--1752},
  archiveprefix = {arXiv},
  doi           = {10.1088/0264-9381/18/9/309},
  eprint        = {gr-qc/0011041},
  file          = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:2001Cuoco-linepowerspectra.pdf/\:PDF/\:/\:2001Cuoco-linepowerspectra.pdf/\:PDF/\:PDF/\:/\:2001Cuoco-linepowerspectra.pdf/\:PDF/\:/\:2001Cuoco-linepowerspectra.pdf/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  primaryclass  = {gr-qc},
}

@Article{2001Cuoco-Noiseparametricidentification,
  author        = {Cuoco, Elena and Losurdo, Giovanni and Calamai, Giovanni and Fabbroni, Leonardo and Mazzoni, Massimo and Stanga, Ruggero and Guidi, Gianluca and Vetrano, Flavio},
  title         = {Noise parametric identification and whitening for LIGO 40-meter interferometer data},
  journal       = {Phys. Rev.},
  year          = {2001},
  volume        = {D64},
  pages         = {122002},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.64.122002},
  eprint        = {gr-qc/0104071},
  primaryclass  = {gr-qc},
}

@Article{2018Tsukada-ApplicationZerolatency,
  author        = {Tsukada, Leo and Cannon, Kipp and Hanna, Chad and Keppel, Drew and Meacher, Duncan and Messick, Cody},
  title         = {Application of a Zero-latency Whitening Filter to Compact Binary Coalescence Gravitational-wave Searches},
  journal       = {Phys. Rev.},
  year          = {2018},
  volume        = {D97},
  number        = {10},
  pages         = {103009},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.97.103009},
  eprint        = {1708.04125},
  primaryclass  = {astro-ph.IM},
}

@Article{2010Abadie-SearchGravitationalWaves,
  author        = {Abadie, J. and others},
  journal       = {Phys. Rev.},
  title         = {Search for Gravitational Waves from Compact Binary Coalescence in LIGO and Virgo Data from S5 and VSR1},
  year          = {2010},
  pages         = {102001},
  volume        = {D82},
  archiveprefix = {arXiv},
  collaboration = {LIGO Scientific, VIRGO},
  doi           = {10.1103/PhysRevD.85.089903,10.1103/PhysRevD.82.102001},
  eprint        = {1005.4655},
  primaryclass  = {gr-qc},
}

@Article{2013Aasi-Parameterestimationcompact,
  author        = {Aasi, J. and others},
  title         = {Parameter estimation for compact binary coalescence signals with the first generation gravitational-wave detector network},
  journal       = {Phys. Rev.},
  year          = {2013},
  volume        = {D88},
  pages         = {062001},
  archiveprefix = {arXiv},
  collaboration = {LIGO Scientific, VIRGO},
  doi           = {10.1103/PhysRevD.88.062001},
  eprint        = {1304.1775},
  primaryclass  = {gr-qc},
}

@Article{2000Finn-gravitationalwavedetection,
  author        = {Finn, L. S. and Gonzalez, G. and Hough, J. and Huq, M. F. and Mohanty, S. and Romano, Joseph D. and Rowan, S. and Saulson, Peter R. and Strain, K. A.},
  title         = {Toward gravitational wave detection},
  journal       = {AIP Conf. Proc.},
  year          = {2000},
  volume        = {523},
  number        = {1},
  pages         = {451--458},
  archiveprefix = {arXiv},
  booktitle     = {Gravitational waves. Proceedings, 3\textsuperscript{rd} Edoardo Amaldi Conference, Pasadena, USA, July 12-16, 1999},
  doi           = {10.1063/1.1291910},
  eprint        = {gr-qc/9911001},
  primaryclass  = {gr-qc},
}

@Thesis{2013Baker-Distinguishingsignalnoise,
  author         = {Baker, Paul Thomas},
  title          = {Distinguishing signal from noise: New techniques for gravitational wave data analysis},
  year           = {2013},
  abstract       = {The principal problem of gravitational wave detection is distinguishing true gravitational wave signals from non-Gaussian noise artifacts. We describe two methods to deal with the problem of non-Gaussian noise in the Laser Interferometer Gravitational Observatory (LIGO). Perturbed black holes (BH) are known to vibrate at determinable quasi-normal mode frequencies. These vibrational modes are strongly excited during the inspiral and merger of binary BH systems. We will develop a template based search for gravitational waves from black hole ringdowns: the final stage of binary merger. Past searches for gravitational waves developed ad hoc detection statistics in an attempt to separate the expected gravitational wave signals from noise. We show how using the output of a multi-variate statistical classifier trained to directly probe the high dimensional parameter space of gravitational waves can improve a search over more traditional means. We conclude by placing preliminary upper limits on the rate of ringdown producing binary BH mergers. LIGO data contains frequent, non-Gaussian, instrument artifacts or glitches. Current LIGO searches for un-modeled gravitational wave bursts are primarily limited by the presence of glitches in analyzed data. We describe the BayesWave algorithm, wherein we model gravitational wave signals and detector glitches simultaneously in the wavelet domain. Using bayesian model selection techniques and a reversible jump Markov chain Monte Carlo, we are able determine whether data is consistent with the presence of gravitational waves, detector glitches, or both. We demonstrate BayesWave's utility as a data quality tool by fitting glitches non-Gaussian LIGO data. Finally, we discuss how BayesWave can be extended into a full-fledged search for gravitational wave bursts.},
  file           = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:2013Baker-Distinguishingsignalnoise.pdf/\:PDF/\:/\:2013Baker-Distinguishingsignalnoise.pdf/\:PDF/\:PDF/\:/\:2013Baker-Distinguishingsignalnoise.pdf/\:PDF/\:/\:2013Baker-Distinguishingsignalnoise.pdf/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  keywords       = {relevant, qualityAssured},
  language       = {eng},
  school         = {Montana State University - Bozeman, College of Letters \& Science},
  type           = {phdthesis},
  url            = {https://scholarworks.montana.edu/xmlui/handle/1/2911},
}

@Article{2010Was-Limitationstimeslide,
  author    = {Was, Michal and Bizouard, Marie-Anne and Brisson, Violette and Cavalier, Fabien and Davier, Michel and Hello, Patrice and Leroy, Nicolas and Robinet, Florent and Vavoulidis, Miltiadis},
  title     = {Limitations of the time slide method of background estimation},
  journal   = {Class. Quant. Grav.},
  year      = {2010},
  volume    = {27},
  pages     = {194014},
  booktitle = {Proceedings, 14\textsuperscript{th} Workshop on Gravitational wave data analysis (GWDAW-14): Rome, Italy, January 26-29, 2010},
  doi       = {10.1088/0264-9381/27/19/194014},
  file      = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:2010Was-Limitationstimeslide.pdf/\:PDF/\:/\:2010Was-Limitationstimeslide.pdf/\:PDF/\:PDF/\:/\:2010Was-Limitationstimeslide.pdf/\:PDF/\:/\:2010Was-Limitationstimeslide.pdf/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
}

@Article{2015Littenberg-Bayesianinferencespectral,
  author        = {Littenberg, Tyson B. and Cornish, Neil J.},
  title         = {Bayesian inference for spectral estimation of gravitational wave detector noise},
  journal       = {Phys. Rev.},
  year          = {2015},
  volume        = {D91},
  number        = {8},
  pages         = {084034},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.91.084034},
  eprint        = {1410.3852},
  file          = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:2015Littenberg-Bayesianinferencespectral.pdf/\:PDF/\:/\:2015Littenberg-Bayesianinferencespectral.pdf/\:PDF/\:PDF/\:/\:2015Littenberg-Bayesianinferencespectral.pdf/\:PDF/\:/\:2015Littenberg-Bayesianinferencespectral.pdf/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  primaryclass  = {gr-qc},
}

@PhdThesis{2015Hoak-GravitationalWaveAstrophysics,
  author   = {Hoak, Daniel},
  title    = {Gravitational Wave Astrophysics: Instrumentation, Detector Characterization, and a Search for Gravitational Signals from Gamma-ray Bursts},
  school   = {University of Massachusetts},
  year     = {2015},
  type     = {phdthesis},
  month    = sep,
  abstract = {In the coming years, the second generation of interferometric gravitational wave detectors are widely expected to observe the gravitational radiation emitted by compact, energetic events in the nearby universe. The field of gravitational wave astrophysics has grown into a large international endeavor with a global network of kilometer-scale observatories. The work presented in this thesis spans the field, from optical metrology, to instrument commissioning, to detector characterization and data analysis. The principal results are a method for the precise characterization of optical cavities, the commissioning of the advanced LIGO Output Mode Cleaner at the Hanford observatory, and a search for gravitational waves associated with gamma-ray bursts.},
  url      = {https://scholarworks.umass.edu/dissertations_2/498},
}

@Book{2011Creighton-Gravitationalwavephysics,
  title   = {Gravitational-wave physics and astronomy: An introduction to theory, experiment and data analysis},
  year    = {2011},
  author  = {Creighton, Jolien D. E. and Anderson, Warren G.},
  journal = {Weinheim, Germany: Wiley-VCH (2011) 375 p},
  url     = {http://www.wiley-vch.de/publish/dt/books/ISBN3-527-40886-X},
}

@Article{2015Schmidhuber-Deeplearningneural,
  author   = {Schmidhuber, J{\"{u}}rgen},
  journal  = {Neural Networks},
  title    = {Deep learning in neural networks: An overview},
  year     = {2015},
  issn     = {0893-6080},
  pages    = {85--117},
  volume   = {61},
  abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning & evolutionary computation, and indirect search for short programs encoding deep and large networks.},
  doi      = {10.1016/j.neunet.2014.09.003},
  keywords = {Deep learning, Supervised learning, Unsupervised learning, Reinforcement learning, Evolutionary computation},
  url      = {http://www.sciencedirect.com/science/article/pii/S0893608014002135},
}

@Article{2013Bengio-RepresentationLearningReview,
  author   = {Bengio, Y. and Courville, A. and Vincent, P.},
  title    = {Representation Learning: A Review and New Perspectives},
  journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year     = {2013},
  volume   = {35},
  number   = {8},
  pages    = {1798--1828},
  month    = aug,
  issn     = {1939-3539},
  abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning.},
  doi      = {10.1109/TPAMI.2013.50},
  keywords = {artificial intelligence, data structures, probability, unsupervised learning, representation learning, machine learning algorithms, data representation, AI, unsupervised feature learning, probabilistic models, autoencoders, manifold learning, geometrical connections, density estimation, Learning systems, Machine learning, Abstracts, Feature extraction, Manifolds, Neural networks, Speech recognition, Deep learning, representation learning, feature learning, unsupervised learning, Boltzmann machine, autoencoder, neural nets, Algorithms, Artificial Intelligence, Humans, Neural Networks (Computer)},
}

@Article{2016Oord-WaveNetGenerativeModel,
  author        = {Oord, Aaron van den and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
  title         = {WaveNet: A Generative Model for Raw Audio},
  year          = {2016},
  archiveprefix = {arXiv},
  eprint        = {1609.03499},
  primaryclass  = {cs.SD},
}

@Book{1998Sutton-IntroductionReinforcementLearning,
  title     = {Introduction to Reinforcement Learning},
  publisher = {MIT Press},
  year      = {1998},
  author    = {Sutton, Richard S. and Barto, Andrew G.},
  address   = {Cambridge, MA, USA},
  edition   = {1\textsuperscript{st}},
  isbn      = {0262193981},
}

@InProceedings{2017Chung-LipReadingSentences,
  author    = {Chung, J. S. and Senior, A. and Vinyals, O. and Zisserman, A.},
  title     = {Lip Reading Sentences in the Wild},
  booktitle = {Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR)},
  year      = {2017},
  pages     = {3444--3453},
  month     = jul,
  abstract  = {The goal of this work is to recognise phrases and sentences being spoken by a talking face, with or without the audio. Unlike previous works that have focussed on recognising a limited number of words or phrases, we tackle lip reading as an open-world problem - unconstrained natural language sentences, and in the wild videos. Our key contributions are: (1) a `Watch, Listen, Attend and Spell' (WLAS) network that learns to transcribe videos of mouth motion to characters; (2) a curriculum learning strategy to accelerate training and to reduce overfitting; (3) a `Lip Reading Sentences' (LRS) dataset for visual speech recognition, consisting of over 100,000 natural sentences from British television. The WLAS model trained on the LRS dataset surpasses the performance of all previous work on standard lip reading benchmark datasets, often by a significant margin. This lip reading performance beats a professional lip reader on videos from BBC television, and we also demonstrate that if audio is available, then visual information helps to improve speech recognition performance.},
  doi       = {10.1109/CVPR.2017.367},
  issn      = {1063-6919},
  keywords  = {audio-visual systems, learning (artificial intelligence), natural language processing, speech recognition, video signal processing, WLAS model, LRS dataset, standard lip reading benchmark datasets, lip reading performance, professional lip reader, speech recognition performance, open-world problem, unconstrained natural language sentences, wild videos, mouth motion, curriculum learning strategy, visual speech recognition, British television, watch, listen, attend and spell network, Lips, Visualization, Speech recognition, Decoding, Training, Face, Videos},
}

@Book{2013Daniel-PrinciplesArtificialNeural,
  title     = {Principles Of Artificial Neural Networks (3\textsuperscript{rd} Edition)},
  publisher = {World Scientific Publishing Company},
  year      = {2013},
  author    = {Daniel, G.},
  series    = {Advanced Series In Circuits And Systems},
  isbn      = {9789814522755},
  url       = {https://books.google.com/books?id=Zz27CgAAQBAJ},
}

@Article{1958Rosenblatt-perceptronprobabilisticmodel,
  author    = {Rosenblatt, Frank},
  title     = {The perceptron: a probabilistic model for information storage and organization in the brain.},
  journal   = {Psychological review},
  year      = {1958},
  volume    = {65},
  number    = {6},
  pages     = {386},
  publisher = {American Psychological Association},
}

@Book{2017Minsky-PerceptronsIntroductionComputational,
  title     = {Perceptrons: An Introduction to Computational Geometry},
  publisher = {MIT Press},
  year      = {2017},
  author    = {Minsky, M. and Papert, S. A. and Bottou, L.},
  series    = {The MIT Press},
  isbn      = {9780262534772},
  lccn      = {2017014248},
  url       = {https://books.google.com/books?id=PLQ5DwAAQBAJ},
}

@Article{1990Hornik-Universalapproximationunknown,
  author   = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  journal  = {Neural Networks},
  title    = {Universal approximation of an unknown mapping and its derivatives using multilayer feedforward networks},
  year     = {1990},
  issn     = {0893-6080},
  number   = {5},
  pages    = {551--560},
  volume   = {3},
  abstract = {We give conditions ensuring that multilayer feedforward networks with as few as a single hidden layer and an appropriately smooth hidden layer activation function are capable of arbitrarily accurate approximation to an arbitrary function and its derivatives. In fact, these networks can approximate functions that are not differentiable in the classical sense, but possess only a generalized derivative, as is the case for certain piecewise differentiable functions. The conditions imposed on the hidden layer activation function are relatively mild; the conditions imposed on the domain of the function to be approximated have practical implications. Our approximation results provide a previously missing theoretical justification for the use of multilayer feedforward networks in applications requiring simultaneous approximation of a function and its derivatives.},
  doi      = {10.1016/0893-6080(90)90005-6},
  keywords = {Approximation, Derivatives, Sobolev space, Feedforward networks},
  url      = {http://www.sciencedirect.com/science/article/pii/0893608090900056},
}

@InProceedings{2009Jarrett-Whatisbest,
  author    = {Jarrett, K. and Kavukcuoglu, K. and Ranzato, M. and LeCun, Y.},
  booktitle = {Proc. IEEE 12\textsuperscript{th} Int. Conf. Computer Vision},
  title     = {What is the best multi-stage architecture for object recognition?},
  year      = {2009},
  month     = sep,
  pages     = {2146--2153},
  abstract  = {In many recent object recognition systems, feature extraction stages are generally composed of a filter bank, a non-linear transformation, and some sort of feature pooling layer. Most systems use only one stage of feature extraction in which the filters are hard-wired, or two stages where the filters in one or both stages are learned in supervised or unsupervised mode. This paper addresses three questions: 1. How does the non-linearities that follow the filter banks influence the recognition accuracy? 2. does learning the filter banks in an unsupervised or supervised manner improve the performance over random filters or hardwired filters? 3. Is there any advantage to using an architecture with two stages of feature extraction, rather than one? We show that using non-linearities that include rectification and local contrast normalization is the single most important ingredient for good accuracy on object recognition benchmarks. We show that two stages of feature extraction yield better accuracy than one. Most surprisingly, we show that a two-stage system with random filters can yield almost 63% recognition rate on Caltech-101, provided that the proper non-linearities and pooling layers are used. Finally, we show that with supervised refinement, the system achieves state-of-the-art performance on NORB dataset (5.6%) and unsupervised pre-training followed by supervised refinement produces good accuracy on Caltech-101 (> 65%), and the lowest known error rate on the undistorted, unprocessed MNIST dataset (0.53%).},
  doi       = {10.1109/ICCV.2009.5459469},
  issn      = {1550-5499},
  keywords  = {feature extraction, object recognition, unsupervised learning, multistage architecture, object recognition, feature extraction, filter bank, nonlinear transformation, feature pooling layer, unsupervised learning, supervised learning, feature rectification, local contrast normalization, Caltech-101, NORB dataset, unprocessed MNIST dataset, Object recognition, Filter bank, Feature extraction, Refining, Brain modeling, Gabor filters, Learning systems, Image edge detection, Error analysis, Histograms},
}

@InBook{2012LeCun-EfficientBackProp,
  author    = {LeCun, Yann A. and Bottou, L{\'e}on and Orr, Genevieve B. and M{\"u}ller, Klaus-Robert},
  editor    = {Montavon, Gr{\'e}goire and Orr, Genevi{\`e}ve B. and M{\"u}ller, Klaus-Robert},
  pages     = {9--48},
  publisher = {Springer Berlin Heidelberg},
  title     = {Efficient BackProp},
  year      = {2012},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-35289-8},
  abstract  = {The convergence of back-propagation learning is analyzed so as to explain common phenomenon observed by practitioners. Many undesirable behaviors of backprop can be avoided with tricks that are rarely exposed in serious technical publications. This paper gives some of those tricks, and offers explanations of why they work.},
  booktitle = {Neural Networks: Tricks of the Trade: Second Edition},
  doi       = {10.1007/978-3-642-35289-8_3},
}

@Article{2016Ruder-overviewgradientdescent,
  author        = {Ruder, Sebastian},
  title         = {An overview of gradient descent optimization algorithms},
  year          = {2016},
  archiveprefix = {arXiv},
  eprint        = {1609.04747},
  primaryclass  = {cs.LG},
}

@Article{2014Kingma-AdamMethodStochastic,
  author        = {Kingma, Diederik P. and Ba, Jimmy},
  title         = {Adam: A Method for Stochastic Optimization},
  year          = {2014},
  archiveprefix = {arXiv},
  eprint        = {1412.6980},
  primaryclass  = {cs.LG},
}

@Article{1988Kohonen-introductionneuralcomputing,
  author   = {Kohonen, Teuvo},
  journal  = {Neural Networks},
  title    = {An introduction to neural computing},
  year     = {1988},
  issn     = {0893-6080},
  number   = {1},
  pages    = {3--16},
  volume   = {1},
  abstract = {This article contains a brief survey of the motivations, fundamentals, and applications of artificial neural networks, as well as some detailed analytical expressions for their theory.},
  doi      = {10.1016/0893-6080(88)90020-2},
  keywords = {Neural computing, Neural networks, Adaptive systems, Learning machines, Pattern recognition},
  url      = {http://www.sciencedirect.com/science/article/pii/0893608088900202},
}

@Book{2016Zhou-MachineLearning,
  title     = {Machine Learning},
  publisher = {Tsinghua University Press},
  year      = {2016},
  author    = {Zhou, Zhihua},
  month     = jan,
  isbn      = {9787302423287},
  url       = {https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/MLbook2016.htm},
}

@Article{1980Fukushima-Neocognitronselforganizing,
  author   = {Fukushima, Kunihiko},
  journal  = {Biological Cybernetics},
  title    = {Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position},
  year     = {1980},
  issn     = {1432-0770},
  month    = apr,
  number   = {4},
  pages    = {193--202},
  volume   = {36},
  abstract = {A neural network model for a mechanism of visual pattern recognition is proposed in this paper. The network is self-organized by \textquotedblleftlearning without a teacher\textquotedblright, and acquires an ability to recognize stimulus patterns based on the geometrical similarity (Gestalt) of their shapes without affected by their positions. This network is given a nickname \textquotedblleftneocognitron\textquotedblright. After completion of self-organization, the network has a structure similar to the hierarchy model of the visual nervous system proposed by Hubel and Wiesel. The network consits of an input layer (photoreceptor array) followed by a cascade connection of a number of modular structures, each of which is composed of two layers of cells connected in a cascade. The first layer of each module consists of \textquotedblleftS-cells\textquotedblright, which show characteristics similar to simple cells or lower order hypercomplex cells, and the second layer consists of \textquotedblleftC-cells\textquotedblright similar to complex cells or higher order hypercomplex cells. The afferent synapses to each S-cell have plasticity and are modifiable. The network has an ability of unsupervised learning: We do not need any \textquotedblleftteacher\textquotedblright during the process of self-organization, and it is only needed to present a set of stimulus patterns repeatedly to the input layer of the network. The network has been simulated on a digital computer. After repetitive presentation of a set of stimulus patterns, each stimulus pattern has become to elicit an output only from one of the C-cell of the last layer, and conversely, this C-cell has become selectively responsive only to that stimulus pattern. That is, none of the C-cells of the last layer responds to more than one stimulus pattern. The response of the C-cells of the last layer is not affected by the pattern's position at all. Neither is it affected by a small change in shape nor in size of the stimulus pattern.},
  doi      = {10.1007/BF00344251},
  refid    = {Fukushima1980},
}

@InCollection{2012Krizhevsky-ImageNetClassificationDeep,
  author    = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  title     = {ImageNet Classification with Deep Convolutional Neural Networks},
  booktitle = {Advances in Neural Information Processing Systems 25},
  publisher = {Curran Associates, Inc.},
  year      = {2012},
  editor    = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
  pages     = {1097--1105},
  url       = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
}

%%% contains utf-8, see: https://inspirehep.net/info/faq/general#utf8
%%% add \usepackage[utf8]{inputenc} to your latex preamble

@InProceedings{2017Weitzel-DataAccessLIGO,
  author        = {Weitzel, Derek and Bockelman, Brian and Brown, Duncan A. and Couvares, Peter and W{\"{u}}rthwein, Frank and Fajardo Hernandez, Edgar},
  title         = {Data Access for LIGO on the OSG},
  year          = {2017},
  archiveprefix = {arXiv},
  doi           = {10.1145/3093338.3093363},
  eprint        = {1705.06202},
  primaryclass  = {cs.DC},
}

@Article{2015Yu-MultiScaleContext,
  author        = {Yu, Fisher and Koltun, Vladlen},
  title         = {Multi-Scale Context Aggregation by Dilated Convolutions},
  year          = {2015},
  month         = nov,
  abstract      = {State-of-the-art models for semantic segmentation are based on adaptations of convolutional networks that had originally been designed for image classification. However, dense prediction and image classification are structurally different. In this work, we develop a new convolutional network module that is specifically designed for dense prediction. The presented module uses dilated convolutions to systematically aggregate multi-scale contextual information without losing resolution. The architecture is based on the fact that dilated convolutions support exponential expansion of the receptive field without loss of resolution or coverage. We show that the presented context module increases the accuracy of state-of-the-art semantic segmentation systems. In addition, we examine the adaptation of image classification networks to dense prediction and show that simplifying the adapted network can increase accuracy.},
  archiveprefix = {arXiv},
  eprint        = {http://arxiv.org/abs/1511.07122v3},
  file          = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:1511.07122v3/\:PDF/\:PDF/\:1511.07122v3/\:PDF/\:/\:http/\:/arxiv.org/pdf/1511.07122v3/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  keywords      = {cs.CV},
  primaryclass  = {cs.CV},
}

@Article{1997Mitchell-Machinelearning.1997,
  author  = {Mitchell, Tom M. and others},
  title   = {Machine learning. 1997},
  journal = {Burr Ridge, IL: McGraw Hill},
  year    = {1997},
  volume  = {45},
  number  = {37},
  pages   = {870--877},
}

@Book{1996Bertsekas-Neurodynamicprogramming,
  title     = {Neuro-dynamic programming},
  publisher = {Athena Scientific},
  year      = {1996},
  author    = {Bertsekas, Dimitri P. and Tsitsiklis, John N.},
}

@Article{2013Mnih-PlayingAtariDeep,
  author        = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  title         = {Playing Atari with Deep Reinforcement Learning},
  year          = {2013},
  month         = dec,
  abstract      = {We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
  archiveprefix = {arXiv},
  eprint        = {http://arxiv.org/abs/1312.5602v1},
  file          = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:1312.5602v1/\:PDF/\:PDF/\:1312.5602v1/\:PDF/\:/\:http/\:/arxiv.org/pdf/1312.5602v1/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  keywords      = {cs.LG},
  primaryclass  = {cs.LG},
}

@Article{2019Nakkiran-DeepDoubleDescent,
  author        = {Nakkiran, Preetum and Kaplun, Gal and Bansal, Yamini and Yang, Tristan and Barak, Boaz and Sutskever, Ilya},
  title         = {Deep Double Descent: Where Bigger Models and More Data Hurt},
  year          = {2019},
  month         = dec,
  abstract      = {We show that a variety of modern deep learning tasks exhibit a "double-descent" phenomenon where, as we increase model size, performance first gets worse and then gets better. Moreover, we show that double descent occurs not just as a function of model size, but also as a function of the number of training epochs. We unify the above phenomena by defining a new complexity measure we call the effective model complexity and conjecture a generalized double descent with respect to this measure. Furthermore, our notion of model complexity allows us to identify certain regimes where increasing (even quadrupling) the number of train samples actually hurts test performance.},
  archiveprefix = {arXiv},
  eprint        = {http://arxiv.org/abs/1912.02292v1},
  file          = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:1912.02292v1/\:PDF/\:PDF/\:1912.02292v1/\:PDF/\:/\:http/\:/arxiv.org/pdf/1912.02292v1/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  keywords      = {cs.LG, cs.CV, cs.NE, stat.ML},
  primaryclass  = {cs.LG},
}

@InCollection{2019Nagarajan-Uniformconvergencemay,
  author    = {Nagarajan, Vaishnavh and Kolter, J. Zico},
  title     = {Uniform convergence may be unable to explain generalization in deep learning},
  booktitle = {Advances in Neural Information Processing Systems 32},
  publisher = {Curran Associates, Inc.},
  year      = {2019},
  editor    = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  pages     = {11611--11622},
  url       = {http://papers.nips.cc/paper/9336-uniform-convergence-may-be-unable-to-explain-generalization-in-deep-learning.pdf},
}

@Article{1986Rumelhart-Learningrepresentationsback,
  author   = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
  journal  = {Nature},
  title    = {Learning representations by back-propagating errors},
  year     = {1986},
  issn     = {1476-4687},
  month    = oct,
  number   = {6088},
  pages    = {533--536},
  volume   = {323},
  abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal \textquotelefthidden\textquoteright units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.},
  doi      = {10.1038/323533a0},
  refid    = {Rumelhart1986},
}

@Article{2012Hinton-Improvingneuralnetworks,
  author        = {Hinton, Geoffrey E. and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R.},
  title         = {Improving neural networks by preventing co-adaptation of feature detectors},
  journal       = {arXiv e-prints},
  year          = {2012},
  pages         = {arXiv:1207.0580},
  month         = jul,
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System},
  adsurl        = {https://ui.adsabs.harvard.edu/abs/2012arXiv1207.0580H},
  archiveprefix = {arXiv},
  eid           = {arXiv:1207.0580},
  eprint        = {1207.0580},
  keywords      = {Computer Science - Neural and Evolutionary Computing, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
  primaryclass  = {cs.NE},
}

@Article{2019Labach-SurveyDropoutMethods,
  author        = {Labach, Alex and Salehinejad, Hojjat and Valaee, Shahrokh},
  title         = {Survey of Dropout Methods for Deep Neural Networks},
  year          = {2019},
  month         = apr,
  abstract      = {Dropout methods are a family of stochastic techniques used in neural network training or inference that have generated significant research interest and are widely used in practice. They have been successfully applied in neural network regularization, model compression, and in measuring the uncertainty of neural network outputs. While original formulated for dense neural network layers, recent advances have made dropout methods also applicable to convolutional and recurrent neural network layers. This paper summarizes the history of dropout methods, their various applications, and current areas of research interest. Important proposed methods are described in additional detail.},
  archiveprefix = {arXiv},
  eprint        = {http://arxiv.org/abs/1904.13310v2},
  file          = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:1904.13310v2/\:PDF/\:PDF/\:1904.13310v2/\:PDF/\:/\:http/\:/arxiv.org/pdf/1904.13310v2/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  keywords      = {cs.NE, cs.LG},
  primaryclass  = {cs.NE},
}

@InBook{1989Lecun-Generalizationnetworkdesign,
  title     = {Generalization and network design strategies},
  publisher = {Elsevier},
  year      = {1989},
  author    = {Lecun, Yann},
  editor    = {R. Pfeifer and Z. Schreter and F. Fogelman and L. Steels},
  booktitle = {Connectionism in perspective},
  language  = {English (US)},
}

@Book{1995Orfanidis-IntroductionSignalProcessing,
  title     = {Introduction to Signal Processing},
  publisher = {Prentice-Hall, Inc.},
  year      = {1995},
  author    = {Orfanidis, Sophocles J.},
  address   = {USA},
  isbn      = {0132091720},
}

@Article{2017Ramachandran-SearchingActivationFunctions,
  author        = {Ramachandran, Prajit and Zoph, Barret and Le, Quoc V.},
  title         = {Searching for Activation Functions},
  year          = {2017},
  month         = oct,
  abstract      = {The choice of activation functions in deep networks has a significant effect on the training dynamics and task performance. Currently, the most successful and widely-used activation function is the Rectified Linear Unit (ReLU). Although various hand-designed alternatives to ReLU have been proposed, none have managed to replace it due to inconsistent gains. In this work, we propose to leverage automatic search techniques to discover new activation functions. Using a combination of exhaustive and reinforcement learning-based search, we discover multiple novel activation functions. We verify the effectiveness of the searches by conducting an empirical evaluation with the best discovered activation function. Our experiments show that the best discovered activation function, f(x) = x ⋅ \text{sigmoid}{(}{β} x), which we name Swish, tends to work better than ReLU on deeper models across a number of challenging datasets. For example, simply replacing ReLUs with Swish units improves top-1 classification accuracy on ImageNet by 0.9% for Mobile NASNet-A and 0.6% for Inception-ResNet-v2. The simplicity of Swish and its similarity to ReLU make it easy for practitioners to replace ReLUs with Swish units in any neural network.},
  archiveprefix = {arXiv},
  eprint        = {http://arxiv.org/abs/1710.05941v2},
  file          = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:1710.05941v2/\:PDF/\:PDF/\:1710.05941v2/\:PDF/\:/\:http/\:/arxiv.org/pdf/1710.05941v2/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  keywords      = {cs.NE, cs.CV, cs.LG},
  primaryclass  = {cs.NE},
}

@Article{2015He-Delvingdeeprectifiers,
  author  = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  title   = {Delving deep into rectifiers: Surpassing human-level performance on imagenet classification. CoRR abs/1502.01852 (2015)},
  journal = {arXiv preprint arXiv:1502.01852},
  year    = {2015},
}

@Article{2015Xu-Empiricalevaluationrectified,
  author  = {Xu, Bing and Wang, Naiyan and Chen, Tianqi and Li, Mu},
  title   = {Empirical evaluation of rectified activations in convolutional network. CoRR abs/1505.00853 (2015)},
  journal = {arXiv preprint arXiv:1505.00853},
  year    = {2015},
}

@Article{2015Clevert-Fastaccuratedeep,
  author  = {Clevert, Djork-Arn{\'e} and Unterthiner, Thomas and Hochreiter, Sepp},
  title   = {Fast and accurate deep network learning by exponential linear units (elus). CoRR abs/1511.07289 (2015)},
  journal = {arXiv preprint arXiv:1511.07289},
  year    = {2015},
}

@InProceedings{1988Zhou-Computationopticalflow,
  author    = {Zhou and Chellappa},
  title     = {Computation of optical flow using a neural network},
  booktitle = {Proc. IEEE 1988 Int. Conf. Neural Networks},
  year      = {1988},
  pages     = {71--78 vol.2},
  month     = jul,
  abstract  = {A method for computing optical flow using a neural network is presented. Usually, the measurement primitives used for computing optical flow from successive image frames are the image-intensity values and their spatial and temporal derivatives, and tokens such as edges, corners, and linear features. Conventional methods based on such primitives suffer from edge sparsity, noise distortion, or sensitivity to rotation. The authors first fit a 2-D polynomial to find a smooth continuous image-intensity function in a window and estimate the subpixel intensity values and their principal curvatures. Under the local rigidity assumption and smoothness constraints, a neural network is then used to implement the computing procedure based on the estimated intensity values and their principal curvatures. Owing to the dense measured primitives, a dense optical flow with subpixel accuracy is obtained with only a few iterations. Since intensity values and their principle curvatures are rotation-invariant, this method can detect both rotating and translating objects in the scene. Experimental results using synthetic image sequences demonstrate the efficacy of the method.},
  doi       = {10.1109/ICNN.1988.23914},
  issn      = {null},
  keywords  = {computerised picture processing, neural nets, computerised picture processing, neural nets, optical flow, neural network, 2-D polynomial, smooth continuous image-intensity function, synthetic image sequences, Image processing, Neural networks},
}

@Article{2016Dumoulin-guideconvolutionarithmetic,
  author        = {Dumoulin, Vincent and Visin, Francesco},
  title         = {A guide to convolution arithmetic for deep learning},
  year          = {2016},
  month         = mar,
  abstract      = {We introduce a guide to help deep learning practitioners understand and manipulate convolutional neural network architectures. The guide clarifies the relationship between various properties (input shape, kernel shape, zero padding, strides and output shape) of convolutional, pooling and transposed convolutional layers, as well as the relationship between convolutional and transposed convolutional layers. Relationships are derived for various cases, and are illustrated in order to make them intuitive.},
  archiveprefix = {arXiv},
  eprint        = {1603.07285v1},
  file          = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:1603.07285v1/\:PDF/\:PDF/\:1603.07285v1/\:PDF/\:/\:2016Dumoulin-Aguideto.pdf/\:PDF/\;online/\:http/\:/arxiv.org/pdf/1603.07285v1/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  keywords      = {stat.ML, cs.LG, cs.NE, printed},
  primaryclass  = {stat.ML},
}

@Article{2016RongGen-gravitationalwavemodels,
  author    = {RongGen, C. A. I. and ZhouJian, C. A. O. and WenBiao, H. A. N.},
  title     = {The gravitational wave models for binary compact objects},
  journal   = {Chinese Science Bulletin},
  year      = {2016},
  volume    = {61},
  number    = {14},
  pages     = {1525--1535},
  month     = apr,
  doi       = {10.1360/n972016-00299},
  publisher = {Science China Press., Co. Ltd.},
}

@Article{2016ZhouJian-Numericalrelativitygravitational,
  author    = {ZhouJian, C. A. O. and ZhiHui, D. U.},
  title     = {Numerical relativity and gravitational wave astronomy},
  journal   = {{SCIENTIA} {SINICA} Physica, Mechanica {\&} Astronomica},
  year      = {2016},
  volume    = {47},
  number    = {1},
  pages     = {010405},
  month     = dec,
  doi       = {10.1360/sspma2016-00200},
  publisher = {Science China Press., Co. Ltd.},
}

%%% contains utf-8, see: https://inspirehep.net/info/faq/general#utf8
%%% add \usepackage[utf8]{inputenc} to your latex preamble

@Article{2017Ezquiaga-DarkEnergyAfter,
  author        = {Ezquiaga, Jose Mar{\'{i}}a and Zumalac{\'{a}}rregui, Miguel},
  title         = {Dark Energy After GW170817: Dead Ends and the Road Ahead},
  journal       = {Phys. Rev. Lett.},
  year          = {2017},
  volume        = {119},
  number        = {25},
  pages         = {251304},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevLett.119.251304},
  eprint        = {1710.05901},
  primaryclass  = {astro-ph.CO},
  reportnumber  = {IFT-UAM-CSIC-17-096, NORDITA-2017-109},
}

@Article{2017Sakstein-ImplicationsNeutronStar,
  author        = {Sakstein, Jeremy and Jain, Bhuvnesh},
  title         = {Implications of the Neutron Star Merger GW170817 for Cosmological Scalar-Tensor Theories},
  journal       = {Phys. Rev. Lett.},
  year          = {2017},
  volume        = {119},
  number        = {25},
  pages         = {251303},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevLett.119.251303},
  eprint        = {1710.05893},
  primaryclass  = {astro-ph.CO},
}

@Article{2017Creminelli-DarkEnergyafter,
  author        = {Creminelli, Paolo and Vernizzi, Filippo},
  title         = {Dark Energy after GW170817 and GRB170817A},
  journal       = {Phys. Rev. Lett.},
  year          = {2017},
  volume        = {119},
  number        = {25},
  pages         = {251302},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevLett.119.251302},
  eprint        = {1710.05877},
  primaryclass  = {astro-ph.CO},
}

@Article{2017Baker-Strongconstraintscosmological,
  author        = {Baker, T. and Bellini, E. and Ferreira, P. G. and Lagos, M. and Noller, J. and Sawicki, I.},
  title         = {Strong constraints on cosmological gravity from GW170817 and GRB 170817A},
  journal       = {Phys. Rev. Lett.},
  year          = {2017},
  volume        = {119},
  number        = {25},
  pages         = {251301},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevLett.119.251301},
  eprint        = {1710.06394},
  primaryclass  = {astro-ph.CO},
}

@Article{2018George-DeepNeuralNetworks,
  author        = {George, Daniel and Huerta, E. A.},
  title         = {Deep Neural Networks to Enable Real-time Multimessenger Astrophysics},
  journal       = {Phys. Rev.},
  year          = {2018},
  volume        = {D97},
  number        = {4},
  pages         = {044039},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.97.044039},
  eprint        = {1701.00008},
  primaryclass  = {astro-ph.IM},
}

@InProceedings{2017George-DeepLearningReal,
  author        = {George, Daniel and Huerta, E. A.},
  title         = {Deep Learning for Real-time Gravitational Wave Detection and Parameter Estimation with LIGO Data},
  booktitle     = {NiPS Summer School 2017 Gubbio, Perugia, Italy, June 30-July 3, 2017},
  year          = {2017},
  archiveprefix = {arXiv},
  eprint        = {1711.07966},
  primaryclass  = {gr-qc},
}

@Article{2018George-DeepLearningReal,
  author        = {George, Daniel and Huerta, E. A.},
  title         = {Deep Learning for Real-time Gravitational Wave Detection and Parameter Estimation: Results with Advanced LIGO Data},
  journal       = {Phys. Lett.},
  year          = {2018},
  volume        = {B778},
  pages         = {64--70},
  archiveprefix = {arXiv},
  doi           = {10.1016/j.physletb.2017.12.053},
  eprint        = {1711.03121},
  primaryclass  = {gr-qc},
}

@Article{2017Shen-DenoisingGravitationalWaves,
  author        = {Shen, Hongyu and George, Daniel and Huerta, E. A. and Zhao, Zhizhen},
  title         = {Denoising Gravitational Waves using Deep Learning with Recurrent Denoising Autoencoders},
  year          = {2017},
  archiveprefix = {arXiv},
  eprint        = {1711.09919},
  primaryclass  = {gr-qc},
}

@Article{2017Li-MethodDetectingGravitational,
  author        = {Li, Xiangru and Yu, Woliang and Fan, Xilong},
  title         = {A Method Of Detecting Gravitational Wave Based On Time-frequency Analysis And Convolutional Neural Networks},
  year          = {2017},
  archiveprefix = {arXiv},
  eprint        = {1712.00356},
  primaryclass  = {astro-ph.IM},
}

@Article{2018Cao-Initialstudyapplication,
  author   = {Cao, Zhoujian and He, Wang and Zhu, Jianyang and Astronomy, Department Of and University, Beijing Normal and Physics, Department Of and University, Beijing Normal},
  journal  = {Journal of Henan Normal University},
  title    = {Initial study on the application of deep learning to the Gravitational Wave data analysis},
  year     = {2018},
  number   = {2},
  volume   = {46},
  doi      = {10.16366/j.cnki.1000-2367.2018.02.005},
  file     = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:2018Cao-Initialstudyapplication.pdf/\:PDF/\:/\:2018Cao-Initialstudyapplication.pdf/\:PDF/\:PDF/\:/\:2018Cao-Initialstudyapplication.pdf/\:PDF/\:/\:2018Cao-Initialstudyapplication.pdf/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  keywords = {gravitational wave astronomy;matched filtering method;dep learning;numerical relativity;gravitational waveform template},
}

@InProceedings{2010LeCun-Convolutionalnetworksapplications,
  author       = {LeCun, Yann and Kavukcuoglu, Koray and Farabet, Cl{\'e}ment},
  title        = {Convolutional networks and applications in vision},
  booktitle    = {Circuits and Systems (ISCAS), Proceedings of 2010 IEEE International Symposium on},
  year         = {2010},
  pages        = {253--256},
  month        = may,
  organization = {IEEE},
  doi          = {10.1109/ISCAS.2010.5537907},
  file         = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:2010LeCun-Convolutionalnetworksand.pdf/\:PDF/\:/\:2010LeCun-Convolutionalnetworksand.pdf/\:PDF/\:PDF/\:/\:2010LeCun-Convolutionalnetworksand.pdf/\:PDF/\:/\:2010LeCun-Convolutionalnetworksand.pdf/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  issn         = {0271-4302},
  keywords     = {printed},
}

@Article{1998Lecun-Gradientbasedlearning,
  author   = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  title    = {Gradient-based learning applied to document recognition},
  journal  = {Proceedings of the IEEE},
  year     = {1998},
  volume   = {86},
  number   = {11},
  pages    = {2278--2324},
  month    = nov,
  issn     = {0018-9219},
  doi      = {10.1109/5.726791},
  file     = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:1998Lecun-Gradientbasedlearning.pdf/\:PDF/\:/\:1998Lecun-Gradientbasedlearning.pdf/\:PDF/\:PDF/\:/\:1998Lecun-Gradientbasedlearning.pdf/\:PDF/\:/\:1998Lecun-Gradientbasedlearning.pdf/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  keywords = {backpropagation, convolution, multilayer perceptrons, optical character recognition, 2D shape variability, GTN, back-propagation, cheque reading, complex decision surface synthesis, convolutional neural network character recognizers, document recognition, document recognition systems, field extraction, gradient based learning technique, gradient-based learning, graph transformer networks, handwritten character recognition, handwritten digit recognition task, high-dimensional patterns, language modeling, multilayer neural networks, multimodule systems, performance measure minimization, segmentation recognition, Character recognition, Feature extraction, Hidden Markov models, Machine learning, Multi-layer neural network, Neural networks, Optical character recognition software, Optical computing, Pattern recognition, Principal component analysis},
}

@Article{2015Ioffe-BatchNormalizationAccelerating,
  author        = {Ioffe, Sergey and Szegedy, Christian},
  title         = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  year          = {2015},
  archiveprefix = {arXiv},
  eprint        = {1502.03167},
  primaryclass  = {cs.LG},
}

@Misc{2014Srivastava-Dropoutsimpleway,
  author    = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  title     = {Dropout: A simple way to prevent neural networks from overfitting},
  year      = {2014},
  abstract  = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different \textquotedblleftthinned \textquotedblright networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.},
  file      = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:2014Srivastava-Dropout_Asimple.pdf/\:PDF/\:/\:2014Srivastava-Dropout_Asimple.pdf/\:PDF/\:PDF/\:/\:2014Srivastava-Dropout_Asimple.pdf/\:PDF/\:/\:2014Srivastava-Dropout_Asimple.pdf/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  journal   = {The Journal of Machine Learning Research},
  number    = {1},
  pages     = {1929--1958},
  publisher = {JMLR. org},
  volume    = {15},
}

@Article{2017Yu-DilatedResidualNetworks,
  author        = {Yu, Fisher and Koltun, Vladlen and Funkhouser, Thomas},
  title         = {Dilated Residual Networks},
  year          = {2017},
  pages         = {636--644},
  month         = jul,
  issn          = {1063-6919},
  abstract      = {Convolutional networks for image classification progressively reduce resolution until the image is represented by tiny feature maps in which the spatial structure of the scene is no longer discernible. Such loss of spatial acuity can limit image classification accuracy and complicate the transfer of the model to downstream applications that require detailed scene understanding. These problems can be alleviated by dilation, which increases the resolution of output feature maps without reducing the receptive field of individual neurons. We show that dilated residual networks (DRNs) outperform their non-dilated counterparts in image classification without increasing the model's depth or complexity. We then study gridding artifacts introduced by dilation, develop an approach to removing these artifacts (`degridding'), and show that this further increases the performance of DRNs. In addition, we show that the accuracy advantage of DRNs is further magnified in downstream applications such as object localization and semantic segmentation.},
  archiveprefix = {arXiv},
  booktitle     = {Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR)},
  date          = {2017-05-28},
  doi           = {10.1109/CVPR.2017.75},
  eprint        = {http://arxiv.org/abs/1705.09914v1},
  file          = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:1705.09914v1/\:PDF/\:PDF/\:1705.09914v1/\:PDF/\:/\:http/\:/arxiv.org/pdf/1705.09914v1/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  keywords      = {image classification, image resolution, neural nets, DRNs, dilated residual networks, convolutional networks, tiny feature maps, spatial structure, spatial acuity, output feature maps, image classification, scene understanding, image resolution, gridding artifacts, Convolution, Spatial resolution, Semantics, Image segmentation, Training},
  primaryclass  = {cs.CV},
}

@Article{2015Chen-MXNetFlexibleEfficient,
  author        = {Chen, Tianqi and Li, Mu and Li, Yutian and Lin, Min and Wang, Naiyan and Wang, Minjie and Xiao, Tianjun and Xu, Bing and Zhang, Chiyuan and Zhang, Zheng},
  title         = {MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems},
  year          = {2015},
  month         = dec,
  abstract      = {MXNet is a multi-language machine learning (ML) library to ease the development of ML algorithms, especially for deep neural networks. Embedded in the host language, it blends declarative symbolic expression with imperative tensor computation. It offers auto differentiation to derive gradients. MXNet is computation and memory efficient and runs on various heterogeneous systems, ranging from mobile devices to distributed GPU clusters. This paper describes both the API design and the system implementation of MXNet, and explains how embedding of both symbolic expression and tensor operation is handled in a unified fashion. Our preliminary experiments reveal promising results on large scale deep neural network applications using multiple GPU machines.},
  archiveprefix = {arXiv},
  eprint        = {1512.01274v1},
  file          = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:1512.01274v1/\:PDF/\:PDF/\:1512.01274v1/\:PDF/\:/\:2015Chen-MXNet_AFlexible.pdf/\:PDF/\;online/\:http/\:/arxiv.org/pdf/1512.01274v1/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  keywords      = {cs.DC, cs.LG, cs.MS, cs.NE, printed, relevant},
  primaryclass  = {cs.DC},
}

@Article{2017Vidal-MathematicsDeepLearning,
  author        = {Vidal, Rene and Bruna, Joan and Giryes, Raja and Soatto, Stefano},
  title         = {Mathematics of Deep Learning},
  year          = {2017},
  month         = dec,
  abstract      = {Recently there has been a dramatic increase in the performance of recognition systems due to the introduction of deep architectures for representation learning and classification. However, the mathematical reasons for this success remain elusive. This tutorial will review recent work that aims to provide a mathematical justification for several properties of deep networks, such as global optimality, geometric stability, and invariance of the learned representations.},
  archiveprefix = {arXiv},
  eprint        = {1712.04741v1},
  file          = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:1712.04741v1/\:PDF/\:PDF/\:1712.04741v1/\:PDF/\:/\:2017Vidal-MathematicsofDeep.pdf/\:PDF/\;online/\:http/\:/arxiv.org/pdf/1712.04741v1/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  keywords      = {cs.LG, cs.CV},
  primaryclass  = {cs.LG},
}

@Article{2017Bau-NetworkDissectionQuantifying,
  author        = {Bau, David and Zhou, Bolei and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},
  title         = {Network Dissection: Quantifying Interpretability of Deep Visual Representations},
  year          = {2017},
  month         = apr,
  abstract      = {We propose a general framework called Network Dissection for quantifying the interpretability of latent representations of CNNs by evaluating the alignment between individual hidden units and a set of semantic concepts. Given any CNN model, the proposed method draws on a broad data set of visual concepts to score the semantics of hidden units at each intermediate convolutional layer. The units with semantics are given labels across a range of objects, parts, scenes, textures, materials, and colors. We use the proposed method to test the hypothesis that interpretability of units is equivalent to random linear combinations of units, then we apply our method to compare the latent representations of various networks when trained to solve different supervised and self-supervised training tasks. We further analyze the effect of training iterations, compare networks trained with different initializations, examine the impact of network depth and width, and measure the effect of dropout and batch normalization on the interpretability of deep visual representations. We demonstrate that the proposed method can shed light on characteristics of CNN models and training methods that go beyond measurements of their discriminative power.},
  archiveprefix = {arXiv},
  eprint        = {1704.05796v1},
  file          = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:1704.05796v1/\:PDF/\:PDF/\:1704.05796v1/\:PDF/\:/\:2017Bau-NetworkDissection_Quantifying.pdf/\:PDF/\;online/\:http/\:/arxiv.org/pdf/1704.05796v1/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  keywords      = {cs.CV, cs.AI, I.2.10, printed},
  primaryclass  = {cs.CV},
}

@Article{2013Zeiler-VisualizingUnderstandingConvolutional,
  author        = {Zeiler, Matthew D. and Fergus, Rob},
  title         = {Visualizing and Understanding Convolutional Networks},
  year          = {2013},
  month         = nov,
  abstract      = {Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we address both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. We also perform an ablation study to discover the performance contribution from different model layers. This enables us to find model architectures that outperform Krizhevsky \etal on the ImageNet classification benchmark. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.},
  archiveprefix = {arXiv},
  comment       = {很经典很重要的卷积神经网络的可视化文章。},
  eprint        = {http://arxiv.org/abs/1311.2901v3},
  file          = {2013Zeiler-VisualizingUnderstandingConvolutional.pdf\::\:/Users/herb/Github/Notes/GW_Astronomy/2013Zeiler-VisualizingUnderstandingConvolutional.pdf\::PDF},
  keywords      = {cs.CV},
  primaryclass  = {cs.CV},
}

@InCollection{2015Ren-FasterRCNN,
  author    = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  title     = {Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
  booktitle = {Advances in Neural Information Processing Systems 28},
  publisher = {Curran Associates, Inc.},
  year      = {2015},
  editor    = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
  pages     = {91--99},
  url       = {http://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf},
}

@InCollection{2016Dai-RFCNObject,
  author    = {Dai, Jifeng and Li, Yi and He, Kaiming and Sun, Jian},
  title     = {R-FCN: Object Detection via Region-based Fully Convolutional Networks},
  booktitle = {Advances in Neural Information Processing Systems 29},
  publisher = {Curran Associates, Inc.},
  year      = {2016},
  editor    = {D. D. Lee and M. Sugiyama and U. V. Luxburg and I. Guyon and R. Garnett},
  pages     = {379--387},
  url       = {http://papers.nips.cc/paper/6465-r-fcn-object-detection-via-region-based-fully-convolutional-networks.pdf},
}

@InProceedings{2016Liu-SSDSingleShot,
  author    = {Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C.},
  booktitle = {Computer Vision -- ECCV 2016},
  title     = {SSD: Single Shot MultiBox Detector},
  year      = {2016},
  address   = {Cham},
  editor    = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
  pages     = {21--37},
  publisher = {Springer International Publishing},
  abstract  = {We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction time, the network generates scores for the presence of each object category in each default box and produces adjustments to the box to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. SSD is simple relative to methods that require object proposals because it completely eliminates proposal generation and subsequent pixel or feature resampling stages and encapsulates all computation in a single network. This makes SSD easy to train and straightforward to integrate into systems that require a detection component. Experimental results on the PASCAL VOC, COCO, and ILSVRC datasets confirm that SSD has competitive accuracy to methods that utilize an additional object proposal step and is much faster, while providing a unified framework for both training and inference. For 300 \backslashtimes 300300\texttimes{3}{0}{0}input, SSD achieves 74.3 % mAP on VOC2007 test at 59 FPS on a Nvidia Titan X and for 512 \backslashtimes 512512\texttimes{5}{1}{2}input, SSD achieves 76.9 % mAP, outperforming a comparable state of the art Faster R-CNN model. Compared to other single stage methods, SSD has much better accuracy even with a smaller input image size. Code is available at https://github.com/weiliu89/caffe/tree/ssd.},
  isbn      = {978-3-319-46448-0},
}

@Article{2016Cao-Gravitationalwaveastronomy,
  author  = {Cao, ZhouJian},
  journal = {Science China Physics, Mechanics \& Astronomy},
  title   = {Gravitational wave astronomy: chance and challenge to fundamental physics and astrophysics},
  year    = {2016},
  issn    = {1869-1927},
  month   = sep,
  number  = {11},
  pages   = {110431},
  volume  = {59},
  doi     = {10.1007/s11433-016-0324-y},
  refid   = {Cao2016},
}

@Book{1991Liang-foundationmodernphysics,
  title     = {foundation of modern physics Series 7: Introduction to Differential Geometry and General Relativity (Vol.1)},
  publisher = {Unknown},
  year      = {1991},
  author    = {Liang, Canbin and Zhou, Bin},
  isbn      = {9787030164605},
  url       = {https://www.amazon.com/foundation-modern-physics-Introduction-Differential/dp/7030164601?SubscriptionId=AKIAIOBINVZYXZQZ2U3A&tag=chimbori05-20&linkCode=xm2&camp=2025&creative=165953&creativeASIN=7030164601},
}

@Article{2005Acernese-StatusVirgo,
  author    = {Acernese, F. and Amico, P. and Al-Shourbagy, M. and Aoudia, S. and Avino, S. and Babusci, D. and Ballardin, G. and Barill{\'{e}}, R. and Barone, F. and Barsotti, L. and Barsuglia, M. and Beauville, F. and Bizouard, M. A. and Boccara, C. and Bondu, F. and Bosi, L. and Bradaschia, C. and Braccini, S. and Brillet, A. and Brisson, V. and Brocco, L. and Buskulic, D. and Calloni, E. and Campagna, E. and Cavalier, F. and Cavalieri, R. and Cella, G. and Chassande-Mottin, E. and Corda, C. and Clapson, A.-C. and Cleva, F. and Coulon, J.-P. and Cuoco, E. and Dattilo, V. and Davier, M. and Rosa, R. De and Fiore, L. Di and Virgilio, A. Di and Dujardin, B. and Eleuteri, A. and Enard, D. and Ferrante, I. and Fidecaro, F. and Fiori, I. and Flaminio, R. and Fournier, J.-D. and Frasca, S. and Frasconi, F. and Freise, A. and Gammaitoni, L. and Gennai, A. and Giazotto, A. and Giordano, G. and Giordano, L. and Gouaty, R. and Grosjean, D. and Guidi, G. and Hebri, S. and Heitmann, H. and Hello, P. and Holloway, L. and Kreckelbergh, S. and Penna, P. La and Loriette, V. and Loupias, M. and Losurdo, G. and Mackowski, J.-M. and Majorana, E. and Man, C. N. and Mantovani, M. and Marchesoni, F. and Marion, F. and Marque, J. and Martelli, F. and Masserot, A. and Mazzoni, M. and Milano, L. and Moins, C. and Moreau, J. and Morgado, N. and Mours, B. and Pai, A. and Palomba, C. and Paoletti, F. and Pardi, S. and Pasqualetti, A. and Passaquieti, R. and Passuello, D. and Perniola, B. and Piergiovanni, F. and Pinard, L. and Poggiani, R. and Punturo, M. and Puppo, P. and Qipiani, K. and Rapagnani, P. and Reita, V. and Remillieux, A. and Ricci, F. and Ricciardi, I. and Ruggi, P. and Russo, G. and Solimeno, S. and Spallicci, A. and Stanga, R. and Taddei, R. and Tombolato, D. and Tonelli, M. and Toncelli, A. and Tournefier, E. and Travasso, F. and Vajente, G. and Verkindt, D. and Vetrano, F. and Vicer{\'{e}}, A. and Vinet, J.-Y. and Vocca, H. and Yvert, M. and Zhang, Z.},
  journal   = {Classical and Quantum Gravity},
  title     = {Status of Virgo},
  year      = {2005},
  month     = aug,
  number    = {18},
  pages     = {S869--S880},
  volume    = {22},
  abstract  = {The gravitational wave interferometer Virgo is presently in its commissioning phase. The status of the detector will be presented, focusing attention on the results obtained during this last year of commissioning activity, running the interferometer in the recombined configuration (a Michelson interferometer with Fabry–Perot cavities in both the arms) and finally recycling the light beam into the interferometer.},
  doi       = {10.1088/0264-9381/22/18/s01},
  publisher = {{IOP} Publishing},
}

@Article{2002Willke-GEO600gravitational,
  author    = {Willke, B. and others},
  title     = {The GEO 600 gravitational wave detector},
  journal   = {Class. Quant. Grav.},
  year      = {2002},
  volume    = {19},
  pages     = {1377--1387},
  booktitle = {Gravitational waves. Proceedings, 4th Edoardo Amaldi Conference, Amaldi 4, Perth, Australia, July 8-13, 2001},
  doi       = {10.1088/0264-9381/19/7/321},
}

@Article{1992Abramovici-LIGOLaserinterferometer,
  author  = {Abramovici, Alex and others},
  title   = {LIGO: The Laser interferometer gravitational wave observatory},
  journal = {Science},
  year    = {1992},
  volume  = {256},
  pages   = {325--333},
  doi     = {10.1126/science.256.5055.325},
}

@Article{2010Harry-AdvancedLIGOnext,
  author        = {Harry, Gregory M.},
  title         = {Advanced LIGO: The next generation of gravitational wave detectors},
  journal       = {Class. Quant. Grav.},
  year          = {2010},
  volume        = {27},
  pages         = {084006},
  booktitle     = {Gravitational waves. Proceedings, 8th Edoardo Amaldi Conference, Amaldi 8, New York, USA, June 22-26, 2009},
  collaboration = {LIGO Scientific},
  doi           = {10.1088/0264-9381/27/8/084006},
}

@Article{2005Jaranowski-GravitationalWaveData,
  author        = {Jaranowski, Piotr and Krolak, Andrzej},
  title         = {Gravitational-Wave Data Analysis. Formalism and Sample Applications: The Gaussian Case},
  journal       = {Living Rev. Rel.},
  year          = {2005},
  volume        = {8},
  pages         = {3},
  note          = {[Living Rev. Rel.15,4(2012)]},
  archiveprefix = {arXiv},
  eprint        = {0711.1115},
  primaryclass  = {gr-qc},
}

@Book{2006Bishop-Patternrecognitionmachine,
  title     = {Pattern recognition and machine learning},
  publisher = {Springer},
  year      = {2006},
  author    = {Bishop, Christopher M.},
  series    = {Information science and statistics},
  address   = {New York, NY},
  note      = {Softcover published in 2016},
  url       = {https://cds.cern.ch/record/998831},
}

@Article{2016Abbott-GW150914AdvancedLIGO,
  author        = {Abbott, B. P. and others},
  title         = {GW150914: The Advanced LIGO Detectors in the Era of First Discoveries},
  journal       = {Phys. Rev. Lett.},
  year          = {2016},
  volume        = {116},
  number        = {13},
  pages         = {131103},
  archiveprefix = {arXiv},
  collaboration = {LIGO Scientific, Virgo},
  doi           = {10.1103/PhysRevLett.116.131103},
  eprint        = {1602.03838},
  primaryclass  = {gr-qc},
  reportnumber  = {LIGO-P1500237},
}

@Article{2013Abdo-secondFermiLarge,
  author    = {Abdo, A. A. and Ajello, M. and Allafort, A. and Baldini, L. and Ballet, J. and Barbiellini, G. and Baring, M. G. and Bastieri, D. and Belfiore, A. and Bellazzini, R. and Bhattacharyya, B. and Bissaldi, E. and Bloom, E. D. and Bonamente, E. and Bottacini, E. and Brandt, T. J. and Bregeon, J. and Brigida, M. and Bruel, P. and Buehler, R. and Burgay, M. and Burnett, T. H. and Busetto, G. and Buson, S. and Caliandro, G. A. and Cameron, R. A. and Camilo, F. and Caraveo, P. A. and Casandjian, J. M. and Cecchi, C. and {\c{C}}elik, Ö. and Charles, E. and Chaty, S. and Chaves, R. C. G. and Chekhtman, A. and Chen, A. W. and Chiang, J. and Chiaro, G. and Ciprini, S. and Claus, R. and Cognard, I. and Cohen-Tanugi, J. and Cominsky, L. R. and Conrad, J. and Cutini, S. and D{\textquotesingle}Ammando, F. and de Angelis, A. and DeCesar, M. E. and Luca, A. De and den Hartog, P. R. and de Palma, F. and Dermer, C. D. and Desvignes, G. and Digel, S. W. and Venere, L. Di and Drell, P. S. and Drlica-Wagner, A. and Dubois, R. and Dumora, D. and Espinoza, C. M. and Falletti, L. and Favuzzi, C. and Ferrara, E. C. and Focke, W. B. and Franckowiak, A. and Freire, P. C. C. and Funk, S. and Fusco, P. and Gargano, F. and Gasparrini, D. and Germani, S. and Giglietto, N. and Giommi, P. and Giordano, F. and Giroletti, M. and Glanzman, T. and Godfrey, G. and Gotthelf, E. V. and Grenier, I. A. and Grondin, M.-H. and Grove, J. E. and Guillemot, L. and Guiriec, S. and Hadasch, D. and Hanabata, Y. and Harding, A. K. and Hayashida, M. and Hays, E. and Hessels, J. and Hewitt, J. and Hill, A. B. and Horan, D. and Hou, X. and Hughes, R. E. and Jackson, M. S. and Janssen, G. H. and Jogler, T. and J{\'{o}}hannesson, G. and Johnson, R. P. and Johnson, A. S. and Johnson, T. J. and Johnson, W. N. and Johnston, S. and Kamae, T. and Kataoka, J. and Keith, M. and Kerr, M. and Knödlseder, J. and Kramer, M. and Kuss, M. and Lande, J. and Larsson, S. and Latronico, L. and Lemoine-Goumard, M. and Longo, F. and Loparco, F. and Lovellette, M. N. and Lubrano, P. and Lyne, A. G. and Manchester, R. N. and Marelli, M. and Massaro, F. and Mayer, M. and Mazziotta, M. N. and McEnery, J. E. and McLaughlin, M. A. and Mehault, J. and Michelson, P. F. and Mignani, R. P. and Mitthumsiri, W. and Mizuno, T. and Moiseev, A. A. and Monzani, M. E. and Morselli, A. and Moskalenko, I. V. and Murgia, S. and Nakamori, T. and Nemmen, R. and Nuss, E. and Ohno, M. and Ohsugi, T. and Orienti, M. and Orlando, E. and Ormes, J. F. and Paneque, D. and Panetta, J. H. and Parent, D. and Perkins, J. S. and Pesce-Rollins, M. and Pierbattista, M. and Piron, F. and Pivato, G. and Pletsch, H. J. and Porter, T. A. and Possenti, A. and Rain{\`{o}}, S. and Rando, R. and Ransom, S. M. and Ray, P. S. and Razzano, M. and Rea, N. and Reimer, A. and Reimer, O. and Renault, N. and Reposeur, T. and Ritz, S. and Romani, R. W. and Roth, M. and Rousseau, R. and Roy, J. and Ruan, J. and Sartori, A. and Parkinson, P. M. Saz and Scargle, J. D. and Schulz, A. and Sgr{\`{o}}, C. and Shannon, R. and Siskind, E. J. and Smith, D. A. and Spandre, G. and Spinelli, P. and Stappers, B. W. and Strong, A. W. and Suson, D. J. and Takahashi, H. and Thayer, J. G. and Thayer, J. B. and Theureau, G. and Thompson, D. J. and Thorsett, S. E. and Tibaldo, L. and Tibolla, O. and Tinivella, M. and Torres, D. F. and Tosti, G. and Troja, E. and Uchiyama, Y. and Usher, T. L. and Vandenbroucke, J. and Vasileiou, V. and Venter, C. and Vianello, G. and Vitale, V. and Wang, N. and Weltevrede, P. and Winer, B. L. and Wolff, M. T. and Wood, D. L. and Wood, K. S. and Wood, M. and Yang, Z.},
  journal   = {The Astrophysical Journal Supplement Series},
  title     = {The second Fermi Large Area Telescope catalog of gamma-ray pulsars},
  year      = {2013},
  month     = sep,
  number    = {2},
  pages     = {17},
  volume    = {208},
  abstract  = {This catalog summarizes 117 high-confidence ⩾0.1 GeV gamma-ray pulsar detections using three years of data acquired by the Large Area Telescope (LAT) on the Fermi satellite. Half are neutron stars discovered using LAT data through periodicity searches in gamma-ray and radio data around LAT unassociated source positions. The 117 pulsars are evenly divided into three groups: millisecond pulsars, young radio-loud pulsars, and young radio-quiet pulsars. We characterize the pulse profiles and energy spectra and derive luminosities when distance information exists. Spectral analysis of the off-peak phase intervals indicates probable pulsar wind nebula emission for four pulsars, and off-peak magnetospheric emission for several young and millisecond pulsars. We compare the gamma-ray properties with those in the radio, optical, and X-ray bands. We provide flux limits for pulsars with no observed gamma-ray emission, highlighting a small number of gamma-faint, radio-loud pulsars. The large, varied gamma-ray pulsar sample constrains emission models. Fermi's selection biases complement those of radio surveys, enhancing comparisons with predicted population distributions.},
  doi       = {10.1088/0067-0049/208/2/17},
  publisher = {{IOP} Publishing},
}

@Article{2002Tyson-Largesynopticsurvey,
  author        = {Tyson, J. Anthony},
  title         = {Large synoptic survey telescope: Overview},
  journal       = {Proc. SPIE Int. Soc. Opt. Eng.},
  year          = {2002},
  volume        = {4836},
  pages         = {10--20},
  archiveprefix = {arXiv},
  booktitle     = {Proceedings, Conference on Astronomical Telescopes and Instrumenation: Waikoloa, Hawaii, August 22-28, 2002},
  collaboration = {LSST},
  doi           = {10.1117/12.456772},
  eprint        = {astro-ph/0302102},
  primaryclass  = {astro-ph},
}

@Article{2015Gehrels-WideFieldInfraRed,
  author        = {Gehrels, Neil and Spergel, David N.},
  title         = {Wide-Field InfraRed Survey Telescope (WFIRST) Mission and Synergies with LISA and LIGO-Virgo},
  journal       = {J. Phys. Conf. Ser.},
  year          = {2015},
  volume        = {610},
  number        = {1},
  pages         = {012007},
  archiveprefix = {arXiv},
  booktitle     = {Proceedings, 10th International LISA Symposium: Gainesville, Florida, USA, May 18-23, 2014},
  collaboration = {WFIRST SDT},
  doi           = {10.1088/1742-6596/610/1/012007},
  eprint        = {1411.0313},
  primaryclass  = {astro-ph.IM},
}

@Article{2016AdrianMartinez-HighenergyNeutrino,
  author        = {Adrian-Martinez, S. and others},
  journal       = {Phys. Rev.},
  title         = {High-energy Neutrino follow-up search of Gravitational Wave Event GW150914 with ANTARES and IceCube},
  year          = {2016},
  number        = {12},
  pages         = {122010},
  volume        = {D93},
  archiveprefix = {arXiv},
  collaboration = {ANTARES, IceCube, LIGO Scientific, Virgo},
  doi           = {10.1103/PhysRevD.93.122010},
  eprint        = {1602.05411},
  primaryclass  = {astro-ph.HE},
}

@InProceedings{2002Tyson-Surveyothertelescope,
  author    = {Tyson, J. Anthony and Wolff, Sidney},
  title     = {Survey and other telescope technologies and discoveries},
  booktitle = {Survey and Other Telescope Technologies and Discoveries},
  year      = {2002},
  volume    = {4836},
}

@Article{2015Powell-Classificationmethodsnoise,
  author        = {Powell, Jade and Trifirò, Daniele and Cuoco, Elena and Heng, Ik Siong and Cavaglià, Marco},
  journal       = {Class. Quant. Grav.},
  title         = {Classification methods for noise transients in advanced gravitational-wave detectors},
  year          = {2015},
  month         = may,
  number        = {21},
  pages         = {215012},
  volume        = {32},
  abstract      = {Noise of non-astrophysical origin will contaminate science data taken by the Advanced Laser Interferometer Gravitational-wave Observatory (aLIGO) and Advanced Virgo gravitational-wave detectors. Prompt characterization of instrumental and environmental noise transients will be critical for improving the sensitivity of the advanced detectors in the upcoming science runs. During the science runs of the initial gravitational-wave detectors, noise transients were manually classified by visually examining the time-frequency scan of each event. Here, we present three new algorithms designed for the automatic classification of noise transients in advanced detectors. Two of these algorithms are based on Principal Component Analysis. They are Principal Component Analysis for Transients (PCAT), and an adaptation of LALInference Burst (LIB). The third algorithm is a combination of an event generator called Wavelet Detection Filter (WDF) and machine learning techniques for classification. We test these algorithms on simulated data sets, and we show their ability to automatically classify transients by frequency, SNR and waveform morphology.},
  archiveprefix = {arXiv},
  doi           = {10.1088/0264-9381/32/21/215012},
  eprint        = {1505.01299v2},
  eprintclass   = {astro-ph.IM},
  eprinttype    = {arXiv},
  file          = {1505.01299v2\:PDF:\:2015Powell-Classificationmethodsfor.pdf\:PDF\;online\:http/\:/arxiv.org/pdf/1505.01299v2\:PDF:PDF},
  keywords      = {astro-ph.IM, skimmed},
  primaryclass  = {astro-ph.IM},
}

%%% contains utf-8, see: https://inspirehep.net/info/faq/general#utf8
%%% add \usepackage[utf8]{inputenc} to your latex preamble

@Article{2016TorresForne-Denoisinggravitationalwave,
  author        = {Torres-Forné, Alejandro and Marquina, Antonio and Font, José A. and Ibáñez, José M.},
  journal       = {Phys. Rev.},
  title         = {Denoising of gravitational wave signals via dictionary learning algorithms},
  year          = {2016},
  number        = {12},
  pages         = {124040},
  volume        = {D94},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.94.124040},
  eprint        = {1612.01305},
  primaryclass  = {astro-ph.IM},
}

@Article{2018Gabbard-MatchingMatchedFiltering,
  author         = {Gabbard, Hunter and Williams, Michael and Hayes, Fergus and Messenger, Chris},
  title          = {Matching Matched Filtering with Deep Networks for Gravitational-Wave Astronomy},
  journal        = {Physical review letters},
  year           = {2018},
  volume         = {120},
  number         = {14},
  pages          = {141103},
  month          = dec,
  issn           = {0031-9007},
  abstract       = {We report on the construction of a deep convolutional neural network that can reproduce the sensitivity of a matched-filtering search for binary black hole gravitational-wave signals. The standard method for the detection of well modeled transient gravitational-wave signals is matched filtering. However, the computational cost of such searches in low latency will grow dramatically as the low frequency sensitivity of gravitational-wave detectors improves. Convolutional neural networks provide a highly computationally efficient method for signal identification in which the majority of calculations are performed prior to data taking during a training process. We use only whitened time series of measured gravitational-wave strain as an input, and we train and test on simulated binary black hole signals in synthetic Gaussian noise representative of Advanced LIGO sensitivity. We show that our network can classify signal from noise with a performance that emulates that of match filtering applied to the same datasets when considering the sensitivity defined by Reciever-Operator characteristics.},
  archiveprefix  = {arXiv},
  doi            = {10.1103/physrevlett.120.141103},
  eprint         = {1712.06041v2},
  eprintclass    = {astro-ph.IM},
  eprinttype     = {arXiv},
  file           = {1712.06041v2\:PDF:\:2018Gabbard-MatchingMatchedFiltering.pdf\:PDF\;online\:http/\:/arxiv.org/pdf/1712.06041v2\:PDF:PDF},
  keywords       = {astro-ph.IM, gr-qc, relevant, read, prio1, qualityAssured},
  primaryclass   = {astro-ph.IM},
  publisher      = {APS},
}

@Article{2014Cao-Gravitationallensingeffects,
  author  = {Cao, Zhoujian and Li, Li-Fang and Wang, Yan},
  title   = {Gravitational lensing effects on parameter estimation in gravitational wave detection with advanced detectors},
  journal = {Phys. Rev.},
  year    = {2014},
  volume  = {D90},
  number  = {6},
  pages   = {062003},
  doi     = {10.1103/PhysRevD.90.062003},
}

@Article{1915Einstein-FieldEquationsGravitation,
  author  = {Einstein, Albert},
  title   = {The Field Equations of Gravitation},
  journal = {Sitzungsber. Preuss. Akad. Wiss. Berlin (Math. Phys.)},
  year    = {1915},
  volume  = {1915},
  pages   = {844--847},
}

%%% contains utf-8, see: https://inspirehep.net/info/faq/general#utf8
%%% add \usepackage[utf8]{inputenc} to your latex preamble

@Article{2016Abbott-DirectlycomparingGW150914,
  author        = {Abbott, B. P. and others},
  title         = {Directly comparing GW150914 with numerical solutions of Einstein’s equations for binary black hole coalescence},
  journal       = {Phys. Rev.},
  year          = {2016},
  volume        = {D94},
  number        = {6},
  pages         = {064035},
  archiveprefix = {arXiv},
  collaboration = {LIGO Scientific, Virgo},
  doi           = {10.1103/PhysRevD.94.064035},
  eprint        = {1606.01262},
  primaryclass  = {gr-qc},
  reportnumber  = {LIGO-P1500263},
}

@InProceedings{2017Huerta-BOSSLDGNovel,
  author        = {Huerta, E. A. and others},
  title         = {BOSS-LDG: A Novel Computational Framework that Brings Together Blue Waters, Open Science Grid, Shifter and the LIGO Data Grid to Accelerate Gravitational Wave Discovery},
  booktitle     = {Proceedings, 13th International Conference on e-Science: Auckland, New Zealand, October 24-27, 2017},
  year          = {2017},
  pages         = {335--344},
  archiveprefix = {arXiv},
  doi           = {10.1109/eScience.2017.47},
  eprint        = {1709.08767},
  primaryclass  = {cs.DC},
}

@Article{2013Gerosa-Resonantplanelocking,
  author        = {Gerosa, Davide and Kesden, Michael and Berti, Emanuele and O'Shaughnessy, Richard and Sperhake, Ulrich},
  title         = {Resonant-plane locking and spin alignment in stellar-mass black-hole binaries: a diagnostic of compact-binary formation},
  journal       = {Phys. Rev.},
  year          = {2013},
  volume        = {D87},
  pages         = {104028},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.87.104028},
  eprint        = {1302.4442},
  primaryclass  = {gr-qc},
}

@Article{2015Rodriguez-BinaryBlackHole,
  author        = {Rodriguez, Carl L. and Morscher, Meagan and Pattabiraman, Bharath and Chatterjee, Sourav and Haster, Carl-Johan and Rasio, Frederic A.},
  title         = {Binary Black Hole Mergers from Globular Clusters: Implications for Advanced LIGO},
  journal       = {Phys. Rev. Lett.},
  year          = {2015},
  volume        = {115},
  number        = {5},
  pages         = {051101},
  note          = {[Erratum: Phys. Rev. Lett.116,no.2,029901(2016)]},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevLett.116.029901,
                        10.1103/PhysRevLett.115.051101},
  eprint        = {1505.00792},
  primaryclass  = {astro-ph.HE},
}

@Article{2013Naoz-ResonantPostNewtonian,
  author        = {Naoz, Smadar and Kocsis, Bence and Loeb, Abraham and Yunes, Nicolas},
  title         = {Resonant Post-Newtonian Eccentricity Excitation in Hierarchical Three-body Systems},
  journal       = {Astrophys. J.},
  year          = {2013},
  volume        = {773},
  pages         = {187},
  archiveprefix = {arXiv},
  doi           = {10.1088/0004-637X/773/2/187},
  eprint        = {1206.4316},
  primaryclass  = {astro-ph.SR},
}

@Article{2014Samsing-FormationEccentricCompact,
  author        = {Samsing, Johan and MacLeod, Morgan and Ramirez-Ruiz, Enrico},
  title         = {The Formation of Eccentric Compact Binary Inspirals and the Role of Gravitational Wave Emission in Binary-Single Stellar Encounters},
  journal       = {Astrophys. J.},
  year          = {2014},
  volume        = {784},
  pages         = {71},
  archiveprefix = {arXiv},
  doi           = {10.1088/0004-637X/784/1/71},
  eprint        = {1308.2964},
  primaryclass  = {astro-ph.HE},
}

@Article{2014Lehner-NumericalRelativityAstrophysics,
  author        = {Lehner, Luis and Pretorius, Frans},
  title         = {Numerical Relativity and Astrophysics},
  journal       = {Ann. Rev. Astron. Astrophys.},
  year          = {2014},
  volume        = {52},
  pages         = {661--694},
  archiveprefix = {arXiv},
  doi           = {10.1146/annurev-astro-081913-040031},
  eprint        = {1405.4840},
  primaryclass  = {astro-ph.HE},
}

@Article{2013Huerta-Effecteccentricitybinary,
  author        = {Huerta, E. A. and Brown, Duncan A.},
  title         = {Effect of eccentricity on binary neutron star searches in Advanced LIGO},
  journal       = {Phys. Rev.},
  year          = {2013},
  volume        = {D87},
  number        = {12},
  pages         = {127501},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.87.127501},
  eprint        = {1301.1895},
  primaryclass  = {gr-qc},
  reportnumber  = {LIGO-DCC-1200187, KITP-NUMBER-NSF-KITP-12-194},
}

%%% contains utf-8, see: https://inspirehep.net/info/faq/general#utf8
%%% add \usepackage[utf8]{inputenc} to your latex preamble

@Article{2016Harry-SearchingGravitationalWaves,
  author        = {Harry, Ian and Privitera, Stephen and Bohé, Alejandro and Buonanno, Alessandra},
  title         = {Searching for Gravitational Waves from Compact Binaries with Precessing Spins},
  journal       = {Phys. Rev.},
  year          = {2016},
  volume        = {D94},
  number        = {2},
  pages         = {024012},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.94.024012},
  eprint        = {1603.02444},
  primaryclass  = {gr-qc},
}

@Article{2017Esteva-Dermatologistlevelclassification,
  author   = {Esteva, Andre and Kuprel, Brett and Novoa, Roberto A. and Ko, Justin and Swetter, Susan M. and Blau, Helen M. and Thrun, Sebastian},
  journal  = {Nature},
  title    = {Dermatologist-level classification of skin cancer with deep neural networks},
  year     = {2017},
  issn     = {1476-4687},
  month    = feb,
  number   = {7639},
  pages    = {115--118},
  volume   = {542},
  abstract = {An artificial intelligence trained to classify images of skin lesions as benign lesions or malignant skin cancers achieves the accuracy of board-certified dermatologists.},
  doi      = {10.1038/nature21056},
  refid    = {Esteva2017},
}

@Article{2016Silver-MasteringgameGo,
  author    = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  journal   = {nature},
  title     = {Mastering the game of Go with deep neural networks and tree search},
  year      = {2016},
  issn      = {1476-4687},
  number    = {7587},
  pages     = {484},
  volume    = {529},
  abstract  = {The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses \textquoteleftvalue networks\textquoteright to evaluate board positions and \textquoteleftpolicy networks\textquoteright to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.},
  doi       = {10.1038/nature16961},
  publisher = {Nature Publishing Group},
  refid     = {Silver2016},
}

@Article{2017Silver-MasteringgameGo,
  author   = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and van den Driessche, George and Graepel, Thore and Hassabis, Demis},
  journal  = {Nature},
  title    = {Mastering the game of Go without human knowledge},
  year     = {2017},
  issn     = {1476-4687},
  month    = oct,
  number   = {7676},
  pages    = {354--359},
  volume   = {550},
  abstract = {A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, superhuman proficiency in challenging domains. Recently, AlphaGo became the first program to defeat a world champion in the game of Go. The tree search in AlphaGo evaluated positions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. Here we introduce an algorithm based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules. AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo’s own move selections and also the winner of AlphaGo’s games. This neural network improves the strength of the tree search, resulting in higher quality move selection and stronger self-play in the next iteration. Starting tabula rasa, our new program AlphaGo Zero achieved superhuman performance, winning 100-0 against the previously published, champion-defeating AlphaGo.},
  doi      = {10.1038/nature24270},
  refid    = {Silver2017},
}

@InProceedings{2016OShea-ConvolutionalRadioModulation,
  author    = {O'Shea, Timothy J. and Corgan, Johnathan and Clancy, T. Charles},
  title     = {Convolutional Radio Modulation Recognition Networks},
  booktitle = {Engineering Applications of Neural Networks},
  year      = {2016},
  editor    = {Jayne, Chrisina and Iliadis, Lazaros},
  pages     = {213--226},
  address   = {Cham},
  publisher = {Springer International Publishing},
  abstract  = {We study the adaptation of convolutional neural networks to the complex-valued temporal radio signal domain. We compare the efficacy of radio modulation classification using naively learned features against using expert feature based methods which are widely used today and e show significant performance improvements. We show that blind temporal learning on large and densely encoded time series using deep convolutional neural networks is viable and a strong candidate approach for this task especially at low signal to noise ratio.},
  isbn      = {978-3-319-44188-7},
}

@Article{2017Hezaveh-FastAutomatedAnalysis,
  author        = {Hezaveh, Yashar D. and Perreault Levasseur, Laurence and Marshall, Philip J.},
  title         = {Fast Automated Analysis of Strong Gravitational Lenses with Convolutional Neural Networks},
  journal       = {Nature},
  year          = {2017},
  volume        = {548},
  pages         = {555--557},
  archiveprefix = {arXiv},
  doi           = {10.1038/nature23463},
  eprint        = {1708.08842},
  primaryclass  = {astro-ph.IM},
}

@Article{2018Hinners-MachineLearningTechniques,
  author    = {Hinners, Trisha A. and Tat, Kevin and Thorp, Rachel},
  journal   = {The Astronomical Journal},
  title     = {Machine Learning Techniques for Stellar Light Curve Classification},
  year      = {2018},
  month     = jun,
  number    = {1},
  pages     = {7},
  volume    = {156},
  abstract  = {We apply machine learning techniques in an attempt to predict and classify stellar properties from noisy and sparse time-series data. We preprocessed over 94 GB of Kepler light curves from the Mikulski Archive for Space Telescopes (MAST) to classify according to 10 distinct physical properties using both representation learning and feature engineering approaches. Studies using machine learning in the field have been primarily done on simulated data, making our study one of the first to use real light-curve data for machine learning approaches. We tuned our data using previous work with simulated data as a template and achieved mixed results between the two approaches. Representation learning using a long short-term memory recurrent neural network produced no successful predictions, but our work with feature engineering was successful for both classification and regression. In particular, we were able to achieve values for stellar density, stellar radius, and effective temperature with low error (∼2%–4%) and good accuracy (∼75%) for classifying the number of transits for a given star. The results show promise for improvement for both approaches upon using larger data sets with a larger minority class. This work has the potential to provide a foundation for future tools and techniques to aid in the analysis of astrophysical data.},
  doi       = {10.3847/1538-3881/aac16d},
  publisher = {American Astronomical Society},
}

@Article{2017Sedaghat-EffectiveImageDifferencing,
  author        = {Sedaghat, Nima and Mahabal, Ashish},
  title         = {Effective Image Differencing with ConvNets for Real-time Transient Hunting},
  year          = {2017},
  month         = oct,
  abstract      = {Large sky surveys are increasingly relying on image subtraction pipelines for real-time (and archival) transient detection. In this process one has to contend with varying PSF, small brightness variations in many sources, as well as artifacts resulting from saturated stars, and, in general, matching errors. Very often the differencing is done with a reference image that is deeper than individual images and the attendant difference in noise characteristics can also lead to artifacts. We present here a deep-learning approach to transient detection that encapsulates all the steps of a traditional image subtraction pipeline – image registration, background subtraction, noise removal, psf matching, and subtraction – into a single real-time convolutional network. Once trained the method works lighteningly fast, and given that it does multiple steps at one go, the advantages for multi-CCD, fast surveys like ZTF and LSST are obvious.},
  archiveprefix = {arXiv},
  doi           = {10.1093/mnras/sty613},
  eprint        = {http://arxiv.org/abs/1710.01422v1},
  file          = {1710.01422v1\:PDF:\:http/\:/arxiv.org/pdf/1710.01422v1\:PDF:PDF},
  keywords      = {astro-ph.IM, cs.CV},
  primaryclass  = {astro-ph.IM},
}

@Article{2017Pearson-SearchingExoplanetsUsing,
  author        = {Pearson, Kyle A. and Palafox, Leon and Griffith, Caitlin A.},
  title         = {Searching for Exoplanets Using Artificial Intelligence},
  year          = {2017},
  month         = jun,
  abstract      = {In the last decade, over a million stars were monitored to detect transiting planets. Manual interpretation of potential exoplanet candidates is labor intensive and subject to human error, the results of which are difficult to quantify. Here we present a new method of detecting exoplanet candidates in large planetary search projects which, unlike current methods uses a neural network. Neural networks, also called "deep learning" or "deep nets" are designed to give a computer perception into a specific problem by training it to recognize patterns. Unlike past transit detection algorithms deep nets learn to recognize planet features instead of relying on hand-coded metrics that humans perceive as the most representative. Our convolutional neural network is capable of detecting Earth-like exoplanets in noisy time-series data with a greater accuracy than a least-squares method. Deep nets are highly generalizable allowing data to be evaluated from different time series after interpolation without compromising performance. As validated by our deep net analysis of Kepler light curves, we detect periodic transits consistent with the true period without any model fitting. Our study indicates that machine learning will facilitate the characterization of exoplanets in future analysis of large astronomy data sets.},
  archiveprefix = {arXiv},
  doi           = {10.1093/mnras/stx2761},
  eprint        = {http://arxiv.org/abs/1706.04319v2},
  file          = {1706.04319v2\:PDF:\:http/\:/arxiv.org/pdf/1706.04319v2\:PDF:PDF},
  keywords      = {astro-ph.IM, astro-ph.EP},
  primaryclass  = {astro-ph.IM},
}

@Article{2017Caron-Analyzingγrays,
  author        = {Caron, Sascha and Gómez-Vargas, Germán A. and Hendriks, Luc and de Austri, Roberto Ruiz},
  journal       = {Journal of Cosmology and Astroparticle Physics, Volume 2018, May 2018},
  title         = {Analyzing γ-rays of the Galactic Center with Deep Learning},
  year          = {2017},
  month         = aug,
  abstract      = {We present a new method to interpret the γ-ray data of our inner Galaxy as measured by the Fermi Large Area Telescope (Fermi LAT). We train and test convolutional neural networks with simulated Fermi-LAT images based on models tuned to real data. We use this method to investigate the origin of an excess emission of GeV γ-rays seen in previous studies. Interpretations of this excess include γ rays created by the annihilation of dark matter particles and γ rays originating from a collection of unresolved point sources, such as millisecond pulsars. Our new method allows precise measurements of the contribution and properties of an unresolved population of γ-ray point sources in the interstellar diffuse emission model.},
  archiveprefix = {arXiv},
  doi           = {10.1088/1475-7516/2018/05/058},
  eprint        = {http://arxiv.org/abs/1708.06706v2},
  file          = {1708.06706v2\:PDF:\:http/\:/arxiv.org/pdf/1708.06706v2\:PDF:PDF},
  keywords      = {astro-ph.HE, hep-ph},
  primaryclass  = {astro-ph.HE},
}

@Article{2018George-Classificationunsupervisedclustering,
  author  = {George, Daniel and Shen, Hongyu and Huerta, E. A.},
  title   = {Classification and unsupervised clustering of LIGO data with Deep Transfer Learning},
  journal = {Phys. Rev.},
  year    = {2018},
  volume  = {D97},
  number  = {10},
  pages   = {101501},
  doi     = {10.1103/PhysRevD.97.101501},
  file    = {\:2018George-Classificationunsupervisedclustering.pdf\:PDF:\:2018George-Classificationunsupervisedclustering.pdf\:PDF:PDF},
}

@InProceedings{2017Bahaadini-DeepMultiview,
  author        = {Bahaadini, Sara and Rohani, Neda and Coughlin, Scott and Zevin, Michael and Kalogera, Vicky and Katsaggelos, Aggelos K.},
  title         = {Deep Multi-view Models for Glitch Classification},
  booktitle     = {2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year          = {2017},
  pages         = {2931--2935},
  abstract      = {Non-cosmic, non-Gaussian disturbances known as “glitches”, show up in gravitational-wave data of the Advanced Laser Interferometer Gravitational-wave Observatory, or aLIGO. In this paper, we propose a deep multi-view convolutional neural network to classify glitches automatically. The primary purpose of classifying glitches is to understand their characteristics and origin, which facilitates their removal from the data or from the detector entirely. We visualize glitches as spectrograms and leverage the state-of-the-art image classification techniques in our model. The suggested classifier is a multi-view deep neural network that exploits four different views for classification. The experimental results demonstrate that the proposed model improves the overall accuracy of the classification compared to traditional single view algorithms.},
  archiveprefix = {arXiv},
  doi           = {10.1109/ICASSP.2017.7952693},
  eprint        = {1705.00034},
  issn          = {2379-190X},
  keywords      = {cosmic rays;gravitational waves;image classification;light interferometers;neural nets;deep multiview models;automatic glitch classification;noncosmic nonGaussian disturbances;gravitational-wave data;advanced laser interferometer gravitational-wave observatory;aLIGO;deep multiview convolutional neural network;spectrograms;image classification;multiview deep neural network;Neural networks;Atmospheric modeling;Training;Spectrogram;Machine learning;Analytical models;Corporate acquisitions;Multi-view learning;deep learning;image classification;neural network},
  primaryclass  = {cs.LG},
}

@Book{2015Nielsen-Neuralnetworksdeep,
  title     = {Neural networks and deep learning},
  publisher = {Determination press San Francisco, CA, USA:},
  year      = {2015},
  author    = {Nielsen, Michael A.},
  volume    = {2018},
}

@Article{2017Moravvcik-DeepStackExpertlevel,
  author    = {Morav{\v c}{\'\i}k, Matej and Schmid, Martin and Burch, Neil and Lis{\'y}, Viliam and Morrill, Dustin and Bard, Nolan and Davis, Trevor and Waugh, Kevin and Johanson, Michael and Bowling, Michael},
  journal   = {Science},
  title     = {DeepStack: Expert-level artificial intelligence in heads-up no-limit poker},
  year      = {2017},
  issn      = {0036-8075},
  number    = {6337},
  pages     = {508--513},
  volume    = {356},
  abstract  = {Computers can beat humans at games as complex as chess or go. In these and similar games, both players have access to the same information, as displayed on the board. Although computers have the ultimate poker face, it has been tricky to teach them to be good at poker, where players cannot see their opponents\textquoteright cards. Moravčı́k et al. built a code dubbed DeepStack that managed to beat professional poker players at a two-player poker variant called heads-up no-limit Texas hold\textquoterightem. Instead of devising its strategy beforehand, DeepStack recalculated it at each step, taking into account the current state of the game. The principles behind DeepStack may enable advances in solving real-world problems that involve information asymmetry.Science, this issue p. 508Artificial intelligence has seen several breakthroughs in recent years, with games often serving as milestones. A common feature of these games is that players have perfect information. Poker, the quintessential game of imperfect information, is a long-standing challenge problem in artificial intelligence. We introduce DeepStack, an algorithm for imperfect-information settings. It combines recursive reasoning to handle information asymmetry, decomposition to focus computation on the relevant decision, and a form of intuition that is automatically learned from self-play using deep learning. In a study involving 44,000 hands of poker, DeepStack defeated, with statistical significance, professional poker players in heads-up no-limit Texas hold\textquoterightem. The approach is theoretically sound and is shown to produce strategies that are more difficult to exploit than prior approaches.},
  doi       = {10.1126/science.aam6960},
  eprint    = {https://science.sciencemag.org/content/356/6337/508.full.pdf},
  publisher = {American Association for the Advancement of Science},
  url       = {https://science.sciencemag.org/content/356/6337/508},
}

@Article{1989Arnett-SUPERNOVASN1987A,
  author  = {Arnett, W. D. and Bahcall, John N. and Kirshner, R. P. and Woosley, S. E.},
  title   = {SUPERNOVA SN1987A},
  journal = {Ann. Rev. Astron. Astrophys.},
  year    = {1989},
  volume  = {27},
  pages   = {629--700},
  doi     = {10.1146/annurev.aa.27.090189.003213},
}

%%% contains utf-8, see: https://inspirehep.net/info/faq/general#utf8
%%% add \usepackage[utf8]{inputenc} to your latex preamble

@Article{2017Abbott-EstimatingContributionDynamical,
  author        = {Abbott, B. P. and others},
  title         = {Estimating the Contribution of Dynamical Ejecta in the Kilonova Associated with GW170817},
  journal       = {Astrophys. J.},
  year          = {2017},
  volume        = {850},
  number        = {2},
  pages         = {L39},
  archiveprefix = {arXiv},
  collaboration = {LIGO Scientific, Virgo},
  doi           = {10.3847/2041-8213/aa9478},
  eprint        = {1710.05836},
  primaryclass  = {astro-ph.HE},
  reportnumber  = {LIGO-P1700309},
}

@Article{2018Aartsen-Neutrinoemissiondirection,
  author        = {Aartsen, M. G. and others},
  title         = {Neutrino emission from the direction of the blazar TXS 0506+056 prior to the IceCube-170922A alert},
  journal       = {Science},
  year          = {2018},
  volume        = {361},
  number        = {6398},
  pages         = {147--151},
  archiveprefix = {arXiv},
  collaboration = {IceCube},
  doi           = {10.1126/science.aat2890},
  eprint        = {1807.08794},
  primaryclass  = {astro-ph.HE},
}

@Article{1995LeCun-Convolutionalnetworksimages,
  author       = {LeCun, Yann and Bengio, Yoshua},
  title        = {Convolutional networks for images, speech, and time series},
  journal      = {The handbook of brain theory and neural networks},
  year         = {1995},
  volume       = {3361},
  number       = {10},
  pages        = {255--258},
  date         = {1998},
  journaltitle = {chapter Convolutional networks for images, speech, and time series},
  publisher    = {MIT Press},
}

@Article{2018Razzano-Imagebaseddeep,
  author        = {Razzano, Massimiliano and Cuoco, Elena},
  title         = {Image-based deep learning for classification of noise transients in gravitational wave detectors},
  year          = {2018},
  month         = mar,
  abstract      = {The detection of gravitational waves has inaugurated the era of gravitational astronomy and opened new avenues for the multimessenger study of cosmic sources. Thanks to their sensitivity, the Advanced LIGO and Advanced Virgo interferometers will probe a much larger volume of space and expand the capability of discovering new gravitational wave emitters. The characterization of these detectors is a primary task in order to recognize the main sources of noise and optimize the sensitivity of interferometers. Glitches are transient noise events that can impact the data quality of the interferometers and their classification is an important task for detector characterization. Deep learning techniques are a promising tool for the recognition and classification of glitches. We present a classification pipeline that exploits convolutional neural networks to classify glitches starting from their time-frequency evolution represented as images. We evaluated the classification accuracy on simulated glitches, showing that the proposed algorithm can automatically classify glitches on very fast timescales and with high accuracy, thus providing a promising tool for online detector characterization.},
  archiveprefix = {arXiv},
  eprint        = {1803.09933v1},
  file          = {1803.09933v1\:PDF:\:2018Razzano-Imagebaseddeep.pdf\:PDF\;online\:http/\:/arxiv.org/pdf/1803.09933v1\:PDF:PDF},
  keywords      = {gr-qc, astro-ph.IM, cs.CV, relevant},
  primaryclass  = {gr-qc},
}

@Article{2019Coughlin-Classifyingunknowndiscovering,
  author        = {Coughlin, S. B. and Bahaadini, S. and Rohani, N. and Zevin, M. and Patane, O. and Harandi, M. and Jackson, C. and Noroozi, V. and Allen, S. and Areeda, J. and Coughlin, M. W. and Ruiz, P. and Berry, C. P. L. and Crowston, K. and Katsaggelos, A. K. and Lundgren, A. and Osterlund, C. and Smith, J. R. and Trouille, L. and Kalogera, V.},
  title         = {Classifying the unknown: discovering novel gravitational-wave detector glitches using similarity learning},
  year          = {2019},
  month         = mar,
  abstract      = {The observation of gravitational waves from compact binary coalescences by LIGO and Virgo has begun a new era in astronomy. A critical challenge in making detections is determining whether loud transient features in the data are caused by gravitational waves or by instrumental or environmental sources. The citizen-science project \emph{Gravity Spy} has been demonstrated as an efficient infrastructure for classifying known types of noise transients (glitches) through a combination of data analysis performed by both citizen volunteers and machine learning. We present the next iteration of this project, using similarity indices to empower citizen scientists to create large data sets of unknown transients, which can then be used to facilitate supervised machine-learning characterization. This new evolution aims to alleviate a persistent challenge that plagues both citizen-science and instrumental detector work: the ability to build large samples of relatively rare events. Using two families of transient noise that appeared unexpectedly during LIGO's second observing run (O2), we demonstrate the impact that the similarity indices could have had on finding these new glitch types in the Gravity Spy program.},
  archiveprefix = {arXiv},
  eprint        = {http://arxiv.org/abs/1903.04058v1},
  file          = {1903.04058v1\:PDF:\:2019Coughlin-Classifyingunknowndiscovering.pdf\:PDF\;\:http/\:/arxiv.org/pdf/1903.04058v1\:PDF:PDF},
  keywords      = {astro-ph.IM, gr-qc},
  primaryclass  = {astro-ph.IM},
}

@Article{2018Bahaadini-MachinelearningGravity,
  author    = {Bahaadini, S. and Noroozi, V. and Rohani, N. and Coughlin, S. and Zevin, M. and Smith, J. R. and Kalogera, V. and Katsaggelos, A.},
  title     = {Machine learning for Gravity Spy: Glitch classification and dataset},
  journal   = {Information Sciences},
  year      = {2018},
  volume    = {444},
  pages     = {172--186},
  month     = may,
  doi       = {10.1016/j.ins.2018.02.068},
  publisher = {Elsevier {BV}},
}

@Article{2019Shen-DeepLearningScale,
  author        = {Shen, Hongyu and Huerta, E. A. and Zhao, Zhizhen},
  title         = {Deep Learning at Scale for Gravitational Wave Parameter Estimation of Binary Black Hole Mergers},
  year          = {2019},
  month         = mar,
  abstract      = {We present the first application of deep learning at scale to do gravitational wave parameter estimation of binary black hole mergers that describe a 4-D signal manifold, i.e., black holes whose spins are aligned or anti-aligned, and which evolve on quasi-circular orbits. We densely sample this 4-D signal manifold using over three hundred thousand simulated waveforms. In order to cover a broad range of astrophysically motivated scenarios, we synthetically enhance this waveform dataset to ensure that our deep learning algorithms can process waveforms located at any point in the data stream of gravitational wave detectors (time invariance) for a broad range of signal-to-noise ratios (scale invariance), which in turn means that our neural network models are trained with over 10⁷ waveform signals. We then apply these neural network models to estimate the astrophysical parameters of black hole mergers, and their corresponding black hole remnants, including the final spin and the gravitational wave quasi-normal frequencies. These neural network models represent the first time deep learning is used to provide point-parameter estimation calculations endowed with statistical errors. For each binary black hole merger that ground-based gravitational wave detectors have observed, our deep learning algorithms can reconstruct its parameters within 2 milliseconds using a single Tesla V100 GPU. We show that this new approach produces parameter estimation results that are consistent with Bayesian analyses that have been used to reconstruct the parameters of the catalog of binary black hole mergers observed by the advanced LIGO and Virgo detectors.},
  archiveprefix = {arXiv},
  eprint        = {http://arxiv.org/abs/1903.01998v1},
  file          = {1903.01998v1\:PDF:\:2019Shen-DeepLearningScale.pdf\:PDF\;\:http/\:/arxiv.org/pdf/1903.01998v1\:PDF:PDF},
  keywords      = {gr-qc, astro-ph.HE, cs.AI, cs.LG, stat.ML, 68T10, 85-08, I.2},
  primaryclass  = {gr-qc},
}

@Article{2017Cai-gravitationalwavephysics,
  author        = {Cai, Rong-Gen and Cao, Zhoujian and Guo, Zong-Kuan and Wang, Shao-Jiang and Yang, Tao},
  title         = {The gravitational-wave physics},
  journal       = {Natl. Sci. Rev.},
  year          = {2017},
  volume        = {4},
  number        = {5},
  pages         = {687--706},
  month         = apr,
  archiveprefix = {arXiv},
  doi           = {10.1093/nsr/nwx029},
  eprint        = {1703.00187},
  journaltitle  = {National Science Review},
  primaryclass  = {gr-qc},
  publisher     = {Oxford University Press ({OUP})},
}

@Article{2014Hannam-SimpleModelComplete,
  author        = {Hannam, Mark and Schmidt, Patricia and Bohé, Alejandro and Haegel, Leïla and Husa, Sascha and Ohme, Frank and Pratten, Geraint and Pürrer, Michael},
  title         = {Simple Model of Complete Precessing Black-Hole-Binary Gravitational Waveforms},
  journal       = {Phys. Rev. Lett.},
  year          = {2014},
  volume        = {113},
  number        = {15},
  pages         = {151101},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevLett.113.151101},
  eprint        = {1308.3271},
  primaryclass  = {gr-qc},
}

%%% contains utf-8, see: https://inspirehep.net/info/faq/general#utf8
%%% add \usepackage[utf8]{inputenc} to your latex preamble

@Article{2014Pan-Inspiralmergerringdown,
  author        = {Pan, Yi and Buonanno, Alessandra and Taracchini, Andrea and Kidder, Lawrence E. and Mroué, Abdul H. and Pfeiffer, Harald P. and Scheel, Mark A. and Szilágyi, Béla},
  title         = {Inspiral-merger-ringdown waveforms of spinning, precessing black-hole binaries in the effective-one-body formalism},
  journal       = {Phys. Rev.},
  year          = {2014},
  volume        = {D89},
  number        = {8},
  pages         = {084006},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.89.084006},
  eprint        = {1307.6232},
  primaryclass  = {gr-qc},
}

%%% contains utf-8, see: https://inspirehep.net/info/faq/general#utf8
%%% add \usepackage[utf8]{inputenc} to your latex preamble

@Article{2015Blackman-FastAccuratePrediction,
  author        = {Blackman, Jonathan and Field, Scott E. and Galley, Chad R. and Szilágyi, Béla and Scheel, Mark A. and Tiglio, Manuel and Hemberger, Daniel A.},
  title         = {Fast and Accurate Prediction of Numerical Relativity Waveforms from Binary Black Hole Coalescences Using Surrogate Models},
  journal       = {Phys. Rev. Lett.},
  year          = {2015},
  volume        = {115},
  number        = {12},
  pages         = {121102},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevLett.115.121102},
  eprint        = {1502.07758},
  primaryclass  = {gr-qc},
}

@Article{2016Klimenko-Methoddetectionreconstruction,
  author        = {Klimenko, S. and others},
  title         = {Method for detection and reconstruction of gravitational wave transients with networks of advanced detectors},
  journal       = {Phys. Rev.},
  year          = {2016},
  volume        = {D93},
  number        = {4},
  pages         = {042004},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.93.042004},
  eprint        = {1511.05999},
  primaryclass  = {gr-qc},
}

@Article{2017Biwer-Validatinggravitationalwave,
  author        = {Biwer, C. and others},
  title         = {Validating gravitational-wave detections: The Advanced LIGO hardware injection system},
  journal       = {Phys. Rev.},
  year          = {2017},
  volume        = {D95},
  number        = {6},
  pages         = {062002},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.95.062002},
  eprint        = {1612.07864},
  primaryclass  = {astro-ph.IM},
  reportnumber  = {LIGO-P1600285},
}

@Article{2019Gebhard-Convolutionalneuralnetworks,
  author         = {Gebhard, Timothy D. and Kilbertus, Niki and Harry, Ian and Schölkopf, Bernhard},
  title          = {Convolutional neural networks: a magic bullet for gravitational-wave detection?},
  year           = {2019},
  month          = apr,
  abstract       = {In the last few years, machine learning techniques, in particular convolutional neural networks, have been investigated as a method to replace or complement traditional matched filtering techniques that are used to detect the gravitational-wave signature of merging black holes. However, to date, these methods have not yet been successfully applied to the analysis of long stretches of data recorded by the Advanced LIGO and Virgo gravitational-wave observatories. In this work, we critically examine the use of convolutional neural networks as a tool to search for merging black holes. We identify the strengths and limitations of this approach, highlight some common pitfalls in translating between machine learning and gravitational-wave astronomy, and discuss the interdisciplinary challenges. In particular, we explain in detail why convolutional neural networks alone can not be used to claim a statistically significant gravitational-wave detection. However, we demonstrate how they can still be used to rapidly flag the times of potential signals in the data for a more detailed follow-up. Our convolutional neural network architecture as well as the proposed performance metrics are better suited for this task than a standard binary classifications scheme. A detailed evaluation of our approach on Advanced LIGO data demonstrates the potential of such systems as trigger generators. Finally, we sound a note of caution by constructing adversarial examples, which showcase interesting "failure modes" of our model, where inputs with no visible resemblance to real gravitational-wave signals are identified as such by the network with high confidence.},
  archiveprefix  = {arXiv},
  eprint         = {http://arxiv.org/abs/1904.08693v1},
  file           = {1904.08693v1\:PDF:\:2019Gebhard-Convolutionalneuralnetworks.pdf\:PDF\;\:http/\:/arxiv.org/pdf/1904.08693v1\:PDF:PDF},
  keywords       = {astro-ph.IM, astro-ph.HE, cs.LG, stat.ML, relevant, qualityAssured, prio1, read},
  primaryclass   = {astro-ph.IM},
}

@Article{2010Slutsky-MethodsReducingFalse,
  author        = {Slutsky, J. and others},
  title         = {Methods for Reducing False Alarms in Searches for Compact Binary Coalescences in LIGO Data},
  journal       = {Class. Quant. Grav.},
  year          = {2010},
  volume        = {27},
  pages         = {165023},
  archiveprefix = {arXiv},
  doi           = {10.1088/0264-9381/27/16/165023},
  eprint        = {1004.0998},
  primaryclass  = {gr-qc},
}

@Article{2019Collaboration-GWTC1Gravitational,
  author         = {Collaboration, The L. I. G. O. Scientific and the Virgo Collaboration and Abbott, B. P. and Abbott, R. and Abbott, T. D. and Abraham, S. and Acernese, F. and Ackley, K. and Adams, C. and Adhikari, R. X. and Adya, V. B. and Affeldt, C. and Agathos, M. and Agatsuma, K. and Aggarwal, N. and Aguiar, O. D. and Aiello, L. and Ain, A. and Ajith, P. and Allen, G. and Allocca, A. and Aloy, M. A. and Altin, P. A. and Amato, A. and Ananyeva, A. and Anderson, S. B. and Anderson, W. G. and Angelova, S. V. and Antier, S. and Appert, S. and Arai, K. and Araya, M. C. and Areeda, J. S. and Ar{\`{e}}ne, M. and Arnaud, N. and Arun, K. G. and Ascenzi, S. and Ashton, G. and Aston, S. M. and Astone, P. and Aubin, F. and Aufmuth, P. and AultONeal, K. and Austin, C. and Avendano, V. and Avila-Alvarez, A. and Babak, S. and Bacon, P. and Badaracco, F. and Bader, M. K. M. and Bae, S. and Baker, P. T. and Baldaccini, F. and Ballardin, G. and Ballmer, S. W. and Banagiri, S. and Barayoga, J. C. and Barclay, S. E. and Barish, B. C. and Barker, D. and Barkett, K. and Barnum, S. and Barone, F. and Barr, B. and Barsotti, L. and Barsuglia, M. and Barta, D. and Bartlett, J. and Bartos, I. and Bassiri, R. and Basti, A. and Bawaj, M. and Bayley, J. C. and Bazzan, M. and B{\'{e}}csy, B. and Bejger, M. and Belahcene, I. and Bell, A. S. and Beniwal, D. and Berger, B. K. and Bergmann, G. and Bernuzzi, S. and Bero, J. J. and Berry, C. P. L. and Bersanetti, D. and Bertolini, A. and Betzwieser, J. and Bhandare, R. and Bidler, J. and Bilenko, I. A. and Bilgili, S. A. and Billingsley, G. and Birch, J. and Birney, R. and Birnholtz, O. and Biscans, S. and Biscoveanu, S. and Bisht, A. and Bitossi, M. and Bizouard, M. A. and Blackburn, J. K. and Blackman, J. and Blair, C. D. and Blair, D. G. and Blair, R. M. and Bloemen, S. and Bode, N. and Boer, M. and Boetzel, Y. and Bogaert, G. and Bondu, F. and Bonilla, E. and Bonnand, R. and Booker, P. and Boom, B. A. and Booth, C. D. and Bork, R. and Boschi, V. and Bose, S. and Bossie, K. and Bossilkov, V. and Bosveld, J. and Bouffanais, Y. and Bozzi, A. and Bradaschia, C. and Brady, P. R. and Bramley, A. and Branchesi, M. and Brau, J. E. and Briant, T. and Briggs, J. H. and Brighenti, F. and Brillet, A. and Brinkmann, M. and Brisson, V. and Brockill, P. and Brooks, A. F. and Brown, D. D. and Brunett, S. and Buikema, A. and Bulik, T. and Bulten, H. J. and Buonanno, A. and Buskulic, D. and Rosell, M. J. Bustamante and Buy, C. and Byer, R. L. and Cabero, M. and Cadonati, L. and Cagnoli, G. and Cahillane, C. and Bustillo, J. Calder{\'{o}}n and Callister, T. A. and Calloni, E. and Camp, J. B. and Campbell, W. A. and Canepa, M. and Cannon, K. C. and Cao, H. and Cao, J. and Capocasa, E. and Carbognani, F. and Caride, S. and Carney, M. F. and Carullo, G. and Diaz, J. Casanueva and Casentini, C. and Caudill, S. and Cavagli{\`{a}}, M. and Cavalier, F. and Cavalieri, R. and Cella, G. and Cerd{\'{a}}-Dur{\'{a}}n, P. and Cerretani, G. and Cesarini, E. and Chaibi, O. and Chakravarti, K. and Chamberlin, S. J. and Chan, M. and Chao, S. and Charlton, P. and Chase, E. A. and Chassande-Mottin, E. and Chatterjee, D. and Chaturvedi, M. and Chatziioannou, K. and Cheeseboro, B. D. and Chen, H. Y. and Chen, X. and Chen, Y. and Cheng, H. P. and Cheong, C. K. and Chia, H. Y. and Chincarini, A. and Chiummo, A. and Cho, G. and Cho, H. S. and Cho, M. and Christensen, N. and Chu, Q. and Chua, S. and Chung, K. W. and Chung, S. and Ciani, G. and Ciobanu, A. A. and Ciolfi, R. and Cipriano, F. and Cirone, A. and Clara, F. and Clark, J. A. and Clearwater, P. and Cleva, F. and Cocchieri, C. and Coccia, E. and Cohadon, P. F. and Cohen, D. and Colgan, R. and Colleoni, M. and Collette, C. G. and Collins, C. and Cominsky, L. R. and Jr., M. Constancio and Conti, L. and Cooper, S. J. and Corban, P. and Corbitt, T. R. and Cordero-Carri{\'{o}}n, I. and Corley, K. R. and Cornish, N. and Corsi, A. and Cortese, S. and Costa, C. A. and Cotesta, R. and Coughlin, M. W. and Coughlin, S. B. and Coulon, J. P. and Countryman, S. T. and Couvares, P. and Covas, P. B. and Cowan, E. E. and Coward, D. M. and Cowart, M. J. and Coyne, D. C. and Coyne, R. and Creighton, J. D. E. and Creighton, T. D. and Cripe, J. and Croquette, M. and Crowder, S. G. and Cullen, T. J. and Cumming, A. and Cunningham, L. and Cuoco, E. and Canton, T. Dal and D{\'{a}}lya, G. and Danilishin, S. L. and D'Antonio, S. and Danzmann, K. and Dasgupta, A. and Costa, C. F. Da Silva and Datrier, L. E. H. and Dattilo, V. and Dave, I. and Davier, M. and Davis, D. and Daw, E. J. and DeBra, D. and Deenadayalan, M. and Degallaix, J. and Laurentis, M. De and Del{\'{e}}glise, S. and Pozzo, W. Del and DeMarchi, L. M. and Demos, N. and Dent, T. and Pietri, R. De and Derby, J. and Rosa, R. De and Rossi, C. De and DeSalvo, R. and de Varona, O. and Dhurandhar, S. and D{\'{i}}az, M. C. and Dietrich, T. and Fiore, L. Di and Giovanni, M. Di and Girolamo, T. Di and Lieto, A. Di and Ding, B. and Pace, S. Di and Palma, I. Di and Renzo, F. Di and Dmitriev, A. and Doctor, Z. and Donovan, F. and Dooley, K. L. and Doravari, S. and Dorrington, I. and Downes, T. P. and Drago, M. and Driggers, J. C. and Du, Z. and Ducoin, J. G. and Dupej, P. and Dwyer, S. E. and Easter, P. J. and Edo, T. B. and Edwards, M. C. and Effler, A. and Ehrens, P. and Eichholz, J. and Eikenberry, S. S. and Eisenmann, M. and Eisenstein, R. A. and Essick, R. C. and Estelles, H. and Estevez, D. and Etienne, Z. B. and Etzel, T. and Evans, M. and Evans, T. M. and Fafone, V. and Fair, H. and Fairhurst, S. and Fan, X. and Farinon, S. and Farr, B. and Farr, W. M. and Fauchon-Jones, E. J. and Favata, M. and Fays, M. and Fazio, M. and Fee, C. and Feicht, J. and Fejer, M. M. and Feng, F. and Fernandez-Galiana, A. and Ferrante, I. and Ferreira, E. C. and Ferreira, T. A. and Ferrini, F. and Fidecaro, F. and Fiori, I. and Fiorucci, D. and Fishbach, M. and Fisher, R. P. and Fishner, J. M. and Fitz-Axen, M. and Flaminio, R. and Fletcher, M. and Flynn, E. and Fong, H. and Font, J. A. and Forsyth, P. W. F. and Fournier, J. D. and Frasca, S. and Frasconi, F. and Frei, Z. and Freise, A. and Frey, R. and Frey, V. and Fritschel, P. and Frolov, V. V. and Fulda, P. and Fyffe, M. and Gabbard, H. A. and Gadre, B. U. and Gaebel, S. M. and Gair, J. R. and Gammaitoni, L. and Ganija, M. R. and Gaonkar, S. G. and Garcia, A. and Garc{\'{i}}a-Quir{\'{o}}s, C. and Garufi, F. and Gateley, B. and Gaudio, S. and Gaur, G. and Gayathri, V. and Gemme, G. and Genin, E. and Gennai, A. and George, D. and George, J. and Gergely, L. and Germain, V. and Ghonge, S. and Ghosh, Abhirup and Ghosh, Archisman and Ghosh, S. and Giacomazzo, B. and Giaime, J. A. and Giardina, K. D. and Giazotto, A. and Gill, K. and Giordano, G. and Glover, L. and Godwin, P. and Goetz, E. and Goetz, R. and Goncharov, B. and Gonz{\'{a}}lez, G. and Castro, J. M. Gonzalez and Gopakumar, A. and Gorodetsky, M. L. and Gossan, S. E. and Gosselin, M. and Gouaty, R. and Grado, A. and Graef, C. and Granata, M. and Grant, A. and Gras, S. and Grassia, P. and Gray, C. and Gray, R. and Greco, G. and Green, A. C. and Green, R. and Gretarsson, E. M. and Groot, P. and Grote, H. and Grunewald, S. and Gruning, P. and Guidi, G. M. and Gulati, H. K. and Guo, Y. and Gupta, A. and Gupta, M. K. and Gustafson, E. K. and Gustafson, R. and Haegel, L. and Halim, O. and Hall, B. R. and Hall, E. D. and Hamilton, E. Z. and Hammond, G. and Haney, M. and Hanke, M. M. and Hanks, J. and Hanna, C. and Hannam, M. D. and Hannuksela, O. A. and Hanson, J. and Hardwick, T. and Haris, K. and Harms, J. and Harry, G. M. and Harry, I. W. and Haster, C. J. and Haughian, K. and Hayes, F. J. and Healy, J. and Heidmann, A. and Heintze, M. C. and Heitmann, H. and Hello, P. and Hemming, G. and Hendry, M. and Heng, I. S. and Hennig, J. and Heptonstall, A. W. and Vivanco, Francisco Hernandez and Heurs, M. and Hild, S. and Hinderer, T. and Hoak, D. and Hochheim, S. and Hofman, D. and Holgado, A. M. and Holland, N. A. and Holt, K. and Holz, D. E. and Hopkins, P. and Horst, C. and Hough, J. and Howell, E. J. and Hoy, C. G. and Hreibi, A. and Huang, Y. and Huerta, E. A. and Huet, D. and Hughey, B. and Hulko, M. and Husa, S. and Huttner, S. H. and Huynh-Dinh, T. and Idzkowski, B. and Iess, A. and Ingram, C. and Inta, R. and Intini, G. and Irwin, B. and Isa, H. N. and Isac, J. M. and Isi, M. and Iyer, B. R. and Izumi, K. and Jacqmin, T. and Jadhav, S. J. and Jani, K. and Janthalur, N. N. and Jaranowski, P. and Jenkins, A. C. and Jiang, J. and Johnson, D. S. and Johnson-McDaniel, N. K. and Jones, A. W. and Jones, D. I. and Jones, R. and Jonker, R. J. G. and Ju, L. and Junker, J. and Kalaghatgi, C. V. and Kalogera, V. and Kamai, B. and Kandhasamy, S. and Kang, G. and Kanner, J. B. and Kapadia, S. J. and Karki, S. and Karvinen, K. S. and Kashyap, R. and Kasprzack, M. and Katsanevas, S. and Katsavounidis, E. and Katzman, W. and Kaufer, S. and Kawabe, K. and Keerthana, N. V. and K{\'{e}}f{\'{e}}lian, F. and Keitel, D. and Kennedy, R. and Key, J. S. and Khalili, F. Y. and Khan, H. and Khan, I. and Khan, S. and Khan, Z. and Khazanov, E. A. and Khursheed, M. and Kijbunchoo, N. and Kim, Chunglee and Kim, J. C. and Kim, K. and Kim, W. and Kim, W. S. and Kim, Y. M. and Kimball, C. and King, E. J. and King, P. J. and Kinley-Hanlon, M. and Kirchhoff, R. and Kissel, J. S. and Kleybolte, L. and Klika, J. H. and Klimenko, S. and Knowles, T. D. and Koch, P. and Koehlenbeck, S. M. and Koekoek, G. and Koley, S. and Kondrashov, V. and Kontos, A. and Koper, N. and Korobko, M. and Korth, W. Z. and Kowalska, I. and Kozak, D. B. and Kringel, V. and Krishnendu, N. and Kr{\'{o}}lak, A. and Kuehn, G. and Kumar, A. and Kumar, P. and Kumar, R. and Kumar, S. and Kuo, L. and Kutynia, A. and Kwang, S. and Lackey, B. D. and Lai, K. H. and Lam, T. L. and Landry, M. and Lane, B. B. and Lang, R. N. and Lange, J. and Lantz, B. and Lanza, R. K. and Lartaux-Vollard, A. and Lasky, P. D. and Laxen, M. and Lazzarini, A. and Lazzaro, C. and Leaci, P. and Leavey, S. and Lecoeuche, Y. K. and Lee, C. H. and Lee, H. K. and Lee, H. M. and Lee, H. W. and Lee, J. and Lee, K. and Lehmann, J. and Lenon, A. and Leroy, N. and Letendre, N. and Levin, Y. and Li, J. and Li, K. J. L. and Li, T. G. F. and Li, X. and Lin, F. and Linde, F. and Linker, S. D. and Littenberg, T. B. and Liu, J. and Liu, X. and Lo, R. K. L. and Lockerbie, N. A. and London, L. T. and Longo, A. and Lorenzini, M. and Loriette, V. and Lormand, M. and Losurdo, G. and Lough, J. D. and Lousto, C. O. and Lovelace, G. and Lower, M. E. and L{\"{u}}ck, H. and Lumaca, D. and Lundgren, A. P. and Lynch, R. and Ma, Y. and Macas, R. and Macfoy, S. and MacInnis, M. and Macleod, D. M. and Macquet, A. and Maga{\~{n}}a-Sandoval, F. and Zertuche, L. Maga{\~{n}}a and Magee, R. M. and Majorana, E. and Maksimovic, I. and Malik, A. and Man, N. and Mandic, V. and Mangano, V. and Mansell, G. L. and Manske, M. and Mantovani, M. and Marchesoni, F. and Marion, F. and M{\'{a}}rka, S. and M{\'{a}}rka, Z. and Markakis, C. and Markosyan, A. S. and Markowitz, A. and Maros, E. and Marquina, A. and Marsat, S. and Martelli, F. and Martin, I. W. and Martin, R. M. and Martynov, D. V. and Mason, K. and Massera, E. and Masserot, A. and Massinger, T. J. and Masso-Reid, M. and Mastrogiovanni, S. and Matas, A. and Matichard, F. and Matone, L. and Mavalvala, N. and Mazumder, N. and McCann, J. J. and McCarthy, R. and McClelland, D. E. and McCormick, S. and McCuller, L. and McGuire, S. C. and McIver, J. and McManus, D. J. and McRae, T. and McWilliams, S. T. and Meacher, D. and Meadors, G. D. and Mehmet, M. and Mehta, A. K. and Meidam, J. and Melatos, A. and Mendell, G. and Mercer, R. A. and Mereni, L. and Merilh, E. L. and Merzougui, M. and Meshkov, S. and Messenger, C. and Messick, C. and Metzdorff, R. and Meyers, P. M. and Miao, H. and Michel, C. and Middleton, H. and Mikhailov, E. E. and Milano, L. and Miller, A. L. and Miller, A. and Millhouse, M. and Mills, J. C. and Milovich-Goff, M. C. and Minazzoli, O. and Minenkov, Y. and Mishkin, A. and Mishra, C. and Mistry, T. and Mitra, S. and Mitrofanov, V. P. and Mitselmakher, G. and Mittleman, R. and Mo, G. and Moffa, D. and Mogushi, K. and Mohapatra, S. R. P. and Montani, M. and Moore, C. J. and Moraru, D. and Moreno, G. and Morisaki, S. and Mours, B. and Mow-Lowry, C. M. and Mukherjee, Arunava and Mukherjee, D. and Mukherjee, S. and Mukund, N. and Mullavey, A. and Munch, J. and Mu{\~{n}}iz, E. A. and Muratore, M. and Murray, P. G. and Nagar, A. and Nardecchia, I. and Naticchioni, L. and Nayak, R. K. and Neilson, J. and Nelemans, G. and Nelson, T. J. N. and Nery, M. and Neunzert, A. and Ng, K. Y. and Ng, S. and Nguyen, P. and Nichols, D. and Nielsen, A. B. and Nissanke, S. and Nitz, A. and Nocera, F. and North, C. and Nuttall, L. K. and Obergaulinger, M. and Oberling, J. and O'Brien, B. D. and O'Dea, G. D. and Ogin, G. H. and Oh, J. J. and Oh, S. H. and Ohme, F. and Ohta, H. and Okada, M. A. and Oliver, M. and Oppermann, P. and Oram, Richard J. and O'Reilly, B. and Ormiston, R. G. and Ortega, L. F. and O'Shaughnessy, R. and Ossokine, S. and Ottaway, D. J. and Overmier, H. and Owen, B. J. and Pace, A. E. and Pagano, G. and Page, M. A. and Pai, A. and Pai, S. A. and Palamos, J. R. and Palashov, O. and Palomba, C. and Pal-Singh, A. and Pan, Huang-Wei and Pang, B. and Pang, P. T. H. and Pankow, C. and Pannarale, F. and Pant, B. C. and Paoletti, F. and Paoli, A. and Papa, M. A. and Parida, A. and Parker, W. and Pascucci, D. and Pasqualetti, A. and Passaquieti, R. and Passuello, D. and Patil, M. and Patricelli, B. and Pearlstone, B. L. and Pedersen, C. and Pedraza, M. and Pedurand, R. and Pele, A. and Penn, S. and Perego, A. and Perez, C. J. and Perreca, A. and Pfeiffer, H. P. and Phelps, M. and Phukon, K. S. and Piccinni, O. J. and Pichot, M. and Piergiovanni, F. and Pillant, G. and Pinard, L. and Pirello, M. and Pitkin, M. and Poggiani, R. and Pong, D. Y. T. and Ponrathnam, S. and Popolizio, P. and Porter, E. K. and Powell, J. and Prajapati, A. K. and Prasad, J. and Prasai, K. and Prasanna, R. and Pratten, G. and Prestegard, T. and Privitera, S. and Prodi, G. A. and Prokhorov, L. G. and Puncken, O. and Punturo, M. and Puppo, P. and P{\"{u}}rrer, M. and Qi, H. and Quetschke, V. and Quinonez, P. J. and Quintero, E. A. and Quitzow-James, R. and Raab, F. J. and Radkins, H. and Radulescu, N. and Raffai, P. and Raja, S. and Rajan, C. and Rajbhandari, B. and Rakhmanov, M. and Ramirez, K. E. and Ramos-Buades, A. and Rana, Javed and Rao, K. and Rapagnani, P. and Raymond, V. and Razzano, M. and Read, J. and Regimbau, T. and Rei, L. and Reid, S. and Reitze, D. H. and Ren, W. and Ricci, F. and Richardson, C. J. and Richardson, J. W. and Ricker, P. M. and Riemenschneider, G. M. and Riles, K. and Rizzo, M. and Robertson, N. A. and Robie, R. and Robinet, F. and Rocchi, A. and Rolland, L. and Rollins, J. G. and Roma, V. J. and Romanelli, M. and Romano, R. and Romel, C. L. and Romie, J. H. and Rose, K. and Rosi{{\'{n}}}ska, D. and Rosofsky, S. G. and Ross, M. P. and Rowan, S. and R{\"{u}}diger, A. and Ruggi, P. and Rutins, G. and Ryan, K. and Sachdev, S. and Sadecki, T. and Sakellariadou, M. and Salafia, O. and Salconi, L. and Saleem, M. and Salemi, F. and Samajdar, A. and Sammut, L. and Sanchez, E. J. and Sanchez, L. E. and Sanchis-Gual, N. and Sandberg, V. and Sanders, J. R. and Santiago, K. A. and Sarin, N. and Sassolas, B. and Sathyaprakash, B. S. and Saulson, P. R. and Sauter, O. and Savage, R. L. and Schale, P. and Scheel, M. and Scheuer, J. and Schmidt, P. and Schnabel, R. and Schofield, R. M. S. and Sch{\"{o}}nbeck, A. and Schreiber, E. and Schulte, B. W. and Schutz, B. F. and Schwalbe, S. G. and Scott, J. and Scott, S. M. and Seidel, E. and Sellers, D. and Sengupta, A. S. and Sennett, N. and Sentenac, D. and Sequino, V. and Sergeev, A. and Setyawati, Y. and Shaddock, D. A. and Shaffer, T. and Shahriar, M. S. and Shaner, M. B. and Shao, L. and Sharma, P. and Shawhan, P. and Shen, H. and Shink, R. and Shoemaker, D. H. and Shoemaker, D. M. and ShyamSundar, S. and Siellez, K. and Sieniawska, M. and Sigg, D. and Silva, A. D. and Singer, L. P. and Singh, N. and Singhal, A. and Sintes, A. M. and Sitmukhambetov, S. and Skliris, V. and Slagmolen, B. J. J. and Slaven-Blair, T. J. and Smith, J. R. and Smith, R. J. E. and Somala, S. and Son, E. J. and Sorazu, B. and Sorrentino, F. and Souradeep, T. and Sowell, E. and Spencer, A. P. and Srivastava, A. K. and Srivastava, V. and Staats, K. and Stachie, C. and Standke, M. and Steer, D. A. and Steinke, M. and Steinlechner, J. and Steinlechner, S. and Steinmeyer, D. and Stevenson, S. P. and Stocks, D. and Stone, R. and Stops, D. J. and Strain, K. A. and Stratta, G. and Strigin, S. E. and Strunk, A. and Sturani, R. and Stuver, A. L. and Sudhir, V. and Summerscales, T. Z. and Sun, L. and Sunil, S. and Suresh, J. and Sutton, P. J. and Swinkels, B. L. and Szczepa{{\'{n}}}czyk, M. J. and Tacca, M. and Tait, S. C. and Talbot, C. and Talukder, D. and Tanner, D. B. and T{\'{a}}pai, M. and Taracchini, A. and Tasson, J. D. and Taylor, R. and Thies, F. and Thomas, M. and Thomas, P. and Thondapu, S. R. and Thorne, K. A. and Thrane, E. and Tiwari, Shubhanshu and Tiwari, Srishti and Tiwari, V. and Toland, K. and Tonelli, M. and Tornasi, Z. and Torres-Forn{\'{e}}, A. and Torrie, C. I. and T{\"{o}}yr{\"{a}}, D. and Travasso, F. and Traylor, G. and Tringali, M. C. and Trovato, A. and Trozzo, L. and Trudeau, R. and Tsang, K. W. and Tse, M. and Tso, R. and Tsukada, L. and Tsuna, D. and Tuyenbayev, D. and Ueno, K. and Ugolini, D. and Unnikrishnan, C. S. and Urban, A. L. and Usman, S. A. and Vahlbruch, H. and Vajente, G. and Valdes, G. and van Bakel, N. and van Beuzekom, M. and van den Brand, J. F. J. and Broeck, C. Van Den and Vander-Hyde, D. C. and van Heijningen, J. V. and van der Schaaf, L. and van Veggel, A. A. and Vardaro, M. and Varma, V. and Vass, S. and Vas{\'{u}}th, M. and Vecchio, A. and Vedovato, G. and Veitch, J. and Veitch, P. J. and Venkateswara, K. and Venugopalan, G. and Verkindt, D. and Vetrano, F. and Vicer{\'{e}}, A. and Viets, A. D. and Vine, D. J. and Vinet, J. Y. and Vitale, S. and Vo, T. and Vocca, H. and Vorvick, C. and Vyatchanin, S. P. and Wade, A. R. and Wade, L. E. and Wade, M. and Walet, R. and Walker, M. and Wallace, L. and Walsh, S. and Wang, G. and Wang, H. and Wang, J. Z. and Wang, W. H. and Wang, Y. F. and Ward, R. L. and Warden, Z. A. and Warner, J. and Was, M. and Watchi, J. and Weaver, B. and Wei, L. W. and Weinert, M. and Weinstein, A. J. and Weiss, R. and Wellmann, F. and Wen, L. and Wessel, E. K. and We{\ss}els, P. and Westhouse, J. W. and Wette, K. and Whelan, J. T. and White, L. V. and Whiting, B. F. and Whittle, C. and Wilken, D. M. and Williams, D. and Williamson, A. R. and Willis, J. L. and Willke, B. and Wimmer, M. H. and Winkler, W. and Wipf, C. C. and Wittel, H. and Woan, G. and Woehler, J. and Wofford, J. K. and Worden, J. and Wright, J. L. and Wu, D. S. and Wysocki, D. M. and Xiao, L. and Yamamoto, H. and Yancey, C. C. and Yang, L. and Yap, M. J. and Yazback, M. and Yeeles, D. W. and Yu, Hang and Yu, Haocun and Yuen, S. H. R. and Yvert, M. and Zadro{\.{z}}ny, A. K. and Zanolin, M. and Zappa, F. and Zelenova, T. and Zendri, J. P. and Zevin, M. and Zhang, J. and Zhang, L. and Zhang, T. and Zhao, C. and Zhou, M. and Zhou, Z. and Zhu, X. J. and Zimmerman, A. B. and Zlochower, Y. and Zucker, M. E. and Zweizig, J.},
  journal        = {Phys. Rev.},
  title          = {GWTC-1: A Gravitational-Wave Transient Catalog of Compact Binary Mergers Observed by LIGO and Virgo during the First and Second Observing Runs},
  year           = {2019},
  number         = {3},
  pages          = {031040},
  volume         = {X9},
  abstract       = {We present the results from three gravitational-wave searches for coalescing compact binaries with component masses above 1\mathrm{M}{_}{⊙} during the first and second observing runs of the Advanced gravitational-wave detector network. During the first observing run (O1), from September 12⁽\mathrm{th}{}{,}) 2015 to January 19⁽\mathrm{th}{}{,}) 2016, gravitational waves from three binary black hole mergers were detected. The second observing run (O2), which ran from November 30⁽\mathrm{th}{}{,}) 2016 to August 25⁽\mathrm{th}{}{,}) 2017, saw the first detection of gravitational waves from a binary neutron star inspiral, in addition to the observation of gravitational waves from a total of seven binary black hole mergers, four of which we report here for the first time: GW170729, GW170809, GW170818 and GW170823. For all significant gravitational-wave events, we provide estimates of the source properties. The detected binary black holes have total masses between 18.6_(-0.7)⁽+3.1)\mathrm{M}{_}{⊙}, and 85.1_(-10.9)⁽+15.6) \mathrm{M}{_}{⊙}, and range in distance between 320₋₁₁₀⁺¹²⁰ Mpc and 2750₋₁₃₂₀⁺¹³⁵⁰ Mpc. No neutron star - black hole mergers were detected. In addition to highly significant gravitational-wave events, we also provide a list of marginal event candidates with an estimated false alarm rate less than 1 per 30 days. From these results over the first two observing runs, which include approximately one gravitational-wave detection per 15 days of data searched, we infer merger rates at the 90% confidence intervals of 110 - 3840 \mathrm{Gpc}{⁻³}{ }\mathrm{y}{⁻¹}{} for binary neutron stars and 9.7 - 101 \mathrm{Gpc}{⁻³}{ }\mathrm{y}{⁻¹}{} for binary black holes assuming fixed population distributions, and determine a neutron star - black hole merger rate 90% upper limit of 610 \mathrm{Gpc}{⁻³}{ }\mathrm{y}{⁻¹}{}.},
  archiveprefix  = {arXiv},
  collaboration  = {LIGO Scientific, Virgo},
  doi            = {10.1103/PhysRevX.9.031040},
  eprint         = {1811.12907},
  file           = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:1811.12907v2/\:PDF/\:PDF/\:1811.12907v2/\:PDF/\:/\:2018Collaboration-GWTC1Gravitational.pdf/\:PDF/\;/\:http/\:/arxiv.org/pdf/1811.12907v2/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  keywords       = {astro-ph.HE, astro-ph.CO, gr-qc, relevant, qualityAssured},
  primaryclass   = {astro-ph.HE},
  qualityassured = {qualityAssured},
  relevance      = {relevant},
  reportnumber   = {LIGO-P1800307},
}

@Article{2018Nitz-1OGCfirst,
  author         = {Nitz, Alexander H. and Capano, Collin and Nielsen, Alex B. and Reyes, Steven and White, Rebecca and Brown, Duncan A. and Krishnan, Badri},
  title          = {1-OGC: The first open gravitational-wave catalog of binary mergers from analysis of public Advanced LIGO data},
  year           = {2018},
  month          = nov,
  abstract       = {We present the first Open Gravitational-wave Catalog (1-OGC), obtained by using the public data from Advanced LIGO's first observing run to search for compact-object binary mergers. Our analysis is based on new methods that improve the separation between signals and noise in matched-filter searches for gravitational waves from the merger of compact objects. The three most significant signals in our catalog correspond to the binary black hole mergers GW150914, GW151226, and LVT151012. We assume a common population of binary black holes for these three signals by defining a region of parameter space that is consistent with these events. Under this assumption, we find that LVT151012 has a 97.6% probability of being astrophysical in origin. No other significant binary black hole candidates are found, nor did we observe any significant binary neutron star or neutron star–black hole candidates. We make available our complete catalog of events, including the sub-threshold population of candidates.},
  archiveprefix  = {arXiv},
  doi            = {10.3847/1538-4357/ab0108},
  eprint         = {http://arxiv.org/abs/1811.01921v3},
  file           = {1811.01921v3\:PDF:\:2018Nitz-1OGCfirst.pdf\:PDF\;\:http/\:/arxiv.org/pdf/1811.01921v3\:PDF:PDF},
  keywords       = {gr-qc, astro-ph.HE, relevant, qualityAssured, read},
  primaryclass   = {gr-qc},
  qualityassured = {qualityAssured},
  readstatus     = {read},
  relevance      = {relevant},
}

@Article{2019Nitz-2OGCOpen,
  author        = {Nitz, Alexander H. and Dent, Thomas and Davies, Gareth S. and Kumar, Sumit and Capano, Collin D. and Harry, Ian and Mazzon, Simone and Nuttall, Laura and Lundgren, Andrew and Tápai, Marton},
  title         = {2-OGC: Open Gravitational-wave Catalog of binary mergers from analysis of public Advanced LIGO and Virgo data},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1910.05331},
  file          = {\:2019Nitz-2OGCOpen.pdf\:PDF:\:2019Nitz-2OGCOpen.pdf\:PDF:PDF},
  primaryclass  = {astro-ph.HE},
}

@Misc{2018Coughlin-UpdatedGravitySpy,
  author    = {Coughlin, Scott},
  title     = {Updated Gravity Spy Data Set},
  year      = {2018},
  doi       = {10.5281/ZENODO.1476551},
  publisher = {Zenodo},
}

@Article{2018Zhoujian-gravitationalwavedetection,
  author    = {Zhou-jian, C. A. O.},
  journal   = {College Physics},
  title     = {From the gravitational wave detection to multi-messenger astronomy},
  year      = {2018},
  number    = {2},
  pages     = {1},
  volume    = {37},
  doi       = {10.16854/j.cnki.1000-0712.170626},
  eid       = {1},
  keywords  = {gravitational waves; gravitational wave astronomy; double black holes; double neutron stars;numerical relativity},
  numpages  = {8},
  publisher = {College Physics},
  url       = {http://dxwl.bnu.edu.cn/EN/abstract/article_7516.shtml},
}

@Book{2009Jaranowski-AnalysisGravitationalWave,
  title     = {Analysis of Gravitational-Wave Data},
  publisher = {Cambridge University Press},
  year      = {2009},
  author    = {Jaranowski, P. and Krolak, A.},
  series    = {Analysis of Gravitational Wave Data},
  isbn      = {9780521864596},
  lccn      = {2009502208},
  url       = {https://books.google.com.sg/books?id=eC9UEPyRuHoC},
}

@Book{1999Oppenheim-Discretetimesignal,
  title     = {Discrete-time signal processing},
  publisher = {Pearson Education India},
  year      = {1999},
  author    = {Oppenheim, Alan V.},
}

@Article{1992Teukolsky-NumericalrecipesC,
  author  = {Teukolsky, Saul A. and Flannery, Brian P. and Press, W. H. and Vetterling, W. T.},
  title   = {Numerical recipes in C},
  journal = {SMR},
  year    = {1992},
  volume  = {693},
  number  = {1},
  pages   = {59--70},
}

@Article{2004Lazzarini-Useoverlappingwindows,
  author  = {Lazzarini, A. and Romano, J.},
  title   = {Use of overlapping windows in the stochastic background search},
  journal = {LIGO Report, http://www. ligo. caltech. edu/docs},
  year    = {2004},
  file    = {\:2004Lazzarini-Useoverlappingwindows.pdf\:PDF:\:2004Lazzarini-Useoverlappingwindows.pdf\:PDF:PDF},
  url     = {https://dcc.ligo.org/T040089/public},
}

@Article{2019Chatziioannou-Noisespectralestimation,
  author        = {Chatziioannou, Katerina and Haster, Carl-Johan and Littenberg, Tyson B. and Farr, Will M. and Ghonge, Sudarshan and Millhouse, Margaret and Clark, James A. and Cornish, Neil},
  title         = {Noise spectral estimation methods and their impact on gravitational wave measurement of compact binary mergers},
  journal       = {Phys. Rev.},
  year          = {2019},
  volume        = {D100},
  number        = {10},
  pages         = {104004},
  month         = jul,
  abstract      = {Estimating the parameters of gravitational wave signals detected by ground-based detectors requires an understanding of the properties of the detectors' noise. In particular, the most commonly used likelihood function for gravitational wave data analysis assumes that the noise is Gaussian, stationary, and of known frequency-dependent variance. The variance of the colored Gaussian noise is used as a whitening filter on the data before computation of the likelihood function. In practice the noise variance is not known and it evolves over timescales of dozens of seconds to minutes. We study two methods for estimating this whitening filter for ground-based gravitational wave detectors with the goal of performing parameter estimation studies. The first method uses large amounts of data separated from the specific segment we wish to analyze and computes the power spectral density of the noise through the mean-median Welch method. The second method uses the same data segment as the parameter estimation analysis, which potentially includes a gravitational wave signal, and obtains the whitening filter through a fit of the power spectrum of the data in terms of a sum of splines and Lorentzians. We compare these two methods and argue that the latter is more reliable for gravitational wave parameter estimation.},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.100.104004},
  eprint        = {http://arxiv.org/abs/1907.06540v1},
  eprintclass   = {gr-qc},
  eprinttype    = {arXiv},
  file          = {1907.06540v1\:PDF:\:2019Chatziioannou-Noisespectralestimation.pdf\:PDF\;\:http/\:/arxiv.org/pdf/1907.06540v1\:PDF:PDF},
  keywords      = {gr-qc, astro-ph.HE, astro-ph.IM},
  primaryclass  = {gr-qc},
}

@Article{2010Was-backgroundestimationtime,
  author        = {Was, Michal and Bizouard, Marie-Anne and Brisson, Violette and Cavalier, Fabien and Davier, Michel and Hello, Patrice and Leroy, Nicolas and Robinet, Florent and Vavoulidis, Miltiadis},
  title         = {On the background estimation by time slides in a network of gravitational wave detectors},
  journal       = {Class. Quant. Grav.},
  year          = {2010},
  volume        = {27},
  pages         = {015005},
  archiveprefix = {arXiv},
  doi           = {10.1088/0264-9381/27/1/015005},
  eprint        = {0906.2120},
  file          = {\:2010Was-backgroundestimationtime.pdf\:PDF:\:2010Was-backgroundestimationtime.pdf\:PDF:PDF},
  primaryclass  = {gr-qc},
}

@Article{2015Coughlin-Prospectssearcheslong,
  author        = {Coughlin, Michael and Meyers, Patrick and Kandhasamy, Shivaraj and Thrane, Eric and Christensen, N.},
  title         = {Prospects for searches for long-duration gravitational-waves without time slides},
  journal       = {Phys. Rev.},
  year          = {2015},
  volume        = {D92},
  number        = {4},
  pages         = {043007},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.92.043007},
  eprint        = {1505.00205},
  file          = {\:2015Coughlin-Prospectssearcheslong.pdf\:PDF:\:2015Coughlin-Prospectssearcheslong.pdf\:PDF:PDF},
  primaryclass  = {gr-qc},
}

@Article{2017Goyal-AccurateLargeMinibatch,
  author        = {Goyal, Priya and Dollár, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
  title         = {Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour},
  year          = {2017},
  month         = jun,
  abstract      = {Deep learning thrives with large neural networks and large datasets. However, larger networks and larger datasets result in longer training times that impede research and development progress. Distributed synchronous SGD offers a potential solution to this problem by dividing SGD minibatches over a pool of parallel workers. Yet to make this scheme efficient, the per-worker workload must be large, which implies nontrivial growth in the SGD minibatch size. In this paper, we empirically show that on the ImageNet dataset large minibatches cause optimization difficulties, but when these are addressed the trained networks exhibit good generalization. Specifically, we show no loss of accuracy when training with large minibatch sizes up to 8192 images. To achieve this result, we adopt a hyper-parameter-free linear scaling rule for adjusting learning rates as a function of minibatch size and develop a new warmup scheme that overcomes optimization challenges early in training. With these simple techniques, our Caffe2-based system trains ResNet-50 with a minibatch size of 8192 on 256 GPUs in one hour, while matching small minibatch accuracy. Using commodity hardware, our implementation achieves 90% scaling efficiency when moving from 8 to 256 GPUs. Our findings enable training visual recognition models on internet-scale data with high efficiency.},
  archiveprefix = {arXiv},
  eprint        = {http://arxiv.org/abs/1706.02677v2},
  file          = {1706.02677v2\:PDF:\:http/\:/arxiv.org/pdf/1706.02677v2\:PDF:PDF},
  keywords      = {cs.CV, cs.DC, cs.LG},
  primaryclass  = {cs.CV},
}

@Article{2017You-ImageNetTrainingMinutes,
  author        = {You, Yang and Zhang, Zhao and Hsieh, Cho-Jui and Demmel, James and Keutzer, Kurt},
  title         = {ImageNet Training in Minutes},
  year          = {2017},
  month         = sep,
  abstract      = {Finishing 90-epoch ImageNet-1k training with ResNet-50 on a NVIDIA M40 GPU takes 14 days. This training requires 10¹8 single precision operations in total. On the other hand, the world's current fastest supercomputer can finish 2 * 10¹7 single precision operations per second (Dongarra et al 2017, https://www.top500.org/lists/2017/06/). If we can make full use of the supercomputer for DNN training, we should be able to finish the 90-epoch ResNet-50 training in one minute. However, the current bottleneck for fast DNN training is in the algorithm level. Specifically, the current batch size (e.g. 512) is too small to make efficient use of many processors. For large-scale DNN training, we focus on using large-batch data-parallelism synchronous SGD without losing accuracy in the fixed epochs. The LARS algorithm (You, Gitman, Ginsburg, 2017, arXiv:1708.03888) enables us to scale the batch size to extremely large case (e.g. 32K). We finish the 100-epoch ImageNet training with AlexNet in 11 minutes on 1024 CPUs. About three times faster than Facebook's result (Goyal et al 2017, arXiv:1706.02677), we finish the 90-epoch ImageNet training with ResNet-50 in 20 minutes on 2048 KNLs without losing accuracy. State-of-the-art ImageNet training speed with ResNet-50 is 74.9% top-1 test accuracy in 15 minutes. We got 74.9% top-1 test accuracy in 64 epochs, which only needs 14 minutes. Furthermore, when we increase the batch size to above 16K, our accuracy is much higher than Facebook's on corresponding batch sizes. Our source code is available upon request.},
  archiveprefix = {arXiv},
  eprint        = {http://arxiv.org/abs/1709.05011v10},
  file          = {1709.05011v10\:PDF:\:http/\:/arxiv.org/pdf/1709.05011v10\:PDF:PDF},
  keywords      = {cs.CV},
  primaryclass  = {cs.CV},
}

@Article{2016Keskar-LargeBatchTraining,
  author        = {Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter},
  title         = {On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima},
  year          = {2016},
  month         = sep,
  abstract      = {The stochastic gradient descent (SGD) method and its variants are algorithms of choice for many Deep Learning tasks. These methods operate in a small-batch regime wherein a fraction of the training data, say 32-512 data points, is sampled to compute an approximation to the gradient. It has been observed in practice that when using a larger batch there is a degradation in the quality of the model, as measured by its ability to generalize. We investigate the cause for this generalization drop in the large-batch regime and present numerical evidence that supports the view that large-batch methods tend to converge to sharp minimizers of the training and testing functions - and as is well known, sharp minima lead to poorer generalization. In contrast, small-batch methods consistently converge to flat minimizers, and our experiments support a commonly held view that this is due to the inherent noise in the gradient estimation. We discuss several strategies to attempt to help large-batch methods eliminate this generalization gap.},
  archiveprefix = {arXiv},
  eprint        = {http://arxiv.org/abs/1609.04836v2},
  file          = {1609.04836v2\:PDF:\:http/\:/arxiv.org/pdf/1609.04836v2\:PDF:PDF},
  keywords      = {cs.LG, math.OC},
  primaryclass  = {cs.LG},
}

@InCollection{2017Hoffer-Trainlongergeneralize,
  author    = {Hoffer, Elad and Hubara, Itay and Soudry, Daniel},
  title     = {Train longer, generalize better: closing the generalization gap in large batch training of neural networks},
  booktitle = {Advances in Neural Information Processing Systems 30},
  publisher = {Curran Associates, Inc.},
  year      = {2017},
  editor    = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
  pages     = {1731--1741},
  url       = {http://papers.nips.cc/paper/6770-train-longer-generalize-better-closing-the-generalization-gap-in-large-batch-training-of-neural-networks.pdf},
}

@Article{2020Yang-RethinkingBiasVariance,
  author        = {Yang, Zitong and Yu, Yaodong and You, Chong and Steinhardt, Jacob and Ma, Yi},
  title         = {Rethinking Bias-Variance Trade-off for Generalization of Neural Networks},
  year          = {2020},
  month         = feb,
  abstract      = {The classical bias-variance trade-off predicts that bias decreases and variance increase with model complexity, leading to a U-shaped risk curve. Recent work calls this into question for neural networks and other over-parameterized models, for which it is often observed that larger models generalize better. We provide a simple explanation for this by measuring the bias and variance of neural networks: while the bias is monotonically decreasing as in the classical theory, the variance is unimodal or bell-shaped: it increases then decreases with the width of the network. We vary the network architecture, loss function, and choice of dataset and confirm that variance unimodality occurs robustly for all models we considered. The risk curve is the sum of the bias and variance curves and displays different qualitative shapes depending on the relative scale of bias and variance, with the double descent curve observed in recent literature as a special case. We corroborate these empirical results with a theoretical analysis of two-layer linear networks with random first layer. Finally, evaluation on out-of-distribution data shows that most of the drop in accuracy comes from increased bias while variance increases by a relatively small amount. Moreover, we find that deeper models decrease bias and increase variance for both in-distribution and out-of-distribution data.},
  archiveprefix = {arXiv},
  eprint        = {http://arxiv.org/abs/2002.11328v1},
  file          = {2002.11328v1\:PDF:\:2020Yang-RethinkingBiasVariance.pdf\:PDF\;\:http/\:/arxiv.org/pdf/2002.11328v1\:PDF:PDF},
  keywords      = {cs.LG, stat.ML, skimmed},
  primaryclass  = {cs.LG},
}

@Article{2019Gabbard-Bayesianparameterestimation,
  author        = {Gabbard, Hunter and Messenger, Chris and Heng, Ik Siong and Tonolini, Francesco and Murray-Smith, Roderick},
  title         = {Bayesian parameter estimation using conditional variational autoencoders for gravitational-wave astronomy},
  year          = {2019},
  archiveprefix = {arXiv},
  date          = {2019},
  eprint        = {1909.06296},
  eprintclass   = {astro-ph.IM},
  eprinttype    = {arXiv},
  file          = {\:2019Gabbard-Bayesianparameterestimation.pdf\:PDF:\:2019Gabbard-Bayesianparameterestimation.pdf\:PDF:PDF},
  keywords      = {skimmed},
  primaryclass  = {astro-ph.IM},
}

@Misc{2013Maas-Rectifiernonlinearitiesimprove,
  author   = {Maas, Andrew L. and Hannun, Awni Y. and Ng, Andrew Y.},
  title    = {Rectifier nonlinearities improve neural network acoustic models},
  year     = {2013},
  abstract = {Deep neural network acoustic models pro-duce substantial gains in large vocabu-lary continuous speech recognition systems. Emerging work with rectified linear (ReL) hidden units demonstrates additional gains in final system performance relative to more commonly used sigmoidal nonlinearities. In this work, we explore the use of deep rectifier networks as acoustic models for the 300 hour Switchboard conversational speech recogni-tion task. Using simple training procedures without pretraining, networks with rectifier nonlinearities produce 2 % absolute reduc-tions in word error rates over their sigmoidal counterparts. We analyze hidden layer repre-sentations to quantify differences in how ReL units encode inputs as compared to sigmoidal units. Finally, we evaluate a variant of the ReL unit with a gradient more amenable to optimization in an attempt to further im-prove deep rectifier networks. 1.},
  file     = {\:2013Maas-Rectifiernonlinearitiesimprove.pdf\:PDF:\:2013Maas-Rectifiernonlinearitiesimprove.pdf\:PDF:PDF},
}

@Article{2014Simonyan-VeryDeepConvolutional,
  author        = {Simonyan, Karen and Zisserman, Andrew},
  title         = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  year          = {2014},
  month         = sep,
  abstract      = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
  archiveprefix = {arXiv},
  eprint        = {http://arxiv.org/abs/1409.1556v6},
  file          = {1409.1556v6\:PDF:\:http/\:/arxiv.org/pdf/1409.1556v6\:PDF:PDF},
  keywords      = {cs.CV},
  primaryclass  = {cs.CV},
}

@Article{2016Wattenberg-HowUset,
  author         = {Wattenberg, Martin and Viégas, Fernanda and Johnson, Ian},
  title          = {How to Use t-SNE Effectively},
  journal        = {Distill},
  year           = {2016},
  doi            = {10.23915/distill.00002},
  keywords       = {relevant, skimmed, qualityAssured},
  url            = {http://distill.pub/2016/misread-tsne},
}

@Article{2008Maaten-Visualizingdatausing,
  author     = {Maaten, Laurens van der and Hinton, Geoffrey},
  title      = {Visualizing data using t-SNE},
  journal    = {Journal of Machine Learning Research},
  year       = {2008},
  volume     = {9},
  number     = {Nov},
  pages      = {2579--2605},
  file       = {\:2008Maaten-Visualizingdatausing.pdf\:PDF:\:2008Maaten-Visualizingdatausing.pdf\:PDF:PDF},
  keywords   = {skimmed, relevant},
}

@Article{2017Indik-Reducingnumbertemplates,
  author        = {Indik, Nathaniel and Fehrmann, Henning and Harke, Franz and Krishnan, Badri and Nielsen, Alex B.},
  journal       = {Phys. Rev. D 97, 124008 (2018)},
  title         = {Reducing the number of templates for aligned-spin compact binary coalescence gravitational wave searches using metric-agnostic template nudging},
  year          = {2017},
  month         = dec,
  abstract      = {Efficient multi-dimensional template placement is crucial in computationally intensive matched-filtering searches for Gravitational Waves (GWs). Here, we implement the Neighboring Cell Algorithm (NCA) to improve the detection volume of an existing Compact Binary Coalescence (CBC) template bank. This algorithm has already been successfully applied for a binary millisecond pulsar search in data from the Fermi satellite. It repositions templates from over-dense regions to under-dense regions and reduces the number of templates that would have been required by a stochastic method to achieve the same detection volume. Our method is readily generalizable to other CBC parameter spaces. Here we apply this method to the aligned–single-spin neutron-star–black-hole binary coalescence inspiral-merger-ringdown gravitational wave parameter space. We show that the template nudging algorithm can attain the equivalent effectualness of the stochastic method with 12% fewer templates.},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.97.124008},
  eprint        = {http://arxiv.org/abs/1712.07869v2},
  file          = {1712.07869v2\:PDF:\:2017Indik-Reducingnumbertemplates.pdf\:PDF\;\:http/\:/arxiv.org/pdf/1712.07869v2\:PDF:PDF},
  keywords      = {gr-qc, skimmed},
  primaryclass  = {gr-qc},
  readstatus    = {skimmed},
}

@Article{2011Graff-BAMBIblindaccelerated,
  author        = {Graff, Philip and Feroz, Farhan and Hobson, Michael P. and Lasenby, Anthony},
  title         = {BAMBI: blind accelerated multimodal Bayesian inference},
  journal       = {MNRAS, Vol. 421, Issue 1, pg. 169-180 (2012)},
  year          = {2011},
  month         = oct,
  abstract      = {In this paper we present an algorithm for rapid Bayesian analysis that combines the benefits of nested sampling and artificial neural networks. The blind accelerated multimodal Bayesian inference (BAMBI) algorithm implements the MultiNest package for nested sampling as well as the training of an artificial neural network (NN) to learn the likelihood function. In the case of computationally expensive likelihoods, this allows the substitution of a much more rapid approximation in order to increase significantly the speed of the analysis. We begin by demonstrating, with a few toy examples, the ability of a NN to learn complicated likelihood surfaces. BAMBI's ability to decrease running time for Bayesian inference is then demonstrated in the context of estimating cosmological parameters from Wilkinson Microwave Anisotropy Probe and other observations. We show that valuable speed increases are achieved in addition to obtaining NNs trained on the likelihood functions for the different model and data combinations. These NNs can then be used for an even faster follow-up analysis using the same likelihood and different priors. This is a fully general algorithm that can be applied, without any pre-processing, to other problems with computationally expensive likelihood functions.},
  archiveprefix = {arXiv},
  doi           = {10.1111/j.1365-2966.2011.20288.x},
  eprint        = {1110.2997v2},
  file          = {1110.2997v2\:PDF:\:2011Graff-BAMBIblindaccelerated.pdf\:PDF\;online\:http/\:/arxiv.org/pdf/1110.2997v2\:PDF:PDF},
  keywords      = {astro-ph.IM, astro-ph.CO, physics.data-an, stat.ML, skimmed},
  primaryclass  = {astro-ph.IM},
}

@Article{2016Mukund-TransientClassificationLIGO,
  author        = {Mukund, Nikhil and Abraham, Sheelu and Kandhasamy, Shivaraj and Mitra, Sanjit and Philip, Ninan Sajeeth},
  journal       = {Phys. Rev. D 95, 104059 (2017)},
  title         = {Transient Classification in LIGO data using Difference Boosting Neural Network},
  year          = {2016},
  month         = sep,
  abstract      = {Detection and classification of transients in data from gravitational wave detectors are crucial for efficient searches for true astrophysical events and identification of noise sources. We present a hybrid method for classification of short duration transients seen in gravitational wave data using both supervised and unsupervised machine learning techniques. To train the classifiers we use the relative wavelet energy and the corresponding entropy obtained by applying one-dimensional wavelet decomposition on the data. The prediction accuracy of the trained classifier on 9 simulated classes of gravitational wave transients and also LIGO's sixth science run hardware injections are reported. Targeted searches for a couple of known classes of non-astrophysical signals in the first observational run of Advanced LIGO data are also presented. The ability to accurately identify transient classes using minimal training samples makes the proposed method a useful tool for LIGO detector characterization as well as searches for short duration gravitational wave signals.},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.95.104059},
  eprint        = {1609.07259v3},
  file          = {1609.07259v3\:PDF:\:2016Mukund-TransientClassificationLIGO.pdf\:PDF\;\:http/\:/arxiv.org/pdf/1609.07259v3\:PDF:PDF},
  keywords      = {astro-ph.IM, gr-qc, skimmed},
  primaryclass  = {astro-ph.IM},
}

@Article{2017Powell-Classificationmethodsnoise,
  author        = {Powell, Jade and Torres-Forn{\'{e}}, Alejandro and Lynch, Ryan and Trifir{\`{o}}, Daniele and Cuoco, Elena and Cavagli{\`{a}}, Marco and Heng, Ik Siong and Font, Jos{\'{e}} A.},
  journal       = {Class. Quant. Grav.},
  title         = {Classification methods for noise transients in advanced gravitational-wave detectors II: performance tests on Advanced LIGO data},
  year          = {2017},
  month         = sep,
  number        = {3},
  pages         = {034002},
  volume        = {34},
  abstract      = {The data taken by the advanced LIGO and Virgo gravitational-wave detectors contains short duration noise transients that limit the significance of astrophysical detections and reduce the duty cycle of the instruments. As the advanced detectors are reaching sensitivity levels that allow for multiple detections of astrophysical gravitational-wave sources it is crucial to achieve a fast and accurate characterization of non-astrophysical transient noise shortly after it occurs in the detectors. Previously we presented three methods for the classification of transient noise sources. They are Principal Component Analysis for Transients (PCAT), Principal Component LALInference Burst (PC-LIB) and Wavelet Detection Filter with Machine Learning (WDF-ML). In this study we carry out the first performance tests of these algorithms on gravitational-wave data from the Advanced LIGO detectors. We use the data taken between the 3ʳᵈ of June 2015 and the 14ᵗʰ of June 2015 during the 7ᵗʰ engineering run (ER7), and outline the improvements made to increase the performance and lower the latency of the algorithms on real data. This work provides an important test for understanding the performance of these methods on real, non stationary data in preparation for the second advanced gravitational-wave detector observation run, planned for later this year. We show that all methods can classify transients in non stationary data with a high level of accuracy and show the benefits of using multiple classifiers.},
  archiveprefix = {arXiv},
  doi           = {10.1088/1361-6382/34/3/034002},
  eprint        = {1609.06262v2},
  eprintclass   = {astro-ph.IM},
  eprinttype    = {arXiv},
  file          = {\\\:PDF\\\:PDF\:PDF:/\:PDF/\:PDF/\:PDF\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:/\:PDF/\:PDF/\:PDF/\:1609.06262v2/\:PDF/\:PDF/\:1609.06262v2/\:PDF/\:/\:2016Powell-Classificationmethodsfor.pdf/\:PDF/\;online/\:http/\:/arxiv.org/pdf/1609.06262v2/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF/\:PDF\:PDF:PDF},
  keywords      = {astro-ph.IM, skimmed},
  primaryclass  = {astro-ph.IM},
  readstatus    = {skimmed},
}

@Article{2019Pan-Accuracysourcelocalization,
  author        = {Pan, Hsing-Po and Lin, Chun-Yu and Cao, Zhoujian and Yo, Hwei-Jang},
  title         = {Accuracy of source localization for eccentric inspiraling binary mergers using a ground-based detector network},
  journal       = {Phys. Rev.},
  year          = {2019},
  volume        = {D100},
  number        = {12},
  pages         = {124003},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.100.124003},
  eprint        = {1912.04455},
  primaryclass  = {gr-qc},
}

@Article{1999Owen-Matchedfilteringgravitational,
  author        = {Owen, Benjamin J. and Sathyaprakash, B. S.},
  title         = {Matched filtering of gravitational waves from inspiraling compact binaries: Computational cost and template placement},
  journal       = {Phys. Rev.},
  year          = {1999},
  volume        = {D60},
  pages         = {022002},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.60.022002},
  eprint        = {gr-qc/9808076},
  file          = {\:1999Owen-Matchedfilteringgravitational.pdf\:PDF:\:1999Owen-Matchedfilteringgravitational.pdf\:PDF:PDF},
  primaryclass  = {gr-qc},
  reportnumber  = {GRP-505},
}

@Article{2019Huerta-Enablingrealtime,
  author        = {Huerta, E. A. and Allen, Gabrielle and Andreoni, Igor and Antelis, Javier M. and Bachelet, Etienne and Berriman, G. Bruce and Bianco, Federica B. and Biswas, Rahul and Carrasco Kind, Matias and Chard, Kyle and Cho, Minsik and Cowperthwaite, Philip S. and Etienne, Zachariah B. and Fishbach, Maya and Forster, Francisco and George, Daniel and Gibbs, Tom and Graham, Matthew and Gropp, William and Gruendl, Robert and Gupta, Anushri and Haas, Roland and Habib, Sarah and Jennings, Elise and Johnson, Margaret W. G. and Katsavounidis, Erik and Katz, Daniel S. and Khan, Asad and Kindratenko, Volodymyr and Kramer, William T. C. and Liu, Xin and Mahabal, Ashish and Marka, Zsuzsa and McHenry, Kenton and Miller, J. M. and Moreno, Claudia and Neubauer, M. S. and Oberlin, Steve and Olivas, Alexander R. and Petravick, Donald and Rebei, Adam and Rosofsky, Shawn and Ruiz, Milton and Saxton, Aaron and Schutz, Bernard F. and Schwing, Alex and Seidel, Ed and Shapiro, Stuart L. and Shen, Hongyu and Shen, Yue and Singer, Leo P. and Sipocz, Brigitta M. and Sun, Lunan and Towns, John and Tsokaros, Antonios and Wei, Wei and Wells, Jack and Williams, Timothy J. and Xiong, Jinjun and Zhao, Zhizhen},
  title         = {Enabling real-time multi-messenger astrophysics discoveries with deep learning},
  journal       = {Nature Rev. Phys.},
  year          = {2019},
  volume        = {1},
  number        = {10},
  pages         = {600--608},
  month         = oct,
  issn          = {2522-5820},
  abstract      = {Multi-messenger astrophysics is a fast-growing, interdisciplinary field that combines data, which vary in volume and speed of data processing, from many different instruments that probe the Universe using different cosmic messengers: electromagnetic waves, cosmic rays, gravitational waves and neutrinos. In this Expert Recommendation, we review the key challenges of real-time observations of gravitational wave sources and their electromagnetic and astroparticle counterparts, and make a number of recommendations to maximize their potential for scientific discovery. These recommendations refer to the design of scalable and computationally efficient machine learning algorithms; the cyber-infrastructure to numerically simulate astrophysical sources, and to process and interpret multi-messenger astrophysics data; the management of gravitational wave detections to trigger real-time alerts for electromagnetic and astroparticle follow-ups; a vision to harness future developments of machine learning and cyber-infrastructure resources to cope with the big-data requirements; and the need to build a community of experts to realize the goals of multi-messenger astrophysics.},
  archiveprefix = {arXiv},
  date          = {2019-02-01},
  doi           = {10.1038/s42254-019-0097-4},
  eprint        = {1911.11779},
  file          = {\:2019Huerta-Enablingrealtime.pdf\:PDF:\:2019Huerta-Enablingrealtime.pdf\:PDF:PDF},
  journaltitle  = {Nature Reviews Physics},
  keywords      = {astro-ph.IM, astro-ph.HE, cs.LG, gr-qc, skimmed},
  primaryclass  = {gr-qc},
}

@Book{2013Wasserman-Allstatisticsconcise,
  title     = {All of statistics: a concise course in statistical inference},
  publisher = {Springer Science \& Business Media},
  year      = {2013},
  author    = {Wasserman, Larry},
}

@Software{2020Macleod-gwpy/gwpy1.0.1,
  author    = {Macleod, Duncan and Urban, Alex L. and Coughlin, Scott and Massinger, Thomas and Pitkin, Matt and paulaltin and Areeda, Joseph and Quintero, Eric and Badger, The Gitter and Singer, Leo and Leinweber, Katrin},
  doi       = {10.5281/zenodo.3598469},
  month     = jan,
  publisher = {Zenodo},
  title     = {gwpy/gwpy: 1.0.1},
  version   = {v1.0.1},
  year      = {2020},
}

@InProceedings{2010McKinney-DataStructuresStatistical,
  author    = {McKinney, Wes},
  title     = {Data Structures for Statistical Computing in Python},
  booktitle = {Proceedings of the 9th Python in Science Conference},
  year      = {2010},
  editor    = {St\'efan van der Walt and Jarrod Millman},
  pages     = {51--56},
}

@Article{2011Pedregosa-ScikitlearnMachine,
  author  = {Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and others},
  title   = {Scikit-learn: Machine learning in Python},
  journal = {Journal of machine learning research},
  year    = {2011},
  volume  = {12},
  number  = {Oct},
  pages   = {2825--2830},
}

@Article{2020Virtanen-SciPy1.0Fundamental,
  author  = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and van der Walt, St{\'e}fan J. and Brett, Matthew and Wilson, Joshua and Jarrod Millman, K. and Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and Kern, Robert and Larson, Eric and Carey, C. J. and Polat, {\. I}lhan and Feng, Yu and Moore, Eric W. and Vand erPlas, Jake and Laxalde, Denis and Perktold, Josef and Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and Harris, Charles R. and Archibald, Anne M. and Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and van Mulbregt, Paul and Contributors, SciPy 1. 0},
  journal = {Nature Methods},
  title   = {SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python},
  year    = {2020},
  pages   = {261--272},
  volume  = {17},
  adsurl  = {https://rdcu.be/b08Wh},
  doi     = {10.1038/s41592-019-0686-2},
}

@Article{2007Hunter-Matplotlib2DGraphics,
  author    = {Hunter, John D.},
  title     = {Matplotlib: A 2D Graphics Environment},
  journal   = {Computing in Science {\&} Engineering},
  year      = {2007},
  volume    = {9},
  number    = {3},
  pages     = {90--95},
  doi       = {10.1109/mcse.2007.55},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Article{2011Walt-NumPyArrayStructure,
  author    = {van der Walt, St{\'{e}}fan and Colbert, S. Chris and Varoquaux, Gaël},
  title     = {The {NumPy} Array: A Structure for Efficient Numerical Computation},
  journal   = {Computing in Science {\&} Engineering},
  year      = {2011},
  volume    = {13},
  number    = {2},
  pages     = {22--30},
  month     = mar,
  doi       = {10.1109/mcse.2011.37},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Software{2020Waskom-mwaskom/seabornv0.10.0January,
  author    = {Waskom, Michael and Botvinnik, Olga and Ostblom, Joel and Lukauskas, Saulius and Hobson, Paul and MaozGelbart and Gemperline, David C. and Augspurger, Tom and Halchenko, Yaroslav and Cole, John B. and Warmenhoven, Jordi and de Ruiter, Julian and Pye, Cameron and Hoyer, Stephan and Vanderplas, Jake and Villalba, Santi and Kunter, Gero and Quintero, Eric and Bachant, Pete and Martin, Marcel and Meyer, Kyle and Swain, Corban and Miles, Alistair and Brunner, Thomas and O'Kane, Drew and Yarkoni, Tal and Williams, Mike Lee and Evans, Constantine},
  doi       = {10.5281/zenodo.3629446},
  month     = jan,
  publisher = {Zenodo},
  title     = {mwaskom/seaborn: v0.10.0 (January 2020)},
  version   = {v0.10.0},
  year      = {2020},
}

@Article{2014Merkel-Dockerlightweightlinux,
  author  = {Merkel, Dirk},
  title   = {Docker: lightweight linux containers for consistent development and deployment},
  journal = {Linux journal},
  year    = {2014},
  volume  = {2014},
  number  = {239},
  pages   = {2},
}

@Article{2017Moritz-RayDistributedFramework,
  author        = {Moritz, Philipp and Nishihara, Robert and Wang, Stephanie and Tumanov, Alexey and Liaw, Richard and Liang, Eric and Elibol, Melih and Yang, Zongheng and Paul, William and Jordan, Michael I. and Stoica, Ion},
  title         = {Ray: A Distributed Framework for Emerging AI Applications},
  year          = {2017},
  month         = dec,
  abstract      = {The next generation of AI applications will continuously interact with the environment and learn from these interactions. These applications impose new and demanding systems requirements, both in terms of performance and flexibility. In this paper, we consider these requirements and present Ray—a distributed system to address them. Ray implements a unified interface that can express both task-parallel and actor-based computations, supported by a single dynamic execution engine. To meet the performance requirements, Ray employs a distributed scheduler and a distributed and fault-tolerant store to manage the system's control state. In our experiments, we demonstrate scaling beyond 1.8 million tasks per second and better performance than existing specialized systems for several challenging reinforcement learning applications.},
  archiveprefix = {arXiv},
  eprint        = {http://arxiv.org/abs/1712.05889v2},
  file          = {1712.05889v2\:PDF:\:http/\:/arxiv.org/pdf/1712.05889v2\:PDF:PDF},
  groups        = {Herb:6},
  keywords      = {cs.DC, cs.AI, cs.LG, stat.ML},
  primaryclass  = {cs.DC},
}

@Conference{2016Kluyver-JupyterNotebookspublishing,
  author       = {Kluyver, Thomas and Ragan-Kelley, Benjamin and P{\'e}rez, Fernando and Granger, Brian and Bussonnier, Matthias and Frederic, Jonathan and Kelley, Kyle and Hamrick, Jessica and Grout, Jason and Corlay, Sylvain and Ivanov, Paul and Avila, Dami{\'a}n and Abdalla, Safia and Willing, Carol},
  title        = {Jupyter Notebooks -- a publishing format for reproducible computational workflows},
  booktitle    = {Positioning and Power in Academic Publishing: Players, Agents and Agendas},
  year         = {2016},
  editor       = {F. Loizides and B. Schmidt},
  pages        = {87--90},
  organization = {IOS Press},
}

@Article{2006Lightman-Prospectsgravitationalwave,
  author    = {Lightman, M. and Thurakal, J. and Dwyer, J. and Grossman, R. and Kalmus, P. and Matone, L. and Rollins, J. and Zairis, S. and Marka, S.},
  journal   = {J. Phys. Conf. Ser.},
  title     = {Prospects of gravitational wave data mining and exploration via evolutionary computing},
  year      = {2006},
  pages     = {58--65},
  volume    = {32},
  booktitle = {Gravitational waves. Proceedings, 6th Edoardo Amaldi Conference, Amaldi6, Bankoku Shinryoukan, June 20-24, 2005},
  doi       = {10.1088/1742-6596/32/1/010},
  file      = {:2006Lightman-Prospectsgravitationalwave.pdf:PDF},
}

@Article{2013Essick-OptimizingVetoesGravitational,
  author        = {Essick, R. and Blackburn, L. and Katsavounidis, E.},
  journal       = {Class. Quant. Grav.},
  title         = {Optimizing Vetoes for Gravitational-Wave Transient Searches},
  year          = {2013},
  pages         = {155010},
  volume        = {30},
  archiveprefix = {arXiv},
  doi           = {10.1088/0264-9381/30/15/155010},
  eprint        = {1303.7159},
  file          = {:2013Essick-OptimizingVetoesGravitational.pdf:PDF},
  primaryclass  = {astro-ph.IM},
}

@Article{2013Biswas-Applicationmachinelearning,
  author        = {Biswas, Rahul and others},
  journal       = {Phys. Rev.},
  title         = {Application of machine learning algorithms to the study of noise artifacts in gravitational-wave data},
  year          = {2013},
  number        = {6},
  pages         = {062003},
  volume        = {D88},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.88.062003},
  eprint        = {1303.6984},
  file          = {:2013Biswas-Applicationmachinelearning.pdf:PDF},
  primaryclass  = {astro-ph.IM},
}

@Article{2015Baker-MultivariateClassificationRandom,
  author        = {Baker, Paul T. and Caudill, Sarah and Hodge, Kari A. and Talukder, Dipongkar and Capano, Collin and Cornish, Neil J.},
  journal       = {Phys. Rev.},
  title         = {Multivariate Classification with Random Forests for Gravitational Wave Searches of Black Hole Binary Coalescence},
  year          = {2015},
  number        = {6},
  pages         = {062004},
  volume        = {D91},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.91.062004},
  eprint        = {1412.6479},
  file          = {:2015Baker-MultivariateClassificationRandom.pdf:PDF},
  primaryclass  = {gr-qc},
  reportnumber  = {LIGO-DOCUMENT-P1400231},
}

@Report{2013RuslanVaulin-iDQRealTime,
  author = {Ruslan Vaulin, Lindy Blackburn, Reed Essick and Katsavounidis, Erik},
  file   = {:2013RuslanVaulin-iDQRealTime.pdf:PDF},
  title  = {iDQ: The Real-Time Pipeline for Glitch Identification},
  year   = {2013},
}

@Article{2020Davis-UtilizingaLIGOGlitch,
  author        = {Davis, Derek and White, Laurel V. and Saulson, Peter R.},
  title         = {Utilizing aLIGO Glitch Classifications to Validate Gravitational-Wave Candidates},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2002.09429},
  file          = {:2020Davis-UtilizingaLIGOGlitch.pdf:PDF},
  primaryclass  = {gr-qc},
}

%%% contains utf-8, see: https://inspirehep.net/info/faq/general#utf8
%%% add \usepackage[utf8]{inputenc} to your latex preamble

@Article{2017Cuoco-Strategysignalclassification,
  author    = {Cuoco, Elena and Powell, Jade and Torres-Forné, Alejandro and Lynch, Ryan and Trifirò, Daniele and Cavaglià, Marco and Siong Heng, Ik and A. Font, José},
  journal   = {Nuovo Cim.},
  title     = {Strategy for signal classification to improve data quality for Advanced Detectors gravitational-wave searches},
  year      = {2017},
  number    = {3},
  pages     = {124},
  volume    = {C40},
  booktitle = {Proceedings, 11th Workshop on Science with the New generation of High Energy Gamma-ray Experiments (SciNeGHE 2016): Pisa, Italy, October 18-21, 2016},
  doi       = {10.1393/ncc/i2017-17124-4},
  file      = {:2017Cuoco-Strategysignalclassification.pdf:PDF},
}

@PhdThesis{2017Powell-ModelSelectionGravitational,
  author       = {Powell, Jade},
  school       = {Glasgow U.},
  title        = {Model Selection for Gravitational-Wave Transient Sources},
  year         = {2017},
  reportnumber = {GLATHESIS-2017-8259},
  url          = {http://theses.gla.ac.uk/8259/},
}

@InProceedings{2018Cuoco-WaveletBasedClassification,
  author          = {Cuoco, Elena and Razzano, Massimiliano and Utina, Andrei},
  title           = {Wavelet-Based Classification of Transient Signals for Gravitational Wave Detectors},
  year            = {2018},
  address         = {Rome},
  pages           = {2648--2652},
  publisher       = {IEEE},
  abstract        = {The detection of gravitational waves opened a new window on the cosmos. The Advanced LIGO and Advanced Virgo interferometers will probe a larger volume of Universe and discover new gravitational wave emitters. Characterizing these detectors is of primary importance in order to recognize the main sources of noise and optimize the sensitivity of the searches. Glitches are transient noise events that can impact the data quality of the interferometers and their classification is an important task for detector characterization. In this paper we present a classification method for short transient signals based on a Wavelet decomposition and de-noising and a classification of the extracted features based on XGBoost algorithm. Although the results show the accuracy is lower than that obtained with the use of deep learning, this method which extracts features while detecting signals in real time, can be configured as a fast classification system.},
  date            = {3-7 Sept. 2018},
  doi             = {10.23919/EUSIPCO.2018.8553393},
  eventdate       = {3-7 Sept. 2018},
  eventtitleaddon = {Rome},
  file            = {:https\://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8553393:PDF;:2018Cuoco-WaveletBasedClassification.pdf:PDF},
  isbn            = {978-1-5386-3736-4},
  issn            = {2219-5491},
  journal         = {2018 26th European Signal Processing Conference (EUSIPCO)},
  keywords        = {Wavelet transforms, Transient analysis, Detectors, Interferometers, Pipelines, Sensitivity, Feature extraction, signal processing, wavelet decomposition, machine learning classification},
}

@Article{2016Chen-XGBoostScalableTree,
  author        = {Chen, Tianqi and Guestrin, Carlos},
  title         = {XGBoost: A Scalable Tree Boosting System},
  year          = {2016},
  month         = mar,
  abstract      = {Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.},
  archiveprefix = {arXiv},
  doi           = {10.1145/2939672.2939785},
  eprint        = {1603.02754v3},
  file          = {:http\://arxiv.org/pdf/1603.02754v3:PDF},
  keywords      = {cs.LG},
  primaryclass  = {cs.LG},
}
%%% contains utf-8, see: https://inspirehep.net/info/faq/general#utf8
%%% add \usepackage[utf8]{inputenc} to your latex preamble

@Article{2019LlorensMonteagudo-Classificationgravitationalwave,
  author        = {Llorens-Monteagudo, Miquel and Torres-Forné, Alejandro and Font, José A. and Marquina, Antonio},
  journal       = {Class. Quant. Grav.},
  title         = {Classification of gravitational-wave glitches via dictionary learning},
  year          = {2019},
  number        = {7},
  pages         = {075005},
  volume        = {36},
  archiveprefix = {arXiv},
  doi           = {10.1088/1361-6382/ab0657},
  eprint        = {1811.03867},
  file          = {:2019LlorensMonteagudo-Classificationgravitationalwave.pdf:PDF},
  primaryclass  = {astro-ph.IM},
}

@Article{2019Cavaglia-Findingoriginnoise,
  author        = {Cavaglia, Marco and Staats, Kai and Gill, Teerth},
  journal       = {Commun. Comput. Phys.},
  title         = {Finding the origin of noise transients in LIGO data with machine learning},
  year          = {2019},
  number        = {4},
  pages         = {963--987},
  volume        = {25},
  archiveprefix = {arXiv},
  doi           = {10.4208/cicp.OA-2018-0092},
  eprint        = {1812.05225},
  file          = {:2019Cavaglia-Findingoriginnoise.pdf:PDF},
  primaryclass  = {physics.data-an},
  reportnumber  = {LIGO-P1800043},
}

@Article{2017George-DeepTransferLearning,
  author      = {George, Daniel and Shen, Hongyu and Huerta, E. A.},
  title       = {Deep Transfer Learning: A new deep learning glitch classification method for advanced LIGO},
  abstract    = {The exquisite sensitivity of the advanced LIGO detectors has enabled the detection of multiple gravitational wave signals. The sophisticated design of these detectors mitigates the effect of most types of noise. However, advanced LIGO data streams are contaminated by numerous artifacts known as glitches: non-Gaussian noise transients with complex morphologies. Given their high rate of occurrence, glitches can lead to false coincident detections, obscure and even mimic gravitational wave signals. Therefore, successfully characterizing and removing glitches from advanced LIGO data is of utmost importance. Here, we present the first application of Deep Transfer Learning for glitch classification, showing that knowledge from deep learning algorithms trained for real-world object recognition can be transferred for classifying glitches in time-series based on their spectrogram images. Using the Gravity Spy dataset, containing hand-labeled, multi-duration spectrograms obtained from real LIGO data, we demonstrate that this method enables optimal use of very deep convolutional neural networks for classification given small training datasets, significantly reduces the time for training the networks, and achieves state-of-the-art accuracy above 98.8%, with perfect precision-recall on 8 out of 22 classes. Furthermore, new types of glitches can be classified accurately given few labeled examples with this technique. Once trained via transfer learning, we show that the convolutional neural networks can be truncated and used as excellent feature extractors for unsupervised clustering methods to identify new classes based on their morphology, without any labeled examples. Therefore, this provides a new framework for dynamic glitch classification for gravitational wave detectors, which are expected to encounter new types of noise as they undergo gradual improvements to attain design sensitivity.},
  date        = {2017},
  doi         = {10.1103/PhysRevD.97.101501},
  eprint      = {1706.07446},
  eprintclass = {gr-qc},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1706.07446v1:PDF},
  keywords    = {gr-qc, astro-ph.IM, cs.CV, cs.LG, cs.NE},
}

@InProceedings{2017George-GlitchClassificationClustering,
  author        = {George, Daniel and Shen, Hongyu and Huerta, E. A.},
  booktitle     = {NiPS Summer School 2017 Gubbio, Perugia, Italy, June 30-July 3, 2017},
  title         = {Glitch Classification and Clustering for LIGO with Deep Transfer Learning},
  year          = {2017},
  abstract      = {The detection of gravitational waves with LIGO and Virgo requires a detailed understanding of the response of these instruments in the presence of environmental and instrumental noise. Of particular interest is the study of anomalous non-Gaussian noise transients known as glitches, since their high occurrence rate in LIGO/Virgo data can obscure or even mimic true gravitational wave signals. Therefore, successfully identifying and excising glitches is of utmost importance to detect and characterize gravitational waves. In this article, we present the first application of Deep Learning combined with Transfer Learning for glitch classification, using real data from LIGO's first discovery campaign labeled by Gravity Spy, showing that knowledge from pre-trained models for real-world object recognition can be transferred for classifying spectrograms of glitches. We demonstrate that this method enables the optimal use of very deep convolutional neural networks for glitch classification given small unbalanced training datasets, significantly reduces the training time, and achieves state-of-the-art accuracy above 98.8%. Once trained via transfer learning, we show that the networks can be truncated and used as feature extractors for unsupervised clustering to automatically group together new classes of glitches and anomalies. This novel capability is of critical importance to identify and remove new types of glitches which will occur as the LIGO/Virgo detectors gradually attain design sensitivity.},
  archiveprefix = {arXiv},
  doi           = {10.1103/PhysRevD.97.101501},
  eprint        = {1711.07468},
  file          = {:http\://arxiv.org/pdf/1711.07468v2:PDF},
  journal       = {Phys. Rev. D 97, 101501 (2018)},
  keywords      = {astro-ph.IM, cs.LG, gr-qc, stat.ML},
  primaryclass  = {astro-ph.IM},
}

@Article{2019Zhan-ZaigaZhaoshanLong,
  author        = {Zhan, Ming-Sheng and Wang, Jin and Ni, Wei-Tou and Gao, Dong-Feng and Wang, Gang and He, Ling-Xiang and Li, Run-Bing and Zhou, Lin and Chen, Xi and Zhong, Jia-Qi and Tang, Biao and Yao, Zhan-Wei and Zhu, Lei and Xiong, Zong-Yuan and Lu, Si-Bin and Yu, Geng-Hua and Cheng, Qun-Feng and Liu, Min and Liang, Yu-Rong and Xu, Peng and He, Xiao-Dong and Ke, Min and Tan, Zheng and Luo, Jun},
  journal       = {Int. J. Mod. Phys. D},
  title         = {Zaiga: Zhaoshan Long-baseline Atom Interferometer Gravitation Antenna},
  year          = {2019},
  issn          = {0218-2718},
  month         = may,
  number        = {04},
  pages         = {1940005},
  volume        = {29},
  abstract      = {The Zhaoshan long-baseline Atom Interferometer Gravitation Antenna (ZAIGA) is a new type of underground laser-linked interferometer facility, and is currently under construction. It is in the 200-m-on-average underground of a mountain named Zhaoshan which is about 80km southeast to Wuhan. ZAIGA will be equipped with long-baseline atom interferometers, high-precision atom clocks, and large-scale gyros. ZAIGA facility will take an equilateral triangle configuration with two 1-km-apart atom interferometers in each arm, a 300-m vertical tunnel with atom fountain and atom clocks mounted, and a tracking-and-ranging 1-km-arm-length prototype with lattice optical clocks linked by locked lasers. The ZAIGA facility will be used for experimental research on gravitation and related problems including gravitational wave detection, high-precision test of the equivalence principle of micro-particles, clock-based gravitational red-shift measurement, rotation measurement and gravitomagnetic effect. The Zhaoshan long-baseline Atom Interferometer Gravitation Antenna (ZAIGA) is a new type of underground laser-linked interferometer facility, and is currently under construction. It is in the 200-m-on-average underground of a mountain named Zhaoshan which is about 80km southeast to Wuhan. ZAIGA will be equipped with long-baseline atom interferometers, high-precision atom clocks, and large-scale gyros. ZAIGA facility will take an equilateral triangle configuration with two 1-km-apart atom interferometers in each arm, a 300-m vertical tunnel with atom fountain and atom clocks mounted, and a tracking-and-ranging 1-km-arm-length prototype with lattice optical clocks linked by locked lasers. The ZAIGA facility will be used for experimental research on gravitation and related problems including gravitational wave detection, high-precision test of the equivalence principle of micro-particles, clock-based gravitational red-shift measurement, rotation measurement and gravitomagnetic effect.},
  archiveprefix = {arXiv},
  comment       = {doi: 10.1142/S0218271819400054},
  date          = {2019-03-22},
  doi           = {10.1142/s0218271819400054},
  eprint        = {1903.09288v4},
  file          = {:http\://arxiv.org/pdf/1903.09288v4:PDF},
  journaltitle  = {International Journal of Modern Physics D (2019) 1940005},
  keywords      = {physics.atom-ph},
  primaryclass  = {physics.atom-ph},
  publisher     = {World Scientific Publishing Co.},
}

@Article{2017Li-TibetsAliNew,
  author        = {Li, Yong-Ping and Liu, Yang and Li, Si-Yu and Li, Hong and Zhang, Xinmin},
  title         = {Tibet's Ali: A New Window to Detect the Cmb Polarization},
  year          = {2017},
  month         = sep,
  abstract      = {The Cosmic Microwave Background (CMB) Polarization plays an important role in current cosmological studies. CMB B-mode polarization is the most effective probe to primordial gravitational waves (PGWs) and a test of the inflation as well as other theories of the early universe such as bouncing and cyclic universe. So far, major ground-based CMB polarization experiments are located in the southern hemisphere.Recently, China has launched the Ali CMB Polarization Telescope (AliCPT) in Tibetan Plateau to measure CMB B mode polarization and detect the PGWs in northern hemisphere. AliCPT include two stages, the first one is to build a telescope at the 5250m site (AliCPT-1) and the second one is to have a more sensitive telescope at a higher altitude of about 6000m (AliCPT-2). In this paper, we report the atmospherical conditions, sky coverage and the current infrastructure associated with AliCPT. We analyzed the reanalysis data from MERRA-2 together with radiosonde data from the Ali Meteorological Service and found that the amount of water vapor has a heavy seasonal variation and October to March is the suitable observation time. We also found 95/150 GHz to be feasible for AliCPT-1 and higher frequencies to be possible for AliCPT-2. Then we analyzed the observable sky and the target fields, and showed that Ali provides us a unique opportunity to observe CMB with less foreground contamination in the northern hemisphere and is complementary to the existed southern CMB experiments. Together with the developed infrastructure, we point out that Ali opens a new window for CMB observation and will be one of the major sites in the world along with Antarctic and Atacama.},
  archiveprefix = {arXiv},
  eprint        = {1709.09053v2},
  file          = {:http\://arxiv.org/pdf/1709.09053v2:PDF},
  keywords      = {astro-ph.IM, astro-ph.CO, gr-qc, hep-ph, hep-th},
  primaryclass  = {astro-ph.IM},
}

@Article{2018Li-Tibet’sWindowPrimordial,
  author   = {Li, Hong and Li, Si-Yu and Liu, Yang and Li, Yong-Ping and Zhang, Xinmin},
  journal  = {Nature Astronomy},
  title    = {Tibet’s Window on Primordial Gravitational Waves},
  year     = {2018},
  issn     = {2397-3366},
  number   = {2},
  pages    = {104--106},
  volume   = {2},
  abstract = {The Ali Cosmic Microwave Background Polarization Telescope – currently under construction in the Ngari prefecture of Tibet – will search for primordial gravitational waves and probe the origin of the Universe.},
  doi      = {10.1038/s41550-017-0373-0},
  refid    = {Li2018},
}

@Article{2011RENDONG-Fivehundredmeter,
  author    = {RENDONG, N. A. N. and L. I., D. I. and CHENGJIN, J. I. N. and QIMING, W. A. N. G. and LICHUN, Z. H. U. and WENBAI, Z. H. U. and ZHANG, H. A. I. Y. A. N. and YOULING, Y. U. E. and Q. I. A. N., L. E. I.},
  journal   = {Int. J. Mod. Phys. D},
  title     = {The Five-hundred-meter Aperture Spherical Radio Telescope (fast) Project},
  year      = {2011},
  issn      = {0218-2718},
  month     = jun,
  number    = {06},
  pages     = {989--1024},
  volume    = {20},
  abstract  = {Five-hundred-meter Aperture Spherical radio Telescope (FAST) is a Chinese mega-science project to build the largest single dish radio telescope in the world. Its innovative engineering concept and design pave a new road to realize a huge single dish in the most effective way. FAST also represents Chinese contribution in the international efforts to build the square kilometer array (SKA). Being the most sensitive single dish radio telescope, FAST will enable astronomers to jump-start many science goals, such as surveying the neutral hydrogen in the Milky Way and other galaxies, detecting faint pulsars, looking for the first shining stars, hearing the possible signals from other civilizations, etc. The idea of sitting a large spherical dish in a karst depression is rooted in Arecibo telescope. FAST is an Arecibo-type antenna with three outstanding aspects: the karst depression used as the site, which is large to host the 500-meter telescope and deep to allow a zenith angle of 40 degrees; the active main reflector correcting for spherical aberration on the ground to achieve a full polarization and a wide band without involving complex feed systems; and the light-weight feed cabin driven by cables and servomechanism plus a parallel robot as a secondary adjustable system to move with high precision. The feasibility studies for FAST have been carried out for 14 years, supported by Chinese and world astronomical communities. Funding for FAST has been approved by the National Development and Reform Commission in July of 2007 with a capital budget   700 million RMB. The project time is 5.5 years from the commencement of work in March of 2011 and the first light is expected to be in 2016. This review intends to introduce the project of FAST with emphasis on the recent progress since 2006. In this paper, the subsystems of FAST are described in modest details followed by discussions of the fundamental science goals and examples of early science projects. Five-hundred-meter Aperture Spherical radio Telescope (FAST) is a Chinese mega-science project to build the largest single dish radio telescope in the world. Its innovative engineering concept and design pave a new road to realize a huge single dish in the most effective way. FAST also represents Chinese contribution in the international efforts to build the square kilometer array (SKA). Being the most sensitive single dish radio telescope, FAST will enable astronomers to jump-start many science goals, such as surveying the neutral hydrogen in the Milky Way and other galaxies, detecting faint pulsars, looking for the first shining stars, hearing the possible signals from other civilizations, etc. The idea of sitting a large spherical dish in a karst depression is rooted in Arecibo telescope. FAST is an Arecibo-type antenna with three outstanding aspects: the karst depression used as the site, which is large to host the 500-meter telescope and deep to allow a zenith angle of 40 degrees; the active main reflector correcting for spherical aberration on the ground to achieve a full polarization and a wide band without involving complex feed systems; and the light-weight feed cabin driven by cables and servomechanism plus a parallel robot as a secondary adjustable system to move with high precision. The feasibility studies for FAST have been carried out for 14 years, supported by Chinese and world astronomical communities. Funding for FAST has been approved by the National Development and Reform Commission in July of 2007 with a capital budget   700 million RMB. The project time is 5.5 years from the commencement of work in March of 2011 and the first light is expected to be in 2016. This review intends to introduce the project of FAST with emphasis on the recent progress since 2006. In this paper, the subsystems of FAST are described in modest details followed by discussions of the fundamental science goals and examples of early science projects.},
  comment   = {doi: 10.1142/S0218271811019335},
  doi       = {10.1142/s0218271811019335},
  publisher = {World Scientific Publishing Co.},
}

@Article{2020Ruan-LisataijiNetwork,
  author  = {Ruan, Wen-Hong and Liu, Chang and Guo, Zong-Kuan and Wu, Yue-Liang and Cai, Rong-Gen},
  journal = {Nature Astronomy},
  title   = {The Lisa-taiji Network},
  year    = {2020},
  issn    = {2397-3366},
  number  = {2},
  pages   = {108--109},
  volume  = {4},
  doi     = {10.1038/s41550-019-1008-4},
  file    = {:2020Ruan-LisataijiNetwork.pdf:PDF},
  refid   = {Ruan2020},
}

@Article{2020Wang-Gravitationalwavesignal,
  author        = {Wang, He and Wu, Shichao and Cao, Zhoujian and Liu, Xiaolin and Zhu, Jian-Yang},
  journal       = {Physical Review D},
  title         = {Gravitational-wave Signal Recognition of {LIGO} Data by Deep Learning},
  year          = {2020},
  month         = may,
  number        = {10},
  volume        = {101},
  abstract      = {Deep learning method develops very fast as a tool for data analysis these years. Such a technique is quite promising to treat gravitational wave detection data. There are many works already in the literature which used deep learning technique to process simulated gravitational wave data. In this paper we apply deep learning to LIGO O1 data. In order to improve the weak signal recognition we adjust the convolutional neural network (CNN) a little bit. Our adjusted convolutional neural network admits comparable accuracy and efficiency of signal recognition as other deep learning works published in the literature. Based on our adjusted CNN, we can clearly recognize the eleven confirmed gravitational wave events included in O1 and O2. And more we find about 2000 gravitational wave triggers in O1 data.},
  archiveprefix = {arXiv},
  doi           = {10.1103/physrevd.101.104003},
  eprint        = {1909.13442},
  eprintclass   = {astro-ph.IM},
  eprinttype    = {arXiv},
  file          = {:http\://arxiv.org/pdf/1909.13442v1:PDF;:2020Wang-Gravitationalwavesignal.pdf:PDF},
  keywords      = {astro-ph.IM, gr-qc},
  primaryclass  = {astro-ph.IM},
  publisher     = {American Physical Society ({APS})},
}

@Article{2020Cuoco-EnhancingGravitationalwave,
  author        = {Cuoco, Elena and Powell, Jade and Cavaglià, Marco and Ackley, Kendall and Bejger, Michal and Chatterjee, Chayan and Coughlin, Michael and Coughlin, Scott and Easter, Paul and Essick, Reed and Gabbard, Hunter and Gebhard, Timothy and Ghosh, Shaon and Haegel, Leila and Iess, Alberto and Keitel, David and Marka, Zsuzsa and Marka, Szabolcs and Morawski, Filip and Nguyen, Tri and Ormiston, Rich and Puerrer, Michael and Razzano, Massimiliano and Staats, Kai and Vajente, Gabriele and Williams, Daniel},
  title         = {Enhancing Gravitational-wave Science with Machine Learning},
  year          = {2020},
  month         = may,
  abstract      = {Machine learning has emerged as a popular and powerful approach for solving problems in astrophysics. We review applications of machine learning techniques for the analysis of ground-based gravitational-wave detector data. Examples include techniques for improving the sensitivity of Advanced LIGO and Advanced Virgo gravitational-wave searches, methods for fast measurements of the astrophysical parameters of gravitational-wave sources, and algorithms for reduction and characterization of non-astrophysical detector noise. These applications demonstrate how machine learning techniques may be harnessed to enhance the science that is possible with current and future gravitational-wave detectors.},
  archiveprefix = {arXiv},
  eprint        = {2005.03745v2},
  file          = {:http\://arxiv.org/pdf/2005.03745v2:PDF;:2020Cuoco-EnhancingGravitationalwave.pdf:PDF},
  keywords      = {astro-ph.HE, gr-qc},
  primaryclass  = {astro-ph.HE},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:标示\;2\;1\;\;\;\;;
2 StaticGroup:Herb:6\;2\;1\;\;\;\;;
2 StaticGroup:[Herb:]\;2\;1\;\;\;\;;
}
